{"Link_to_commit": "https://github.com/jimmylewis/libman.audit/commit/91bef447774e61cd70318a523aa84a939e369c63", "n-gram matched": "generated by copilot", "n_lines_longer_change": 268, "n_files_impacted": 8, "longest_chunk": ["using System;", "using System.Collections.Generic;", "using System.IO;", "using System.Linq;", "using System.Net.Http;", "using System.Text;", "using System.Text.Json;", "using System.Text.Json.Serialization;", "using System.Threading.Tasks;", "using Microsoft.Build.Framework;", "using Microsoft.Build.Utilities;", "", "using Task = Microsoft.Build.Utilities.Task;", "", "namespace Libman.Audit", "{", "    public class LibmanAuditTask : Task", "    {", "        [Required]", "        public string LibmanJsonPath { get; set; }", "", "        [Output]", "        public ITaskItem[] VulnerablePackages { get; private set; }", "", "        private readonly HttpClient _httpClient;", "        private const string SonatypeApiBaseUrl = \"https://ossindex.sonatype.org/api/v3/component-report\";", "        private static readonly JsonSerializerOptions _jsonOptions = new JsonSerializerOptions", "        {", "            PropertyNameCaseInsensitive = true,", "            PropertyNamingPolicy = JsonNamingPolicy.CamelCase", "        };", "", "        public LibmanAuditTask()", "        {", "            _httpClient = new HttpClient();", "            // initialize non-null values", "            LibmanJsonPath = \"\";", "            VulnerablePackages = [];", "        }", "", "        public override bool Execute()", "        {", "            try", "            {", "                Log.LogMessage(MessageImportance.Normal, \"Starting Libman audit task...\");", "", "                if (!File.Exists(LibmanJsonPath))", "                {", "                    Log.LogError($\"Libman.json file not found at: {LibmanJsonPath}\");", "                    return false;", "                }", "", "                string jsonContent = File.ReadAllText(LibmanJsonPath);", "                List<LibmanPackage> libmanPackages = ParseLibmanJson(jsonContent);", "", "                if (libmanPackages.Count == 0)", "                {", "                    Log.LogMessage(MessageImportance.Normal, \"No packages found in libman.json\");", "                    VulnerablePackages = new TaskItem[0];", "                    return true;", "                }", "", "                List<VulnerablePackage> vulnerablePackages = AuditPackagesAsync(libmanPackages).GetAwaiter().GetResult();", "                VulnerablePackages = ConvertToTaskItems(vulnerablePackages);", "", "                if (vulnerablePackages.Count > 0)", "                {", "                    Log.LogWarning($\"Found {vulnerablePackages.Count} vulnerable packages in libman.json\");", "                    foreach (VulnerablePackage package in vulnerablePackages)", "                    {", "                        Log.LogWarning($\"Vulnerable package: {package.Name} {package.Version}, Vulnerability count: {package.VulnerabilityCount}\");", "                    }", "                }", "                else", "                {", "                    Log.LogMessage(MessageImportance.Normal, \"No vulnerable packages found\");", "                }", "", "                return true;", "            }", "            catch (Exception ex)", "            {", "                Log.LogErrorFromException(ex);", "                return false;", "            }", "        }", "", "        private List<LibmanPackage> ParseLibmanJson(string jsonContent)", "        {", "            List<LibmanPackage> packages = new List<LibmanPackage>();", "", "            try", "            {", "                using (JsonDocument doc = JsonDocument.Parse(jsonContent))", "                {", "                    JsonElement root = doc.RootElement;", "", "                    if (!root.TryGetProperty(\"libraries\", out JsonElement librariesElement) ||", "                        librariesElement.ValueKind != JsonValueKind.Array)", "                    {", "                        Log.LogMessage(MessageImportance.Normal, \"No libraries found in libman.json\");", "                        return packages;", "                    }", "", "                    foreach (JsonElement library in librariesElement.EnumerateArray())", "                    {", "                        if (!library.TryGetProperty(\"provider\", out JsonElement providerElement) ||", "                            !library.TryGetProperty(\"library\", out JsonElement nameElement))", "                        {", "                            continue;", "                        }", "", "                        string provider = providerElement.GetString() ?? string.Empty;", "                        string name = nameElement.GetString() ?? string.Empty;", "", "                        if (string.IsNullOrEmpty(provider) || string.IsNullOrEmpty(name))", "                        {", "                            continue;", "                        }", "", "                        // Parse package name and version (format varies by provider)", "                        string packageName;", "                        string packageVersion;", "", "                        if (name.Contains(\"@\"))", "                        {", "                            string[] parts = name.Split(new[] { '@' }, 2);", "                            packageName = parts[0];", "                            packageVersion = parts[1];", "                        }", "                        else", "                        {", "                            // If no version is specified, use the name as-is and leave version empty", "                            packageName = name;", "                            packageVersion = string.Empty;", "                        }", "", "                        packages.Add(new LibmanPackage", "                        {", "                            Name = packageName,", "                            Version = packageVersion,", "                            Provider = provider", "                        });", "", "                        Log.LogMessage(MessageImportance.Low, $\"Found package: {packageName} {packageVersion} (Provider: {provider})\");", "                    }", "                }", "            }", "            catch (JsonException ex)", "            {", "                Log.LogError($\"Failed to parse libman.json: {ex.Message}\");", "            }", "", "            return packages;", "        }", "", "        private async Task<List<VulnerablePackage>> AuditPackagesAsync(List<LibmanPackage> packages)", "        {", "            List<VulnerablePackage> vulnerablePackages = new List<VulnerablePackage>();", "", "            try", "            {", "                // Group packages in batches to avoid large requests", "                for (int i = 0; i < packages.Count; i += 20)", "                {", "                    List<LibmanPackage> batch = packages.Skip(i).Take(20).ToList();", "                    List<string> components = new List<string>();", "", "                    foreach (LibmanPackage package in batch)", "                    {", "                        string packageId = GetPackageCoordinates(package);", "                        if (!string.IsNullOrEmpty(packageId))", "                        {", "                            components.Add(packageId);", "                        }", "                    }", "", "                    if (components.Count > 0)", "                    {", "                        SonatypeRequest requestData = new SonatypeRequest", "                        {", "                            Coordinates = components.ToArray()", "                        };", "", "                        StringContent content = new StringContent(", "                            JsonSerializer.Serialize(requestData, _jsonOptions),", "                            Encoding.UTF8,", "                            \"application/json\");", "", "                        HttpResponseMessage response = await _httpClient.PostAsync(SonatypeApiBaseUrl, content);", "", "                        if (response.IsSuccessStatusCode)", "                        {", "                            string responseContent = await response.Content.ReadAsStringAsync();", "                            List<SonatypeResult>? results = JsonSerializer.Deserialize<List<SonatypeResult>>(responseContent, _jsonOptions);", "", "                            if (results != null)", "                            {", "                                foreach (SonatypeResult result in results)", "                                {", "                                    if (result.Vulnerabilities != null && result.Vulnerabilities.Count > 0)", "                                    {", "                                        LibmanPackage? package = batch.FirstOrDefault(p => GetPackageCoordinates(p) == result.Coordinates);", "                                        if (package != null)", "                                        {", "                                            vulnerablePackages.Add(new VulnerablePackage", "                                            {", "                                                Name = package.Name,", "                                                Version = package.Version,", "                                                Provider = package.Provider,", "                                                VulnerabilityCount = result.Vulnerabilities.Count,", "                                                Description = string.Join(\"; \", result.Vulnerabilities.Select(v => v.Title))", "                                            });", "                                        }", "                                    }", "                                }", "                            }", "                        }", "                        else", "                        {", "                            Log.LogWarning($\"Failed to get vulnerability data: {response.StatusCode} {await response.Content.ReadAsStringAsync()}\");", "                        }", "                    }", "                }", "            }", "            catch (Exception ex)", "            {", "                Log.LogWarning($\"Error checking for vulnerabilities: {ex.Message}\");", "            }", "", "            return vulnerablePackages;", "        }", "", "        private string GetPackageCoordinates(LibmanPackage package)", "        {", "            // Map libman providers to Sonatype coordinate formats", "            switch (package.Provider.ToLowerInvariant())", "            {", "                case \"cdnjs\":", "                    return $\"pkg:npm/{package.Name}@{package.Version}\";", "                case \"unpkg\":", "                    return $\"pkg:npm/{package.Name}@{package.Version}\";", "                case \"jsdelivr\":", "                    return $\"pkg:npm/{package.Name}@{package.Version}\";", "                default:", "                    Log.LogWarning($\"Unsupported provider: {package.Provider}\");", "                    return \"\";", "            }", "        }", "", "        private ITaskItem[] ConvertToTaskItems(List<VulnerablePackage> vulnerablePackages)", "        {", "            List<TaskItem> taskItems = new List<TaskItem>();", "", "            foreach (VulnerablePackage package in vulnerablePackages)", "            {", "                TaskItem taskItem = new TaskItem(package.Name);", "                taskItem.SetMetadata(\"Version\", package.Version);", "                taskItem.SetMetadata(\"Provider\", package.Provider);", "                taskItem.SetMetadata(\"VulnerabilityCount\", package.VulnerabilityCount.ToString());", "                taskItem.SetMetadata(\"Description\", package.Description);", "                taskItems.Add(taskItem);", "            }", "", "            return taskItems.ToArray();", "        }", "    }", "}"], "file_path": "Libman.Audit/LibmanPackage.cs"}
{"Link_to_commit": "https://github.com/luis-rodriguezfernandez-sonarsource/maven-basic/commit/177684f4cbcef2fd26f63623cac2161f584c0496", "n-gram matched": "generated by copilot", "n_lines_longer_change": 27, "n_files_impacted": 1, "longest_chunk": ["package com.acme.basic;", "", "import org.junit.jupiter.api.Test;", "import org.springframework.boot.test.context.SpringBootTest;", "import org.springframework.boot.test.web.server.LocalServerPort;", "import org.springframework.http.ResponseEntity;", "import org.springframework.web.client.RestTemplate;", "", "import static org.assertj.core.api.Assertions.assertThat;", "", "@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)", "public class FibonacciControllerIT {", "", "    @LocalServerPort", "    private int port;", "", "    private final RestTemplate restTemplate = new RestTemplate();", "", "    @Test", "    public void testFibonacciEndpoint() {", "        String url = \"http://localhost:\" + port + \"/fibonacci?n=5\";", "        ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);", "", "        assertThat(response.getStatusCode().is2xxSuccessful()).isTrue();", "        assertThat(response.getBody()).isEqualTo(\"5\");", "    }", "}"], "file_path": "src/test/java/com/acme/basic/FibonacciControllerIT.java"}
{"Link_to_commit": "https://github.com/professor-tucker/ai-prompts/commit/a023769eb9d4881bd696a1e52cad31a5c3967dc2", "n-gram matched": "generated by copilot", "n_lines_longer_change": 141, "n_files_impacted": 1, "longest_chunk": ["import requests", "import pandas as pd", "import re", "import os", "from bs4 import BeautifulSoup", "from datetime import datetime, timedelta", "import pickle", "from google.colab import drive", "from google_auth_oauthlib.flow import InstalledAppFlow", "from googleapiclient.discovery import build", "from docx import Document", "import nltk", "from nltk.tokenize import word_tokenize", "from nltk.corpus import stopwords", "from sklearn.feature_extraction.text import TfidfVectorizer", "", "# Initialization", "def initialize():", "    drive.mount('/content/drive')", "    nltk.download('punkt')", "    nltk.download('stopwords')", "", "# Job Retriever Class", "class JobRetriever:", "    def __init__(self):", "        self.jobs_df = pd.DataFrame(columns=['Title', 'Company', 'Location', 'Description', 'URL', 'Date_Posted', 'Keywords_Match'])", "", "    def search_indeed(self, keywords, location, pages=5):", "        base_url = \"https://www.indeed.com/jobs\"", "        all_jobs = []", "", "        for page in range(pages):", "            params = {'q': keywords, 'l': location, 'start': page * 10}", "            headers = {'User-Agent': 'Mozilla/5.0'}", "", "            try:", "                response = requests.get(base_url, params=params, headers=headers)", "                soup = BeautifulSoup(response.text, 'html.parser')", "                job_cards = soup.find_all('div', class_='jobsearch-SerpJobCard')", "", "                for card in job_cards:", "                    job_title_elem = card.find('a', class_='jobtitle')", "                    company_elem = card.find('span', class_='company')", "                    location_elem = card.find('div', class_='recJobLoc')", "                    description_elem = card.find('div', class_='summary')", "", "                    if job_title_elem and company_elem:", "                        job_title = job_title_elem.text.strip()", "                        company = company_elem.text.strip()", "                        location = location_elem['data-rc-loc'] if location_elem else \"N/A\"", "                        description = description_elem.text.strip() if description_elem else \"N/A\"", "                        url = \"https://www.indeed.com\" + job_title_elem['href']", "", "                        keywords_list = keywords.lower().split()", "                        match_score = sum(1 for keyword in keywords_list if keyword.lower() in (job_title.lower() + \" \" + description.lower()))", "", "                        job_data = {'Title': job_title, 'Company': company, 'Location': location, 'Description': description, 'URL': url, 'Date_Posted': datetime.now().strftime(\"%Y-%m-%d\"), 'Keywords_Match': match_score}", "                        all_jobs.append(job_data)", "", "            except requests.RequestException as e:", "                print(f\"Error scraping Indeed page {page}: {str(e)}\")", "", "        self.jobs_df = pd.concat([self.jobs_df, pd.DataFrame(all_jobs)], ignore_index=True)", "", "    def filter_jobs(self, min_keywords_match=2):", "        return self.jobs_df[self.jobs_df['Keywords_Match'] >= min_keywords_match].sort_values('Keywords_Match', ascending=False)", "", "    def save_jobs(self, filename='job_listings.csv'):", "        path = '/content/drive/My Drive/' + filename", "        self.jobs_df.to_csv(path, index=False)", "        print(f\"Saved {len(self.jobs_df)} jobs to {path}\")", "        return path", "", "# Document Customizer Class", "class DocumentCustomizer:", "    def __init__(self, resume_path, cover_letter_path):", "        self.resume_path = resume_path", "        self.cover_letter_path = cover_letter_path", "        self.resume_doc = self.load_document(resume_path)", "        self.cover_letter_doc = self.load_document(cover_letter_path)", "", "    def load_document(self, path):", "        try:", "            return Document(path)", "        except Exception as e:", "            print(f\"Error loading document from {path}: {str(e)}\")", "            return None", "", "    def extract_job_keywords(self, job_description):", "        tokens = word_tokenize(job_description.lower())", "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words('english')]", "        vectorizer = TfidfVectorizer(max_features=20)", "        tfidf_matrix = vectorizer.fit_transform([' '.join(filtered_tokens)])", "        feature_names = vectorizer.get_feature_names_out()", "        word_scores = [(word, tfidf_matrix[0, i]) for i, word in enumerate(feature_names)]", "        word_scores.sort(key=lambda x: x[1], reverse=True)", "        return [word for word, score in word_scores[:10]]", "", "    def customize_resume(self, job_title, company_name, job_description):", "        if not self.resume_doc:", "            return None", "", "        custom_resume = Document()", "        keywords = self.extract_job_keywords(job_description)", "        print(f\"Keywords extracted: {keywords}\")", "", "        for para in self.resume_doc.paragraphs:", "            if \"[OBJECTIVE]\" in para.text:", "                custom_text = para.text.replace(\"[OBJECTIVE]\", f\"Experienced professional seeking the {job_title} position at {company_name}, bringing expertise in {', '.join(keywords[:3])}.\")", "                custom_resume.add_paragraph(custom_text, para.style)", "            else:", "                text = para.text", "                for keyword in keywords:", "                    if keyword.lower() in text.lower() and len(keyword) > 3:", "                        text = re.sub(re.escape(keyword), f\"**{keyword}**\", text, flags=re.IGNORECASE)", "                custom_resume.add_paragraph(text, para.style)", "", "        filename = f\"Custom_Resume_{company_name}_{datetime.now().strftime('%Y%m%d')}.docx\"", "        save_path = f\"/content/drive/My Drive/{filename}\"", "        custom_resume.save(save_path)", "        print(f\"Customized resume saved to {save_path}\")", "        return save_path", "", "# Initialization", "initialize()", "", "# Example usage", "def run_job_application_system():", "    resume_path = \"/content/drive/My Drive/Resume_Template.docx\"", "    cover_letter_path = \"/content/drive/My Drive/Cover_Letter_Template.docx\"", "    manager = JobApplicationManager(resume_path, cover_letter_path)", "    job_keywords = \"cybersecurity IT project management CISSP PMP\"", "    locations = [\"New York, NY\", \"Remote\"]", "    jobs_found = manager.search_jobs(job_keywords, locations)", "    print(\"\\nTop matching jobs:\")", "    for i, (_, job) in enumerate(jobs_found.head(10).iterrows()):", "        print(f\"{i+1}. {job['Title']} at {job['Company']} ({job['Location']}) - Match Score: {job['Keywords_Match']}\")", "    manager.batch_process_jobs(num_jobs=3)", "    print(\"\\nJob application automation completed!\")", "", "run_job_application_system()"], "file_path": "03.03.2025.claude-auto-app-copilot-mod.py"}
{"Link_to_commit": "https://github.com/SimTimms/mappi/commit/7f511bd95ddf7066fd40a729a1155b95b8eabe02", "n-gram matched": "generated by copilot", "n_lines_longer_change": 8, "n_files_impacted": 3, "longest_chunk": ["/**", " * Fetch tide data for a given location.", " *", " * @param locationName - The name of the location to fetch tide data for.", " * @param apiKey - The API key for authenticating with the weather API.", " * @returns A promise that resolves to the tide data for the specified location.", " */", ""], "file_path": "mappi-api/src/services/fetchTideData.ts"}
{"Link_to_commit": "https://github.com/MoleskiCoder/EightBitNet/commit/caca3467d9c2b627b824a80601b1ccee4221dd13", "n-gram matched": "generated by copilot", "n_lines_longer_change": 105, "n_files_impacted": 6, "longest_chunk": ["namespace EightBit.UnitTest", "{", "    using Microsoft.VisualStudio.TestTools.UnitTesting;", "    using EightBit;", "", "    [TestClass]", "    public class ChipTests", "    {", "        [TestMethod]", "        public void Bit_ReturnsCorrectBit()", "        {", "            Assert.AreEqual(0x01, Chip.Bit(0));", "            Assert.AreEqual(0x02, Chip.Bit(1));", "            Assert.AreEqual(0x80, Chip.Bit(7));", "            Assert.AreEqual(0x08, Chip.Bit((byte)3));", "        }", "", "        [TestMethod]", "        public void SetBit_SetsBitCorrectly()", "        {", "            Assert.AreEqual(0b00001101, Chip.SetBit(0b00001001, 0b00000100));", "            Assert.AreEqual(0b00001101, Chip.SetBit(0b00001101, 0b00000100));", "            Assert.AreEqual(0b00001101, Chip.SetBit(0b00001101, 0b00000100, true));", "            Assert.AreEqual(0b00001001, Chip.SetBit(0b00001101, 0b00000100, false));", "        }", "", "        [TestMethod]", "        public void ClearBit_ClearsBitCorrectly()", "        {", "            Assert.AreEqual(0b00001001, Chip.ClearBit(0b00001101, 0b00000100));", "            Assert.AreEqual(0b00001101, Chip.ClearBit(0b00001101, 0b00000100, false));", "            Assert.AreEqual(0b00001001, Chip.ClearBit(0b00001101, 0b00000100, true));", "        }", "", "        [TestMethod]", "        public void HighByte_LowByte_WorkCorrectly()", "        {", "            ushort value = 0xABCD;", "            Assert.AreEqual(0xAB, Chip.HighByte(value));", "            Assert.AreEqual(0xCD, Chip.LowByte(value));", "            int intValue = 0x1234;", "            Assert.AreEqual(0x12, Chip.HighByte(intValue));", "            Assert.AreEqual(0x34, Chip.LowByte(intValue));", "        }", "", "        [TestMethod]", "        public void PromoteByte_DemoteByte_WorkCorrectly()", "        {", "            Assert.AreEqual(0x3400, Chip.PromoteByte(0x34));", "            Assert.AreEqual(0x12, Chip.DemoteByte(0x1234));", "        }", "", "        [TestMethod]", "        public void HigherPart_LowerPart_WorkCorrectly()", "        {", "            ushort value = 0xABCD;", "            Assert.AreEqual(0xAB00, Chip.HigherPart(value));", "            Assert.AreEqual(0xCD, Chip.LowerPart(value));", "        }", "", "        [TestMethod]", "        public void MakeWord_CreatesCorrectWord()", "        {", "            Assert.AreEqual(0x1234, Chip.MakeWord(0x34, 0x12));", "        }", "", "        [TestMethod]", "        public void NibbleMethods_WorkCorrectly()", "        {", "            byte value = 0xAB;", "            Assert.AreEqual(0xA, Chip.HighNibble(value));", "            Assert.AreEqual(0xB, Chip.LowNibble(value));", "            Assert.AreEqual(0xA0, Chip.HigherNibble(value));", "            Assert.AreEqual(0xB, Chip.LowerNibble(value));", "            Assert.AreEqual(0xB0, Chip.PromoteNibble(value));", "            Assert.AreEqual(0xA, Chip.DemoteNibble(value));", "        }", "", "        [TestMethod]", "        public void CountBits_ReturnsCorrectCount()", "        {", "            Assert.AreEqual(0, Chip.CountBits(0));", "            Assert.AreEqual(1, Chip.CountBits(1));", "            Assert.AreEqual(8, Chip.CountBits(0xFF));", "        }", "", "        [TestMethod]", "        public void EvenParity_ReturnsCorrectParity()", "        {", "            Assert.IsTrue(Chip.EvenParity(0)); // 0 bits set", "            Assert.IsFalse(Chip.EvenParity(1)); // 1 bit set", "            Assert.IsTrue(Chip.EvenParity(3)); // 2 bits set", "        }", "", "        [TestMethod]", "        public void FindFirstSet_ReturnsCorrectIndex()", "        {", "            Assert.AreEqual(0, Chip.FindFirstSet(0));", "            Assert.AreEqual(1, Chip.FindFirstSet(1));", "            Assert.AreEqual(2, Chip.FindFirstSet(2));", "            Assert.AreEqual(3, Chip.FindFirstSet(4));", "            Assert.AreEqual(5, Chip.FindFirstSet(0b10000));", "        }", "    }", "}"], "file_path": "EightBit/EightBit.UnitTest/DeviceTests.cs"}
{"Link_to_commit": "https://github.com/jakobatgithub/notification_test/commit/db2954f478a1cebc63fad4a320bda7039de35838", "n-gram matched": "generated by copilot", "n_lines_longer_change": 15, "n_files_impacted": 8, "longest_chunk": ["    \"\"\"", "    Send a data message via Firebase Cloud Messaging (FCM).", "", "    Args:", "        token (str): The recipient's FCM device token.", "        msg_id (str): The unique message ID.", "        title (str): The title of the message.", "        body (str): The body content of the message.", "", "    Returns:", "        str: The response from the Firebase messaging service.", "", "    Raises:", "        ImportError: If the Firebase Admin SDK is not installed.", "    \"\"\""], "file_path": "backend/django_emqx/utils.py"}
{"Link_to_commit": "https://github.com/depromeet/depromeet-makers-fe/commit/e6e80a27020c304f49d511e4fbebd73db3aa6a11", "n-gram matched": "generated by copilot", "n_lines_longer_change": 37, "n_files_impacted": 10, "longest_chunk": ["import { CURRENT_GENERATION } from '@depromeet-makers/constant';", "import type { UseMutationOptions } from '@tanstack/react-query';", "import { useMutation, useQueryClient } from '@tanstack/react-query';", "", "import type { CustomError } from '../base';", "import { api } from '../base';", "import type { Session } from '../types';", "", "interface EditSessionRequest extends Omit<Session, 'sessionId' | 'generation'> {}", "", "interface EditSessionResponse extends Session {}", "", "const editSession = (sessionId: Session['sessionId'], request: EditSessionRequest) => {", "  return api.put<EditSessionResponse>(`/v1/sessions/${sessionId}`, {", "    ...request,", "    generation: CURRENT_GENERATION,", "  });", "};", "", "export const useEditSession = (", "  sessionId: Session['sessionId'],", "  options?: UseMutationOptions<EditSessionResponse, CustomError, EditSessionRequest>,", ") => {", "  const queryClient = useQueryClient();", "", "  return useMutation({", "    mutationFn: (request: EditSessionRequest) => editSession(sessionId, request),", "    ...options,", "    onSuccess: (...params) => {", "      options?.onSuccess?.(...params);", "", "      queryClient.invalidateQueries({", "        queryKey: ['sessions'],", "      });", "    },", "  });", "};"], "file_path": "packages/api/src/sessions/useGetSessionDetail.ts"}
{"Link_to_commit": "https://github.com/ikedam/udpredirector/commit/e027a115f6670d96ce526a615d320c3a1b88e9bc", "n-gram matched": "generated by copilot", "n_lines_longer_change": 10, "n_files_impacted": 1, "longest_chunk": ["\tdefer syscall.Close(fd)", "", "\t// \u30bd\u30b1\u30c3\u30c8\u3092\u30a4\u30f3\u30bf\u30fc\u30d5\u30a7\u30fc\u30b9\u306b\u30d0\u30a4\u30f3\u30c9", "\taddr := syscall.SockaddrLinklayer{", "\t\tProtocol: syscall.ETH_P_ALL,", "\t\tIfindex:  iface.Index,", "\t}", "\tif err := syscall.Bind(fd, &addr); err != nil {", "\t\tlog.Fatalf(\"Failed to bind raw socket: %v\", err)", "\t}"], "file_path": "main.go"}
{"Link_to_commit": "https://github.com/depromeet/depromeet-makers-fe/commit/724bed64d2071c62797209a4dffeccf6986353bf", "n-gram matched": "generated by copilot", "n_lines_longer_change": 7, "n_files_impacted": 7, "longest_chunk": ["export const ATTENDANCE_STATUS_TEXT_COLOR: Record<ATTENDANCE_STATUS, string> = {", "  [ATTENDANCE_STATUS.\ucd9c\uc11d\ub300\uae30]: 'text-gray-300',", "  [ATTENDANCE_STATUS.\ucd9c\uc11d]: 'text-green-300',", "  [ATTENDANCE_STATUS.\uc9c0\uac01]: 'text-yellow-300',", "  [ATTENDANCE_STATUS.\uacb0\uc11d]: 'text-red-300',", "};", ""], "file_path": "apps/admin/src/constants/attendance.ts"}
{"Link_to_commit": "https://github.com/Pablo-Aliskevicius/cpp8Queens/commit/26dfaacf128b0dfb554e5cf2e7fa6c9890f4a44b", "n-gram matched": "generated by copilot", "n_lines_longer_change": 144, "n_files_impacted": 6, "longest_chunk": ["// #include <iostream>", "// include <vector>", "// include <chrono>", "", "import <iostream>;", "import <vector>;", "import <chrono>;", "", "constexpr int N = 8;", "using Board = uint64_t;", "", "constexpr Board col_mask = (1ULL << N) - 1;", "constexpr Board diag1_mask = (1ULL << (2 * N - 1)) - 1;", "constexpr Board diag2_mask = (1ULL << (2 * N - 1)) - 1;", "", "/*", "constexpr Board col_threats[N] = {", "    0x0101010101010101ULL,", "    0x0202020202020202ULL,", "    0x0404040404040404ULL,", "    0x0808080808080808ULL,", "    0x1010101010101010ULL,", "    0x2020202020202020ULL,", "    0x4040404040404040ULL,", "    0x8080808080808080ULL", "};", "", "constexpr Board diag1_threats[2 * N - 1] = {", "    0x0000000000000080ULL,", "    0x0000000000008040ULL,", "    0x0000000000804020ULL,", "    0x0000000080402010ULL,", "    0x0000008040201008ULL,", "    0x0000804020100804ULL,", "    0x0080402010080402ULL,", "    0x8040201008040201ULL,", "    0x4020100804020100ULL,", "    0x2010080402010000ULL,", "    0x1008040201000000ULL,", "    0x0804020100000000ULL,", "    0x0402010000000000ULL,", "    0x0201000000000000ULL,", "    0x0100000000000000ULL", "};", "", "constexpr Board diag2_threats[2 * N - 1] = {", "    0x0000000000000001ULL,", "    0x0000000000000102ULL,", "    0x0000000000010204ULL,", "    0x0000000001020408ULL,", "    0x0000000102040810ULL,", "    0x0000010204081020ULL,", "    0x0001020408102040ULL,", "    0x0102040810204080ULL,", "    0x0204081020408000ULL,", "    0x0408102040800000ULL,", "    0x0810204080000000ULL,", "    0x1020408000000000ULL,", "    0x2040800000000000ULL,", "    0x4080000000000000ULL,", "    0x8000000000000000ULL", "};", "//*/", "", "void solve(Board col, Board diag1, Board diag2, int row, std::vector<Board>& solutions, Board board) {", "    if (row == N) [[unlikely]] {", "        solutions.push_back(board);", "        return;", "    }", "", "    Board safe = ~(col | diag1 | diag2) & col_mask;", "", "    while (safe) {", "        Board p = safe & (-safe);", "        safe -= p;", "        solve(col | p, (diag1 | p) << 1, (diag2 | p) >> 1, row + 1, solutions, board | (p << (row * N)));", "    }", "}", "", "void print_solution(Board board) {", "    for (int i = 0; i < N; ++i) {", "        for (int j = 0; j < N; ++j) {", "            std::cout << ((board & (1ULL << (i * N + j))) ? \"1 \" : \"0 \");", "        }", "        std::cout << \"\\n\";", "    }", "    std::cout << \"\\n\";", "}", "", "int main() {", "    std::vector<Board> solutions;", "    auto start = std::chrono::high_resolution_clock::now();", "    solve(0, 0, 0, 0, solutions, 0);", "    auto end = std::chrono::high_resolution_clock::now();", "    std::chrono::duration<double> elapsed = end - start;", "", "    std::cout << \"Time taken: \" << elapsed.count() << \" seconds\\n\";", "    std::cout << \"Number of solutions found: \" << solutions.size() << \"\\n\";", "", "    for (int i = 0; i < std::min(3, static_cast<int>(solutions.size())); ++i) {", "        std::cout << \"Solution \" << i + 1 << \":\\n\";", "        print_solution(solutions[i]);", "    }", "", "    return 0;", "}", "", "/*", "Time taken: 2.68e-05 seconds", "Number of solutions found: 92", "Solution 1:", "1 0 0 0 0 0 0 0", "0 0 0 0 1 0 0 0", "0 0 0 0 0 0 0 1", "0 0 0 0 0 1 0 0", "0 0 1 0 0 0 0 0", "0 0 0 0 0 0 1 0", "0 1 0 0 0 0 0 0", "0 0 0 1 0 0 0 0", "", "Solution 2:", "1 0 0 0 0 0 0 0", "0 0 0 0 0 1 0 0", "0 0 0 0 0 0 0 1", "0 0 1 0 0 0 0 0", "0 0 0 0 0 0 1 0", "0 0 0 1 0 0 0 0", "0 1 0 0 0 0 0 0", "0 0 0 0 1 0 0 0", "", "Solution 3:", "1 0 0 0 0 0 0 0", "0 0 0 0 0 0 1 0", "0 0 0 1 0 0 0 0", "0 0 0 0 0 1 0 0", "0 0 0 0 0 0 0 1", "0 1 0 0 0 0 0 0", "0 0 0 0 1 0 0 0", "0 0 1 0 0 0 0 0", "", "", "E:\\Documents and Settings\\Pablo\\My Documents\\My Sources\\Cpp8Queens\\cpp8Queens\\x64\\Release\\CopilotCpp8Qeens.exe (process 10280) exited with code 0.", "Press any key to close this window . . .", "*/"], "file_path": "CopilotCpp8Qeens/CopilotCpp8Qeens.cpp"}
{"Link_to_commit": "https://github.com/MirkoMilenkovic/QuickQuiz/commit/c3156d98a929ea805d4c5d72764fa274a2cf1a02", "n-gram matched": "generated by copilot", "n_lines_longer_change": 134, "n_files_impacted": 2, "longest_chunk": ["using System;", "using System.Collections.Generic;", "using System.Linq;", "using Microsoft.VisualStudio.TestTools.UnitTesting;", "using QuickQuiz.QuestionLogic.Model;", "using QuickQuiz.QuizLogic.Exceptions;", "using QuickQuiz.QuizLogic.Model;", "", "namespace QuickQuiz.Tests", "{", "    [TestClass]", "    public class QuizTests", "    {", "        [TestMethod]", "        public void CreateQuiz_ShouldInitializeQuizWithPlayerName()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>", "            {", "                new Question(\"Question 1\"),", "                new Question(\"Question 2\")", "            };", "", "            // Act", "            Quiz quiz = Quiz.Create(playerName, questions);", "", "            // Assert", "            Assert.AreEqual(playerName, quiz.PlayerName);", "            Assert.IsNotNull(quiz.QuizId);", "            Assert.IsTrue(quiz.QuestionListReadOnly.Any());", "        }", "", "        [TestMethod]", "        public void GetNextQuestion_ShouldReturnNextUnansweredQuestion()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>", "            {", "                new Question(\"Question 1\"),", "                new Question(\"Question 2\")", "            };", "            Quiz quiz = Quiz.Create(playerName, questions);", "", "            // Act", "            QuizQuestion nextQuestion = quiz.GetNextQuestion();", "", "            // Assert", "            Assert.IsNotNull(nextQuestion);", "            Assert.AreEqual(\"Question 1\", nextQuestion.OriginalQuestion.Text);", "        }", "", "        [TestMethod]", "        [ExpectedException(typeof(ActiveQuestionNotAnsweredException))]", "        public void GetNextQuestion_ShouldThrowExceptionIfActiveQuestionNotAnswered()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>", "            {", "                new Question(\"Question 1\"),", "                new Question(\"Question 2\")", "            };", "            Quiz quiz = Quiz.Create(playerName, questions);", "            QuizQuestion nextQuestion = quiz.GetNextQuestion();", "", "            // Act", "            quiz.GetNextQuestion();", "        }", "", "        [TestMethod]", "        public void AnswerQuestion_ShouldReturnPlayersAnswer()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>();", "", "            Question question = new Question(\"Question 1\");", "            questions.Add(question);", "            question.AddAnswer(new Answer(\"Answer 1\", true));", "            question.AddAnswer(new Answer(\"Answer 2\", false));", "", "            Quiz quiz = Quiz.Create(playerName, questions);", "            QuizQuestion nextQuestion = quiz.GetNextQuestion();", "", "            // Act", "            Answer answer = quiz.AnswerQuestion(nextQuestion.QuizQuestionId, nextQuestion.OriginalQuestion.Answers.First().AnswerId);", "", "            // Assert", "            Assert.IsNotNull(answer);", "            Assert.AreEqual(\"Answer 1\", answer.Text);", "        }", "", "        [TestMethod]", "        [ExpectedException(typeof(Exception), \"There is no Active Question\")]", "        public void AnswerQuestion_ShouldThrowExceptionIfNoActiveQuestion()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>();", "", "            Question question = new Question(\"Question 1\");", "            questions.Add(question);", "            question.AddAnswer(new Answer(\"Answer 1\", true));", "            question.AddAnswer(new Answer(\"Answer 2\", false));", "", "            Quiz quiz = Quiz.Create(playerName, questions);", "", "            // Act", "            quiz.AnswerQuestion(\"invalidQuizQuestionId\", \"invalidAnswerId\");", "        }", "", "        [TestMethod]", "        [ExpectedException(typeof(Exception), \"You are not answering Active Question\")]", "        public void AnswerQuestion_ShouldThrowExceptionIfAnsweringNonActiveQuestion()", "        {", "            // Arrange", "            string playerName = \"Test Player\";", "            var questions = new List<Question>();", "", "            Question question = new Question(\"Question 1\");", "            questions.Add(question);", "            question.AddAnswer(new Answer(\"Answer 1\", true));", "            question.AddAnswer(new Answer(\"Answer 2\", false));", "", "            Quiz quiz = Quiz.Create(playerName, questions);", "            QuizQuestion nextQuestion = quiz.GetNextQuestion();", "", "            // Act", "            quiz.AnswerQuestion(\"invalidQuizQuestionId\", \"invalidAnswerId\");", "        }", "    }", "}"], "file_path": "QuickQuiz/QuickQuiz/QuizLogic/Model/QuizTests.cs"}
{"Link_to_commit": "https://github.com/paul356/agent-workspace/commit/eb91104c74d5354477325eb8b172f12135d6c9e2", "n-gram matched": "generated by copilot", "n_lines_longer_change": 15, "n_files_impacted": 10, "longest_chunk": ["<template>", "  <div>", "    <h1>Hello World</h1>", "  </div>", "</template>", "", "<script>", "export default {", "  name: 'MainView',", "};", "</script>", "", "<style scoped>", "/* Add any styles specific to MainView here */", "</style>"], "file_path": "vue.config.js"}
{"Link_to_commit": "https://github.com/Elkozel/WooODM/commit/883310ca61e772e072d329b5901884d2d8bd84db", "n-gram matched": "generated by copilot", "n_lines_longer_change": 103, "n_files_impacted": 1, "longest_chunk": ["import unittest", "import unittest", "from wooODM.products.category import Category", "from wooODM.core import WooCommerce", "", "class TestCategoryModel(unittest.TestCase):", "", "    @classmethod", "    def setUpClass(cls):", "        # Initialize WooCommerce API with dummy credentials for testing", "        WooCommerce.init(", "            url=\"\",", "            consumer_key=\"\",", "            consumer_secret=\"\"", "        )", "    @classmethod", "    def create_test_category(cls, name=\"Test Category\", slug=\"test-category\", description=\"A category for testing\"):", "        category = Category(", "            name=name,", "            slug=slug,", "            description=description", "        )", "        return category.save()", "", "    @classmethod", "    def delete_test_category(cls, category: Category):", "        return category.delete()", "", "    def test_create_category(self):", "        category = Category(", "            name=\"Test Category\",", "            slug=\"test-category\",", "            description=\"A category for testing\"", "        )", "        saved_category = category.save()", "        self.assertIsNotNone(saved_category.id)", "        self.assertEqual(saved_category.name, \"Test Category\")", "", "    def test_get_category(self):", "        test_category = TestCategoryModel.create_test_category(name=\"Get Test Category\", slug=\"get-test-category\")", "        category = Category.get(test_category.id)", "        self.assertEqual(category.id, test_category.id)", "        self.assertEqual(category, test_category)", "", "        test_category.delete()", "        with self.assertRaises(Exception):", "            Category.get(test_category.id)", "", "    def test_get_all_categories(self):", "        categories = Category.all(per_page=5, page=1)", "        self.assertIsInstance(categories, list)", "        self.assertGreaterEqual(len(categories), 1)", "        self.assertIsInstance(categories[0], Category)", "", "    def test_create_incomplete_category(self):", "        with self.assertRaises(ValueError):", "            Category(", "                slug=\"incomplete-category\"", "            ).save()", "", "    def test_create_category_without_slug(self):", "        with self.assertRaises(ValueError):", "            Category(", "                name=\"Category without Slug\"", "            ).save()", "", "    def test_create_category_with_invalid_data(self):", "        with self.assertRaises(ValueError):", "            Category(", "                name=\"Invalid Category\",", "                slug=\"invalid-category\",", "                description=123  # Invalid type for description", "            ).save()", "", "    def test_update_category_with_invalid_data(self):", "        category_id = 1  # Update with a valid category ID", "        category = Category.get(category_id)", "        category.description = 123  # Invalid type for description", "        with self.assertRaises(ValueError):", "            category.save()", "", "    def test_smoke(self):", "        # Create a category", "        category = TestCategoryModel.create_test_category(", "            name=\"Smoke Test Category\",", "            slug=\"smoke-test-category\",", "            description=\"A category for smoke testing\"", "        )", "        self.assertIsNotNone(category.id)", "        self.assertEqual(category.name, \"Smoke Test Category\")", "        self.assertEqual(category.description, \"A category for smoke testing\")", "", "        # Update the category", "        category.name = \"Updated Smoke Test Category\"", "        updated_category = category.save()", "        self.assertEqual(updated_category.name, \"Updated Smoke Test Category\")", "", "        # Delete the category", "        delete_response = updated_category.delete()", "        self.assertEqual(delete_response, updated_category)", "", "if __name__ == '__main__':", "    unittest.main()"], "file_path": "tests/wooODM/product/test_category.py"}
{"Link_to_commit": "https://github.com/coolsheets/takeStock/commit/5f90da0c46e6cd5072f35816e7aa011590cdcdb3", "n-gram matched": "generated by copilot", "n_lines_longer_change": 36, "n_files_impacted": 6, "longest_chunk": ["const express = require('express');", "const axios = require('axios');", "const router = express.Router();", "", "// Replace with your Alpha Vantage API key", "const API_KEY = 'YOUR_API_KEY';", "", "router.get('/:symbol', async (req, res) => {", "  const symbol = req.params.symbol;", "  const url = `https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=${symbol}&interval=5min&apikey=${API_KEY}`;", "", "  try {", "    const response = await axios.get(url);", "    const data = response.data;", "", "    if (data['Error Message']) {", "      return res.status(404).render('stock', { error: 'Stock symbol not found' });", "    }", "", "    const timeSeries = data['Time Series (5min)'];", "    const latestTime = Object.keys(timeSeries)[0];", "    const latestData = timeSeries[latestTime];", "", "    const stockInfo = {", "      symbol,", "      price: latestData['1. open'],", "      time: latestTime", "    };", "", "    res.render('stock', { stock: stockInfo });", "  } catch (error) {", "    res.status(500).render('stock', { error: 'Error fetching stock data' });", "  }", "});", "", "module.exports = router;"], "file_path": "routes/stock.js"}
{"Link_to_commit": "https://github.com/AnkiBhatia/copilot_tdd_experiment/commit/6e396755d92ae84d51751459a1bb4215a1338de3", "n-gram matched": "generated by copilot", "n_lines_longer_change": 107, "n_files_impacted": 16, "longest_chunk": ["# \ud83d\ude9c Smart Fleet Maintenance API", "", "## \ud83d\udccc Overview", "The **Smart Fleet Maintenance API** is designed to help track maintenance schedules, predict equipment failures, and log service records for agricultural machinery.", "", "## \ud83d\udd25 Features", "- **Register Equipment** \u2013 Store machine details (model, purchase date, usage hours).", "- **Maintenance Scheduler** \u2013 Predict maintenance needs based on usage.", "- **Service Logging** \u2013 Track service records and update machine status.", "- **Alerts & Notifications** \u2013 Notify users when maintenance is due.", "", "## \ud83c\udfd7\ufe0f Tech Stack", "- **Backend:** FastAPI (Python)", "- **Database:** SQLite / PostgreSQL", "- **Testing:** Pytest", "- **Data Validation:** Pydantic", "- **CI/CD:** GitHub Actions (for automated testing)", "", "## \ud83c\udfc1 Getting Started", "", "### **\ud83d\udd39 Prerequisites**", "Ensure you have the following installed:", "- Python 3.9+", "- pip", "- Virtual environment tool (venv or conda)", "", "### **\ud83d\udd39 Installation**", "```bash", "# Clone the repository", "git clone https://github.com/yourusername/smart-fleet-maintenance-api.git", "cd smart-fleet-maintenance-api", "", "# Set up a virtual environment", "python -m venv venv", "source venv/bin/activate  # On Windows: venv\\Scripts\\activate", "", "# Install dependencies", "pip install -r requirements.txt", "```", "", "### **\ud83d\udd39 Running the API**", "```bash", "uvicorn main:app --reload", "```", "API will be available at: `http://127.0.0.1:8000`", "", "### **\ud83d\udd39 Running Tests**", "```bash", "pytest tests/", "```", "", "## \ud83d\udcc2 Project Structure", "```", "smart-fleet-maintenance-api/", "\u2502\u2500\u2500 main.py          # Entry point for FastAPI application", "\u2502\u2500\u2500 database.py      # Database connection setup", "\u2502\u2500\u2500 requirements.txt # List of dependencies", "|\u2500\u2500 models/", "    |\u2500\u2500 models.py      # Pydantic models for request validation", "\u2502\u2500\u2500 tests/           # Pytest test cases", "\u2502\u2500\u2500 routers/         # API route handlers", "\u2502   \u251c\u2500\u2500 equipment.py", "\u2502   \u251c\u2500\u2500 maintenance.py", "\u2502\u2500\u2500 .github/workflows/ci.yml  # GitHub Actions for CI/CD", "\u2502\u2500\u2500 README.md        # Project documentation", "```", "", "## \ud83d\ude80 API Endpoints", "### 1\ufe0f\u20e3 Register Equipment", "**POST** `/equipment/`", "#### Request Body:", "```json", "{", "  \"name\": \"Tractor X\",", "  \"model\": \"TX-500\",", "  \"purchase_date\": \"2023-01-15\",", "  \"usage_hours\": 100", "}", "```", "#### Response:", "```json", "{", "  \"id\": \"UUID\",", "  \"name\": \"Tractor X\",", "  \"model\": \"TX-500\",", "  \"purchase_date\": \"2023-01-15\",", "  \"usage_hours\": 100", "}", "```", "", "### 2\ufe0f\u20e3 Get Equipment List", "**GET** `/equipment/`", "", "More endpoints will be added as features are implemented.", "", "## \ud83d\udccc Future Enhancements", "- **Machine Learning for Predictive Maintenance**", "- **Fleet Analytics Dashboard (Power BI)**", "- **Real-Time Alerts via WebSockets**", "", "---", "### \ud83d\udca1 Contributing", "Feel free to open an issue or submit a pull request.", "", "### \ud83d\udcdc License", "MIT License. See `LICENSE` for details.", ""], "file_path": "app/__init__.py"}
{"Link_to_commit": "https://github.com/depromeet/depromeet-makers-fe/commit/e2d541463d9e1388b2854e4f6f9bf4df37a029ea", "n-gram matched": "generated by copilot", "n_lines_longer_change": 44, "n_files_impacted": 9, "longest_chunk": ["import type { Dispatch, PropsWithChildren, SetStateAction } from 'react';", "import { createContext, useContext, useState } from 'react';", "", "export interface MarkerType {", "  id: string;", "  position: {", "    lat: number;", "    lng: number;", "  };", "  placeName: string;", "  addressName: string;", "}", "", "interface UsersContextType {", "  markers: MarkerType[];", "  setMarkers: Dispatch<SetStateAction<MarkerType[]>>;", "  selectedPlace?: MarkerType;", "  setSelectedPlace: Dispatch<SetStateAction<MarkerType | undefined>>;", "}", "", "const KaKaoMapContext = createContext<UsersContextType | null>(null);", "", "const KaKaoMapProvider = ({ children }: PropsWithChildren) => {", "  const [markers, setMarkers] = useState<MarkerType[]>([]);", "  const [selectedPlace, setSelectedPlace] = useState<MarkerType>();", "", "  return (", "    <KaKaoMapContext.Provider value={{ markers, setMarkers, selectedPlace, setSelectedPlace }}>", "      {children}", "    </KaKaoMapContext.Provider>", "  );", "};", "", "export const useKaKaoMap = () => {", "  const kaKaoMapContext = useContext(KaKaoMapContext);", "", "  if (!kaKaoMapContext) {", "    throw new Error('<kaKaoMapContext /> \ub0b4\ubd80\uc5d0\uc11c useKaKaoMap\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uc5b4\uc694.');", "  }", "", "  return kaKaoMapContext;", "};", "", "export default KaKaoMapProvider;"], "file_path": "apps/admin/src/app/(admin)/session/(data)/session.ts"}
{"Link_to_commit": "https://github.com/depromeet/depromeet-makers-fe/commit/03dcbae7a9530ee260ae429c30cf198e0883854b", "n-gram matched": "generated by copilot", "n_lines_longer_change": 30, "n_files_impacted": 6, "longest_chunk": ["import type { UseMutationOptions } from '@tanstack/react-query';", "import { useMutation, useQueryClient } from '@tanstack/react-query';", "", "import type { CustomError } from '../base';", "import { api } from '../base';", "import type { Session } from '../types';", "", "interface DeleteSessionRequest extends Pick<Session, 'sessionId'> {}", "", "interface DeleteSessionResponse extends Session {}", "", "const deleteSession = ({ sessionId }: DeleteSessionRequest) => {", "  return api.delete<DeleteSessionResponse>(`/v1/sessions/${sessionId}`);", "};", "", "export const useDeleteSession = (", "  options?: UseMutationOptions<DeleteSessionResponse, CustomError, DeleteSessionRequest>,", ") => {", "  const queryClient = useQueryClient();", "", "  return useMutation({", "    mutationFn: ({ sessionId }: DeleteSessionRequest) => deleteSession({ sessionId }),", "    ...options,", "    onSuccess: (...params) => {", "      options?.onSuccess?.(...params);", "", "      queryClient.invalidateQueries({ queryKey: ['sessions'] });", "    },", "  });", "};"], "file_path": "packages/api/src/sessions/useDeleteSession.ts"}
{"Link_to_commit": "https://github.com/Axolotls7/Axolotls7/commit/32e57ed021a49360d53357f32650383944bcae39", "n-gram matched": "generated by copilot", "n_lines_longer_change": 13, "n_files_impacted": 1, "longest_chunk": ["for i in range(0,len(tape)):", "\ttry:", "\t\ttape[i] = int(tape[i])", "\texcept ValueError:", "\t\ttry:", "\t\t\tassert tape[i] in symbols", "\t\texcept AssertionError:", "\t\t\ttape[i] = \"A\"", "\telse:", "\t\ttry:", "\t\t\tassert tape[i] in symbols", "\t\texcept AssertionError:", "\t\t\ttape[i] = 0"], "file_path": "turingmachine.py"}
{"Link_to_commit": "https://github.com/mg3-codes/d-d-spell-finder/commit/8222734bd8a9ff1118e8dfa578a6515120f8ff5e", "n-gram matched": "generated by copilot", "n_lines_longer_change": 15, "n_files_impacted": 33, "longest_chunk": ["\t/**", "\t * Maps the value of the proficiency die to the corresponding array of `EdgeOfTheEmpireDiceSymbol` results.", "\t *", "\t * @returns {EdgeOfTheEmpireDiceSymbol[]} An array of `EdgeOfTheEmpireDiceSymbol` representing the result of the die roll.", "\t *", "\t * The mapping is as follows:", "\t * - 1: Blank", "\t * - 2, 3: Success", "\t * - 4, 5: Success, Success", "\t * - 6: Advantage", "\t * - 7, 8, 9: Success, Advantage", "\t * - 10, 11: Advantage, Advantage", "\t * - 12: Triumph", "\t * - Default: Empty array", "\t */"], "file_path": "src/classes/edge-of-the-empire-dice/proficiency-die.ts"}
{"Link_to_commit": "https://github.com/depromeet/depromeet-makers-fe/commit/c06284175a9ca0a7d14ecb120520f8a80e791952", "n-gram matched": "generated by copilot", "n_lines_longer_change": 27, "n_files_impacted": 5, "longest_chunk": ["import type { UseMutationOptions } from '@tanstack/react-query';", "import { useMutation } from '@tanstack/react-query';", "", "import type { CustomError } from '../base';", "import { api } from '../base';", "import { setAccessToken, setRefreshToken } from '../base/token';", "", "interface PostAuthTestResponse {", "  accessToken: string;", "  refreshToken: string;", "}", "", "const postAuthTest = () => {", "  return api.post<PostAuthTestResponse>('/v1/auth/test');", "};", "", "export const useAuthTest = (options?: UseMutationOptions<PostAuthTestResponse, CustomError>) =>", "  useMutation({", "    mutationFn: postAuthTest,", "    ...options,", "    onSuccess: async (data, ...params) => {", "      await setAccessToken(data.accessToken);", "      await setRefreshToken(data.refreshToken);", "", "      options?.onSuccess?.(data, ...params);", "    },", "  });"], "file_path": "packages/api/src/base/token.ts"}
{"Link_to_commit": "https://github.com/shinyay/cobol-sample-app/commit/5ec286b12bd10e8186aabc65ebb0d3bef996313a", "n-gram matched": "generated by copilot", "n_lines_longer_change": 17, "n_files_impacted": 1, "longest_chunk": ["/**", " * Encapsulates the logic for calculating bonuses based on gross salary.", " */", "public class BonusCalculator {", "    // Constants", "    private static final double BONUS_RATE = 0.10;", "", "    /**", "     * Calculates the bonus based on the given gross salary.", "     *", "     * @param grossSalary the gross salary of the employee", "     * @return the calculated bonus", "     */", "    public double calculateBonus(double grossSalary) {", "        return grossSalary * BONUS_RATE;", "    }", "}"], "file_path": "java/BonusCalculator.java"}
{"Link_to_commit": "https://github.com/shinyay/cobol-sample-app/commit/4cce4a13f3f12f369c7fcd3e65ae6c88faa2305d", "n-gram matched": "generated by copilot", "n_lines_longer_change": 121, "n_files_impacted": 1, "longest_chunk": ["import java.util.ArrayList;", "import java.util.Collections;", "import java.util.Comparator;", "import java.util.List;", "", "/**", " * Manages the overall payroll system, including initializing employees, sorting employees, calculating net salaries,", " * calculating department totals, and displaying information.", " */", "public class PayrollSystem {", "    // Constants", "    private static final int MAX_EMPLOYEES = 5;", "    private static final double TAX_RATE = 0.20;", "    private static final double BONUS_RATE = 0.10;", "    private static final double DEDUCTION_RATE = 0.05;", "", "    // Attributes", "    private List<Employee> employees = new ArrayList<>();", "    private List<DepartmentTotal> departmentTotals = new ArrayList<>();", "", "    /**", "     * Initializes the employee data with hardcoded values.", "     */", "    public void initializeEmployees() {", "        employees.add(new Employee(\"E001\", \"Alice Johnson\", \"HR\", 70000.00));", "        employees.add(new Employee(\"E002\", \"Bob Smith\", \"IT\", 85000.00));", "        employees.add(new Employee(\"E003\", \"Charlie Brown\", \"Finance\", 60000.00));", "        employees.add(new Employee(\"E004\", \"David Wilson\", \"IT\", 95000.00));", "        employees.add(new Employee(\"E005\", \"Eve Davis\", \"HR\", 75000.00));", "    }", "", "    /**", "     * Sorts the employees by their IDs.", "     */", "    public void sortEmployees() {", "        Collections.sort(employees, Comparator.comparing(Employee::getId));", "    }", "", "    /**", "     * Calculates the net salaries for all employees.", "     */", "    public void calculateNetSalaries() {", "        BonusCalculator bonusCalculator = new BonusCalculator();", "        for (Employee employee : employees) {", "            double bonus = bonusCalculator.calculateBonus(employee.getGrossSalary());", "            double deductions = employee.getGrossSalary() * DEDUCTION_RATE;", "            double taxDeduction = employee.getGrossSalary() * TAX_RATE;", "            double netSalary = employee.getGrossSalary() + bonus - taxDeduction - deductions;", "", "            employee.setBonus(bonus);", "            employee.setDeductions(deductions);", "            employee.setTaxDeduction(taxDeduction);", "            employee.setNetSalary(netSalary);", "        }", "    }", "", "    /**", "     * Calculates the total salaries for each department.", "     */", "    public void calculateDepartmentTotals() {", "        for (Employee employee : employees) {", "            DepartmentTotal departmentTotal = departmentTotals.stream()", "                .filter(dt -> dt.getDepartmentName().equals(employee.getDepartment()))", "                .findFirst()", "                .orElseGet(() -> {", "                    DepartmentTotal newDeptTotal = new DepartmentTotal(employee.getDepartment());", "                    departmentTotals.add(newDeptTotal);", "                    return newDeptTotal;", "                });", "", "            departmentTotal.setTotalSalary(departmentTotal.getTotalSalary() + employee.getNetSalary());", "        }", "    }", "", "    /**", "     * Displays the employee payroll information.", "     */", "    public void displayEmployees() {", "        System.out.println(\"Employee Payroll Information\");", "        System.out.println(\"-----------------------------\");", "        for (Employee employee : employees) {", "            System.out.println(\"Employee ID: \" + employee.getId());", "            System.out.println(\"Name: \" + employee.getName());", "            System.out.println(\"Department: \" + employee.getDepartment());", "            System.out.println(\"Gross Salary: $\" + employee.getGrossSalary());", "            System.out.println(\"Bonus: $\" + employee.getBonus());", "            System.out.println(\"Deductions: $\" + employee.getDeductions());", "            System.out.println(\"Tax Deduction: $\" + employee.getTaxDeduction());", "            System.out.println(\"Net Salary: $\" + employee.getNetSalary());", "            System.out.println(\"-----------------------------\");", "        }", "    }", "", "    /**", "     * Displays the department salary totals.", "     */", "    public void displayDepartmentTotals() {", "        System.out.println(\"Department Salary Totals\");", "        System.out.println(\"-----------------------------\");", "        for (DepartmentTotal departmentTotal : departmentTotals) {", "            System.out.println(\"Department: \" + departmentTotal.getDepartmentName());", "            System.out.println(\"Total Salary: $\" + departmentTotal.getTotalSalary());", "            System.out.println(\"-----------------------------\");", "        }", "    }", "", "    /**", "     * The main method to run the payroll system.", "     *", "     * @param args command-line arguments", "     */", "    public static void main(String[] args) {", "        PayrollSystem payrollSystem = new PayrollSystem();", "        payrollSystem.initializeEmployees();", "        payrollSystem.sortEmployees();", "        payrollSystem.calculateNetSalaries();", "        payrollSystem.calculateDepartmentTotals();", "        payrollSystem.displayEmployees();", "        payrollSystem.displayDepartmentTotals();", "    }", "}"], "file_path": "java/PayrollSystem.java"}
{"Link_to_commit": "https://github.com/shinyay/cobol-sample-app/commit/c0b86f798bfb3b061c1622c6e5b808b4ba6a1c92", "n-gram matched": "generated by copilot", "n_lines_longer_change": 102, "n_files_impacted": 1, "longest_chunk": ["package java;", "", "/**", " * Represents an employee with attributes like ID, name, department, gross salary, bonus, deductions, net salary, and tax deduction.", " */", "public class Employee {", "    // Attributes", "    private String id;", "    private String name;", "    private String department;", "    private double grossSalary;", "    private double bonus;", "    private double deductions;", "    private double netSalary;", "    private double taxDeduction;", "", "    /**", "     * Initializes the employee with the given ID, name, department, and gross salary.", "     * Other attributes are initialized to default values.", "     *", "     * @param id          the employee's ID", "     * @param name        the employee's name", "     * @param department  the department the employee belongs to", "     * @param grossSalary the employee's gross salary", "     */", "    public Employee(String id, String name, String department, double grossSalary) {", "        this.id = id;", "        this.name = name;", "        this.department = department;", "        this.grossSalary = grossSalary;", "        this.bonus = 0.0;", "        this.deductions = 0.0;", "        this.netSalary = 0.0;", "        this.taxDeduction = 0.0;", "    }", "", "    // Getters and setters for all attributes", "", "    public String getId() {", "        return id;", "    }", "", "    public void setId(String id) {", "        this.id = id;", "    }", "", "    public String getName() {", "        return name;", "    }", "", "    public void setName(String name) {", "        this.name = name;", "    }", "", "    public String getDepartment() {", "        return department;", "    }", "", "    public void setDepartment(String department) {", "        this.department = department;", "    }", "", "    public double getGrossSalary() {", "        return grossSalary;", "    }", "", "    public void setGrossSalary(double grossSalary) {", "        this.grossSalary = grossSalary;", "    }", "", "    public double getBonus() {", "        return bonus;", "    }", "", "    public void setBonus(double bonus) {", "        this.bonus = bonus;", "    }", "", "    public double getDeductions() {", "        return deductions;", "    }", "", "    public void setDeductions(double deductions) {", "        this.deductions = deductions;", "    }", "", "    public double getNetSalary() {", "        return netSalary;", "    }", "", "    public void setNetSalary(double netSalary) {", "        this.netSalary = netSalary;", "    }", "", "    public double getTaxDeduction() {", "        return taxDeduction;", "    }", "", "    public void setTaxDeduction(double taxDeduction) {", "        this.taxDeduction = taxDeduction;", "    }", "}"], "file_path": "multiple-file/java/Employee.java"}
{"Link_to_commit": "https://github.com/Cloud-Solutions-International/antikythera/commit/fca563f284f1a6eba21bffc2d78166ed325a3e42", "n-gram matched": "generated by copilot", "n_lines_longer_change": 59, "n_files_impacted": 1, "longest_chunk": ["", "", "class VariableInitializationModifierTest {", "", "    @Test", "    void shouldModifySimpleVariableInitialization() {", "        String code = \"\"\"", "            public void testMethod() {", "                String test = \"old\";", "                int other = 5;", "            }", "            \"\"\";", "        MethodDeclaration method = StaticJavaParser.parseMethodDeclaration(code);", "        StringLiteralExpr newValue = new StringLiteralExpr(\"new\");", "", "        VariableInitializationModifier modifier = new VariableInitializationModifier(\"test\", newValue);", "        MethodDeclaration result = (MethodDeclaration) modifier.visit(method, null);", "", "        assertTrue(result.toString().contains(\"String test = \\\"new\\\"\"));", "        assertTrue(result.toString().contains(\"int other = 5\"));", "    }", "", "    @Test", "    void shouldNotModifyWhenVariableNotFound() {", "        String code = \"\"\"", "            public void testMethod() {", "                String existingVar = \"old\";", "            }", "            \"\"\";", "        MethodDeclaration method = StaticJavaParser.parseMethodDeclaration(code);", "        IntegerLiteralExpr newValue = new IntegerLiteralExpr(\"42\");", "", "        VariableInitializationModifier modifier = new VariableInitializationModifier(\"nonexistentVar\", newValue);", "        MethodDeclaration result = (MethodDeclaration) modifier.visit(method, null);", "", "        assertEquals(method.toString(), result.toString());", "    }", "", "    @Test", "    void shouldModifyFirstOccurrenceOnly() {", "        String code = \"\"\"", "            public void testMethod() {", "                int target = 1;", "                String other = \"middle\";", "                int target = 3;", "            }", "            \"\"\";", "        MethodDeclaration method = StaticJavaParser.parseMethodDeclaration(code);", "        IntegerLiteralExpr newValue = new IntegerLiteralExpr(\"42\");", "", "        VariableInitializationModifier modifier = new VariableInitializationModifier(\"target\", newValue);", "        MethodDeclaration result = (MethodDeclaration) modifier.visit(method, null);", "", "        String modifiedCode = result.toString();", "        assertTrue(modifiedCode.contains(\"int target = 42\"));", "        assertTrue(modifiedCode.contains(\"int target = 3\"));", "        assertEquals(1, modifiedCode.split(\"42\").length - 1);", "    }", "}"], "file_path": "src/test/java/sa/com/cloudsolutions/antikythera/generator/UnitTestGeneratorTest.java"}
{"Link_to_commit": "https://github.com/Rabin-Kalikote/fast-html-todo-app/commit/53cb66f1aa75747ae2d2271829928a10dd780cca", "n-gram matched": "generated by copilot", "n_lines_longer_change": 56, "n_files_impacted": 14, "longest_chunk": ["// This file contains the JavaScript code for client-side interactions in the todo tracker app.", "", "document.addEventListener('DOMContentLoaded', function() {", "    const addTodoForm = document.getElementById('add-todo-form');", "    const todoList = document.getElementById('todo-list');", "", "    addTodoForm.addEventListener('submit', function(event) {", "        event.preventDefault();", "        const title = document.getElementById('todo-title').value;", "        const body = document.getElementById('todo-body').value;", "        const dueDate = document.getElementById('todo-due-date').value;", "", "        // Add new todo item", "        fetch('/todos', {", "            method: 'POST',", "            headers: {", "                'Content-Type': 'application/json'", "            },", "            body: JSON.stringify({ title, body, due_date: dueDate })", "        })", "        .then(response => response.json())", "        .then(data => {", "            // Append new todo item to the list", "            const todoItem = document.createElement('li');", "            todoItem.textContent = `${data.title} - ${data.body}`;", "            todoList.appendChild(todoItem);", "            addTodoForm.reset();", "        });", "    });", "", "    // Function to filter todos by completion status", "    document.getElementById('filter-completed').addEventListener('change', function() {", "        const showCompleted = this.checked;", "        const todos = todoList.getElementsByTagName('li');", "        for (let todo of todos) {", "            if (showCompleted && !todo.classList.contains('completed')) {", "                todo.style.display = 'none';", "            } else {", "                todo.style.display = 'list-item';", "            }", "        }", "    });", "", "    // Function to sort todos by creation date or due date", "    document.getElementById('sort-todos').addEventListener('change', function() {", "        const sortBy = this.value;", "        const todosArray = Array.from(todoList.getElementsByTagName('li'));", "        todosArray.sort((a, b) => {", "            const aDate = new Date(a.dataset.creationTime);", "            const bDate = new Date(b.dataset.creationTime);", "            return sortBy === 'due_date' ? aDate - bDate : bDate - aDate;", "        });", "        todoList.innerHTML = '';", "        todosArray.forEach(todo => todoList.appendChild(todo));", "    });", "});"], "file_path": "src/static/main.js"}
{"Link_to_commit": "https://github.com/jacekkowalczyk82/technology-startup/commit/e93cc5c58673f6867840b9e7dca69bcf976b3af5", "n-gram matched": "generated by copilot", "n_lines_longer_change": 79, "n_files_impacted": 3, "longest_chunk": ["package main", "", "import (", "    \"encoding/base64\"", "    \"fmt\"", "    \"io/ioutil\"", "    \"os\"", ")", "", "// EncodeFile encodes the content of the input file and writes it to the output file", "func EncodeFile(inputFile, outputFile string) error {", "    data, err := ioutil.ReadFile(inputFile)", "    if err != nil {", "        return fmt.Errorf(\"failed to read file: %w\", err)", "    }", "", "    encodedData := base64.StdEncoding.EncodeToString(data)", "", "    err = ioutil.WriteFile(outputFile, []byte(encodedData), 0644)", "    if err != nil {", "        return fmt.Errorf(\"failed to write file: %w\", err)", "    }", "", "    return nil", "}", "", "// DecodeFile decodes the base64 content of the input file and writes it to the output file", "func DecodeFile(inputFile, outputFile string) error {", "    data, err := ioutil.ReadFile(inputFile)", "    if err != nil {", "        return fmt.Errorf(\"failed to read file: %w\", err)", "    }", "", "    decodedData, err := base64.StdEncoding.DecodeString(string(data))", "    if err != nil {", "        return fmt.Errorf(\"failed to decode base64 data: %w\", err)", "    }", "", "    err = ioutil.WriteFile(outputFile, decodedData, 0644)", "    if err != nil {", "        return fmt.Errorf(\"failed to write file: %w\", err)", "    }", "", "    return nil", "}", "", "func ShowUsage() {", "    fmt.Println(\"Usage:\")", "    fmt.Println(\"  go-base64 encode <input file> <output file>\")", "    fmt.Println(\"  go-base64 decode <input file> <output file>\")", "}", "", "func main() {", "    if len(os.Args) < 4 {", "        ShowUsage()", "        return", "    }", "", "    command := os.Args[1]", "    inputFile := os.Args[2]", "    outputFile := os.Args[3]", "", "    var err error", "    switch command {", "    case \"encode\":", "        err = EncodeFile(inputFile, outputFile)", "    case \"decode\":", "        err = DecodeFile(inputFile, outputFile)", "    default:", "        ShowUsage()", "        return", "    }", "", "    if err != nil {", "        fmt.Printf(\"Error: %v\\n\", err)", "    } else {", "        fmt.Printf(\"Success: %s completed\\n\", command)", "    }", "}"], "file_path": "go-base64/go-base64.go"}
{"Link_to_commit": "https://github.com/alexgalkin/goal-tracking/commit/2083a2279ffd9f39593e6cc095edc51844200d51", "n-gram matched": "generated by copilot", "n_lines_longer_change": 20, "n_files_impacted": 11, "longest_chunk": ["import { initializeApp } from \"firebase/app\";", "import { getFirestore } from \"firebase/firestore\";", "import { getAuth } from \"firebase/auth\";", "import { getAnalytics } from \"firebase/analytics\";", "", "const firebaseConfig = {", "    apiKey: \"YOUR_API_KEY\",", "    authDomain: \"YOUR_PROJECT_ID.firebaseapp.com\",", "    projectId: \"YOUR_PROJECT_ID\",", "    storageBucket: \"YOUR_PROJECT_ID.appspot.com\",", "    messagingSenderId: \"YOUR_MESSAGING_SENDER_ID\",", "    appId: \"YOUR_APP_ID\"", "};", "", "const app = initializeApp(firebaseConfig);", "const db = getFirestore(app);", "const auth = getAuth(app);", "const analytics = getAnalytics(app);", "", "export { db, auth };"], "file_path": "bimbink-web-app/src/firebase.js"}
{"Link_to_commit": "https://github.com/zetaloop/desktop/commit/adc4bcc2305725673bb8622a6680377545b853ad", "n-gram matched": "generated by copilot", "n_lines_longer_change": 5, "n_files_impacted": 2, "longest_chunk": ["  /**", "   * Whether or not the message was generated by Copilot", "   * (optional, default: false)", "   */", "  readonly messageGeneratedByCopilot?: boolean"], "file_path": "app/src/models/commit.ts"}
{"Link_to_commit": "https://github.com/DCRT-LUMC/Tandem-Repeat-Domain-Database/commit/16d7318b1ef4c0c3e7affc150731341a51e5fb33", "n-gram matched": "generated by copilot", "n_lines_longer_change": 270, "n_files_impacted": 6, "longest_chunk": ["import json", "import sqlite3", "import os", "from tqdm import tqdm  # For progress bars", "", "def populate_test_database(json_file, db_file):", "    \"\"\"Populate SQLite database from the repeat domain JSON file\"\"\"", "    print(f\"Creating database from {json_file}...\")", "    ", "    # Connect to SQLite DB", "    conn = sqlite3.connect(db_file)", "    cursor = conn.cursor()", "    ", "    # Create tables using schema file", "    # Get the directory of the script to find the schema file", "    script_dir = os.path.dirname(os.path.abspath(__file__))", "    schema_file_path = os.path.join(script_dir, \"database_schema.sql\")", "    ", "    with open(schema_file_path, \"r\") as schema_file:", "        schema = schema_file.read()", "        conn.executescript(schema)", "    ", "    # Load JSON data", "    with open(json_file, \"r\") as f:", "        data = json.load(f)", "    ", "    # Track processed IDs to avoid duplicates", "    processed_genes = {}", "    processed_proteins = {}", "    processed_transcripts = {}", "    processed_exons = {}", "", "    # Process each repeat entry", "    for repeat in tqdm(data, desc=\"Processing repeats\"):", "        if not isinstance(repeat, dict) or not repeat:", "            continue  # Skip empty entries", "        ", "        # Get gene info", "        gene_name = repeat.get(\"geneName\", \"\")", "        if not gene_name:", "            continue", "        ", "        # Insert gene if not already processed", "        if gene_name not in processed_genes:", "            aliases = repeat.get(\"aliases\", \"\")", "            if isinstance(aliases, list):", "                aliases = \",\".join(aliases)", "            ", "            cursor.execute(\"\"\"", "                INSERT INTO genes (gene_name, aliases, chromosome, location)", "                VALUES (?, ?, ?, ?)", "            \"\"\", (", "                gene_name,", "                aliases,", "                repeat.get(\"chrom\", \"\"),", "                f\"{repeat.get('chrom', '')}:{repeat.get('chromStart', '')}_{repeat.get('chromEnd', '')}\"", "            ))", "            processed_genes[gene_name] = cursor.lastrowid", "        ", "        gene_id = processed_genes[gene_name]", "        ", "        # Process protein", "        uniprot_id = repeat.get(\"uniProtId\", \"\")", "        if uniprot_id and uniprot_id not in processed_proteins:", "            status = repeat.get(\"status\", \"\")", "            ", "            # Extract length from position if possible: \"amino acids 343-389 on protein Q6TDP4\"", "            position = repeat.get(\"position\", \"\")", "            length = 0", "            if position and isinstance(position, str):", "                try:", "                    parts = position.split()", "                    if len(parts) >= 3:", "                        pos = parts[2].split(\"-\")", "                        if len(pos) == 2:", "                            length = int(pos[1]) - int(pos[0]) + 1", "                except:", "                    pass", "            ", "            cursor.execute(\"\"\"", "                INSERT INTO proteins (protein_id, gene_id, length, description, status)", "                VALUES (?, ?, ?, ?, ?)", "            \"\"\", (", "                uniprot_id,", "                gene_id,", "                length,", "                f\"Protein for {gene_name}\",", "                status", "            ))", "            processed_proteins[uniprot_id] = uniprot_id", "        ", "        # Process repeat domain", "        amino_start = None", "        amino_end = None", "        if repeat.get(\"position\") and isinstance(repeat.get(\"position\"), str):", "            position = repeat.get(\"position\")", "            try:", "                # Extract positions from \"amino acids 343-389 on protein Q6TDP4\"", "                parts = position.split()", "                if len(parts) >= 3:", "                    pos = parts[2].split(\"-\")", "                    if len(pos) == 2:", "                        amino_start = int(pos[0])", "                        amino_end = int(pos[1])", "            except:", "                pass", "        ", "        # Calculate sequence length from blockSizes", "        sequence_length = 0", "        block_sizes = repeat.get(\"blockSizes\", [])", "        if isinstance(block_sizes, list):", "            for size in block_sizes:", "                try:", "                    sequence_length += int(size)", "                except:", "                    pass", "        ", "        # Insert repeat", "        cursor.execute(\"\"\"", "            INSERT INTO repeats (protein_id, repeat_type, start_pos, end_pos, sequence)", "            VALUES (?, ?, ?, ?, ?)", "        \"\"\", (", "            uniprot_id,", "            repeat.get(\"repeatType\", \"\"),", "            amino_start,", "            amino_end,", "            \"N\" * sequence_length  # Placeholder sequence of Ns", "        ))", "        repeat_id = cursor.lastrowid", "        ", "        # Process exon information if available", "        if \"ensembl_exon_info\" not in repeat:", "            continue", "            ", "        exon_info = repeat.get(\"ensembl_exon_info\", {})", "        if not exon_info or \"transcripts\" not in exon_info:", "            continue", "            ", "        # Process each transcript", "        for transcript_data in exon_info.get(\"transcripts\", []):", "            transcript_id = transcript_data.get(\"transcript_id\")", "            if not transcript_id:", "                continue", "                ", "            # Insert transcript if not already processed", "            if transcript_id not in processed_transcripts:", "                cursor.execute(\"\"\"", "                    INSERT INTO transcripts (transcript_id, gene_id, description)", "                    VALUES (?, ?, ?)", "                \"\"\", (", "                    transcript_id,", "                    gene_id,", "                    f\"{transcript_data.get('transcript_name', '')} ({transcript_data.get('biotype', '')})\"", "                ))", "                processed_transcripts[transcript_id] = transcript_id", "            ", "            # Create repeat_transcript relationship", "            genomic_start = repeat.get(\"chromStart\", 0)", "            genomic_end = repeat.get(\"chromEnd\", 0)", "            ", "            # Convert exon mapping to JSON string", "            exon_mapping = json.dumps([", "                {", "                    \"exon_id\": exon.get(\"exon_id\", \"\"),", "                    \"exon_number\": exon.get(\"exon_number\", 0),", "                    \"overlap_bp\": exon.get(\"overlap_bp\", 0),", "                    \"overlap_percentage\": exon.get(\"overlap_percentage\", 0),", "                    \"coding_percentage\": exon.get(\"coding_percentage\", 0)", "                } for exon in transcript_data.get(\"containing_exons\", [])", "            ])", "            ", "            cursor.execute(\"\"\"", "                INSERT INTO repeat_transcripts (", "                    repeat_id, transcript_id, genomic_start, genomic_end, exon_mapping", "                ) VALUES (?, ?, ?, ?, ?)", "            \"\"\", (", "                repeat_id, ", "                transcript_id, ", "                genomic_start, ", "                genomic_end, ", "                exon_mapping", "            ))", "            ", "            # Process exons in this transcript", "            for exon_data in transcript_data.get(\"containing_exons\", []):", "                exon_id = exon_data.get(\"exon_id\")", "                if not exon_id or exon_id in processed_exons:", "                    continue", "                    ", "                # Estimate exon size from overlap percentage", "                exon_size = 0", "                if exon_data.get(\"overlap_percentage\") and exon_data.get(\"overlap_bp\"):", "                    try:", "                        exon_size = int(exon_data.get(\"overlap_bp\") * 100 / exon_data.get(\"overlap_percentage\"))", "                    except:", "                        pass", "                ", "                # Calculate if skipping would preserve reading frame", "                frame_preserving = exon_size % 3 == 0", "                ", "                cursor.execute(\"\"\"", "                    INSERT INTO exons (", "                        exon_id, gene_id, length, frame_preserving", "                    ) VALUES (?, ?, ?, ?)", "                \"\"\", (", "                    exon_id,", "                    gene_id,", "                    exon_size,", "                    frame_preserving", "                ))", "                processed_exons[exon_id] = exon_id", "                ", "                # Create transcript_exon relationship", "                cursor.execute(\"\"\"", "                    INSERT INTO transcript_exons (", "                        transcript_id, exon_id, exon_number", "                    ) VALUES (?, ?, ?)", "                \"\"\", (", "                    transcript_id,", "                    exon_id,", "                    exon_data.get(\"exon_number\", 0)", "                ))", "                ", "                # Create repeat_exon relationship", "                cursor.execute(\"\"\"", "                    INSERT INTO repeat_exons (", "                        repeat_id, exon_id, overlap_bp, overlap_percentage", "                    ) VALUES (?, ?, ?, ?)", "                \"\"\", (", "                    repeat_id,", "                    exon_id,", "                    exon_data.get(\"overlap_bp\", 0),", "                    exon_data.get(\"overlap_percentage\", 0)", "                ))", "    ", "    # Commit all changes", "    conn.commit()", "    ", "    # Print some statistics", "    cursor.execute(\"SELECT COUNT(*) FROM genes\")", "    gene_count = cursor.fetchone()[0]", "    ", "    cursor.execute(\"SELECT COUNT(*) FROM proteins\")", "    protein_count = cursor.fetchone()[0]", "    ", "    cursor.execute(\"SELECT COUNT(*) FROM repeats\")", "    repeat_count = cursor.fetchone()[0]", "    ", "    cursor.execute(\"SELECT COUNT(*) FROM exons\")", "    exon_count = cursor.fetchone()[0]", "    ", "    print(f\"\\nDatabase populated successfully:\")", "    print(f\"  - {gene_count} genes\")", "    print(f\"  - {protein_count} proteins\")", "    print(f\"  - {repeat_count} repeat domains\")", "    print(f\"  - {exon_count} exons\")", "    ", "    conn.close()", "    ", "    print(f\"\\nDatabase created at: {db_file}\")", "", "if __name__ == \"__main__\":", "    # Define file paths - simplified to use the same directory as the script", "    script_dir = os.path.dirname(os.path.abspath(__file__))", "    ", "    json_file = os.path.join(script_dir, \"1000_test_exons_hg38_repeats.json\")", "    db_file = os.path.join(script_dir, \"tandem_repeats.db\")", "    ", "    # Create the database", "    populate_test_database(json_file, db_file)"], "file_path": "test_sqlite/populate_database.py"}
{"Link_to_commit": "https://github.com/goatstone/aaarto_backend/commit/0f7bd6630dcaaf8e6a8bd80e79bbff8239936463", "n-gram matched": "generated by copilot", "n_lines_longer_change": 28, "n_files_impacted": 4, "longest_chunk": ["/** ", " * Use environment variables to provide arguments ", " * export contractAddress=\"\"", " * export spender=\"\"", " * export amount=\"\"", " * Run the script with hardhat run ", " * npx hardhat run scripts/approveTokens.ts --network sepolia ", " */", "import { ethers } from \"hardhat\";", "", "async function approveTokens(contractAddress: string, spender: string, amount: string) {", "  const GLDToken = await ethers.getContractFactory(\"GLDToken\");", "  const token = GLDToken.attach(contractAddress);", "", "  const tx = await token.approve(spender, ethers.utils.parseUnits(amount, 18));", "  console.log(`Approved ${amount} GLD for ${spender}. Transaction hash: ${tx.hash}`);", "}", "", "const contractAddress = process.env.contractAddress as string;", "const spender = process.env.spender as string;", "const amount = process.env.amount as string;", "", "approveTokens(contractAddress, spender, amount)", "  .then(() => process.exit(0))", "  .catch((error) => {", "    console.error(error);", "    process.exit(1);", "  });"], "file_path": "scripts/checkAllowance.ts"}
{"Link_to_commit": "https://github.com/zereight/confluence-mcp/commit/a424d7c23b831ee020be5a33eb1f5fc678ff2dbc", "n-gram matched": "generated by copilot", "n_lines_longer_change": 36, "n_files_impacted": 7, "longest_chunk": ["{", "  \"name\": \"@zereight/mcp-confluence\",", "  \"version\": \"1.0.1\",", "  \"description\": \"MCP server for using the Confluence API\",", "  \"license\": \"MIT\",", "  \"author\": \"zereight\",", "  \"type\": \"module\",", "  \"private\": false,", "  \"bin\": \"./build/index.js\",", "  \"files\": [", "    \"build\"", "  ],", "  \"publishConfig\": {", "    \"access\": \"public\"", "  },", "  \"engines\": {", "    \"node\": \">=14\"", "  },", "  \"scripts\": {", "    \"build\": \"tsc && node -e \\\"require('fs').chmodSync('build/index.js', '755')\\\"\",", "    \"prepare\": \"npm run build\",", "    \"watch\": \"tsc --watch\",", "    \"inspector\": \"npx @modelcontextprotocol/inspector build/index.js\",", "    \"start\": \"node build/index.js\"", "  },", "  \"dependencies\": {", "    \"@modelcontextprotocol/sdk\": \"0.6.0\",", "    \"axios\": \"^1.7.9\",", "    \"mcp-framework\": \"^0.1.12\",", "    \"okhttp\": \"^1.1.0\"", "  },", "  \"devDependencies\": {", "    \"@types/node\": \"^20.11.24\",", "    \"typescript\": \"^5.7.2\"", "  }", "}"], "file_path": "src/index.ts"}
{"Link_to_commit": "https://github.com/Byloth/core/commit/c15edeb04b9f3f2b26c474c1a75eba2b0e0bb07d", "n-gram matched": "generated by copilot", "n_lines_longer_change": 53, "n_files_impacted": 2, "longest_chunk": ["import { describe, it, expect } from \"vitest\";", "", "import { SmartIterator, ValueException } from \"../../src/index.js\";", "import { Curve } from \"../../src/index.js\";", "", "describe(\"Curve\", () =>", "{", "    describe(\"Linear\", () =>", "    {", "        it(\"Should return an instance of `SmartIterator`\", () =>", "        {", "            const iterator = Curve.Linear(5);", "", "            expect(iterator).toBeInstanceOf(SmartIterator);", "        });", "        it(\"Should generate a linear sequence of values\", () =>", "        {", "            const values = Array.from(Curve.Linear(5));", "", "            expect(values).toEqual([0, 0.25, 0.5, 0.75, 1]);", "        });", "    });", "", "    describe(\"Exponential\", () =>", "    {", "        it(\"Should return an instance of `SmartIterator`\", () =>", "        {", "            const iterator = Curve.Exponential(6);", "", "            expect(iterator).toBeInstanceOf(SmartIterator);", "        });", "", "        it(\"Should generate an exponential sequence of values with default base\", () =>", "        {", "            const values = Array.from(Curve.Exponential(6));", "", "            expect(values).toEqual([0, 0.04000000000000001, 0.16000000000000003, 0.36, 0.6400000000000001, 1]);", "        });", "        it(\"Should generate an exponential sequence of values with custom base\", () =>", "        {", "            const values = Array.from(Curve.Exponential(6, 3));", "", "            expect(values).toEqual(", "                [0, Math.pow(1 / 5, 3), Math.pow(2 / 5, 3), Math.pow(3 / 5, 3), Math.pow(4 / 5, 3), 1]", "            );", "        });", "", "        it(\"Should throw a `ValueException` if base is negative\", () =>", "        {", "            expect(() => Curve.Exponential(6, -1)).toThrow(ValueException);", "        });", "    });", "});"], "file_path": "tests/utils/date.test.ts"}
{"Link_to_commit": "https://github.com/mg3-codes/d-d-spell-finder/commit/48e7987d31802f7be98db844892af2fd9e69169d", "n-gram matched": "generated by copilot", "n_lines_longer_change": 15, "n_files_impacted": 33, "longest_chunk": ["\t/**", "\t * Maps the value of the proficiency die to the corresponding array of `EdgeOfTheEmpireDiceSymbol` results.", "\t *", "\t * @returns {EdgeOfTheEmpireDiceSymbol[]} An array of `EdgeOfTheEmpireDiceSymbol` representing the result of the die roll.", "\t *", "\t * The mapping is as follows:", "\t * - 1: Blank", "\t * - 2, 3: Success", "\t * - 4, 5: Success, Success", "\t * - 6: Advantage", "\t * - 7, 8, 9: Success, Advantage", "\t * - 10, 11: Advantage, Advantage", "\t * - 12: Triumph", "\t * - Default: Empty array", "\t */"], "file_path": "src/classes/edge-of-the-empire-dice/proficiency-die.ts"}
{"Link_to_commit": "https://github.com/j2willey/GiftExchangeTimer/commit/a2ce3941a6bda7ac3e0bbd079aa08e6afd322b05", "n-gram matched": "generated by copilot", "n_lines_longer_change": 54, "n_files_impacted": 5, "longest_chunk": ["document.getElementById('createTimers').addEventListener('click', function() {", "    const numTimers = parseInt(document.getElementById('numTimers').value);", "    const defaultTime = parseInt(document.getElementById('defaultTime').value);", "    const timersContainer = document.getElementById('timersContainer');", "    timersContainer.innerHTML = '';", "", "    for (let i = 1; i <= numTimers; i++) {", "        const timerDiv = document.createElement('div');", "        timerDiv.className = 'timer';", "        timerDiv.innerHTML = `", "            <input type=\"text\" value=\"${i}\">", "            <div class=\"time\">${defaultTime}</div>", "            <div class=\"buttons\">", "                <button class=\"start\">Start</button>", "                <button class=\"pause\">Pause</button>", "                <button class=\"reset\">Reset</button>", "            </div>", "        `;", "        timersContainer.appendChild(timerDiv);", "", "        const timeDisplay = timerDiv.querySelector('.time');", "        let timeLeft = defaultTime;", "        let interval;", "", "        timerDiv.querySelector('.start').addEventListener('click', function() {", "            if (interval) return;", "            interval = setInterval(() => {", "                if (timeLeft > 0) {", "                    timeLeft--;", "                    timeDisplay.textContent = timeLeft;", "                    if (timeLeft <= 10) {", "                        timeDisplay.classList.add('warning');", "                    }", "                } else {", "                    clearInterval(interval);", "                    timeDisplay.textContent = 'Times Up!';", "                }", "            }, 1000);", "        });", "", "        timerDiv.querySelector('.pause').addEventListener('click', function() {", "            clearInterval(interval);", "            interval = null;", "        });", "", "        timerDiv.querySelector('.reset').addEventListener('click', function() {", "            clearInterval(interval);", "            interval = null;", "            timeLeft = defaultTime;", "            timeDisplay.textContent = timeLeft;", "            timeDisplay.classList.remove('warning');", "        });", "    }", "});"], "file_path": "js/timers.js"}
{"Link_to_commit": "https://github.com/kimjeffsj/empcon_backend/commit/6277914de02416970a0724fabbf7cb6686fe4e18", "n-gram matched": "generated by copilot", "n_lines_longer_change": 11, "n_files_impacted": 1, "longest_chunk": ["", "    req.user = {", "      userId: decoded.userId,", "      role: decoded.role,", "    };", "", "    next();", "  } catch (error) {", "    logger.error(\"JWT verification failed\", { error });", "    return next(new UnauthorizedError(\"Invalid or expired token\"));", "  }"], "file_path": "src/common/middleware/auth.middleware.ts"}
{"Link_to_commit": "https://github.com/yeohwk/calculator/commit/6bb72c18063d9e6c6618b635b123d81e2e6c6897", "n-gram matched": "generated by copilot", "n_lines_longer_change": 11, "n_files_impacted": 1, "longest_chunk": ["import numpy as np", "", "def generate_hilbert_matrix(size):", "    \"\"\"Generates a Hilbert matrix of given size.\"\"\"", "    hilbert_matrix = np.array([[1 / (i + j + 1) for j in range(size)] for i in range(size)])", "    return hilbert_matrix", "", "if __name__ == \"__main__\":", "    size = 12", "    hilbert_matrix = generate_hilbert_matrix(size)", "    print(hilbert_matrix)"], "file_path": "hilbert12.py"}
{"Link_to_commit": "https://github.com/yeohwk/calculator/commit/0f23585f11a4482a8b65802a8802c9d5f8d473c5", "n-gram matched": "generated by copilot", "n_lines_longer_change": 65, "n_files_impacted": 1, "longest_chunk": ["import math", "", "def text_based_calculator():", "    while True:", "        print(\"\\nSelect operation:\")", "        print(\"1. Addition (+)\")", "        print(\"2. Subtraction (-)\")", "        print(\"3. Multiplication (*)\")", "        print(\"4. Division (/)\")", "        print(\"5. Trigonometry (sin, cos, tan)\")", "        print(\"6. Square Root (sqrt)\")", "        print(\"7. Square (sq)\")", "        print(\"8. Exponential (exp)\")", "        print(\"9. Exit\")", "", "        choice = input(\"Enter choice: \")", "", "        if choice == '9':", "            break", "", "        if choice in ['1', '2', '3', '4']:", "            num1 = float(input(\"Enter first number: \"))", "            num2 = float(input(\"Enter second number: \"))", "", "            if choice == '1':", "                print(\"Result:\", num1 + num2)", "            elif choice == '2':", "                print(\"Result:\", num1 - num2)", "            elif choice == '3':", "                print(\"Result:\", num1 * num2)", "            elif choice == '4':", "                if num2 != 0:", "                    print(\"Result:\", num1 / num2)", "                else:", "                    print(\"Error: Division by zero\")", "", "        elif choice in ['5']:", "            trig_operation = input(\"Enter trigonometric function (sin, cos, tan): \")", "            angle = float(input(\"Enter angle in radians: \"))", "            if trig_operation == 'sin':", "                print(\"Result:\", math.sin(angle))", "            elif trig_operation == 'cos':", "                print(\"Result:\", math.cos(angle))", "            elif trig_operation == 'tan':", "                print(\"Result:\", math.tan(angle))", "            else:", "                print(\"Invalid trigonometric function\")", "", "        elif choice == '6':", "            num = float(input(\"Enter number: \"))", "            print(\"Result:\", math.sqrt(num))", "", "        elif choice == '7':", "            num = float(input(\"Enter number: \"))", "            print(\"Result:\", num * num)", "", "        elif choice == '8':", "            num = float(input(\"Enter number: \"))", "            print(\"Result:\", math.exp(num))", "", "        else:", "            print(\"Invalid choice\")", "", "if __name__ == \"__main__\":", "    text_based_calculator()"], "file_path": "calc2.py"}
{"Link_to_commit": "https://github.com/jaluebbe/GPSTracker/commit/53b89f640b9b4b4c3bc713ce9bd977a1b97ecd3f", "n-gram matched": "generated by copilot", "n_lines_longer_change": 16, "n_files_impacted": 1, "longest_chunk": ["        ['e2', 8], ['e2', 8], ['p', 8], ['e2', 8], ['p', 8], ['c2', 8], ['e2', 8],", "        ['g2', 4], ['p', 4], ['g1', 4], ['p', 4],", "        ['c2', 4], ['p', 8], ['g1', 8], ['g1', 8], ['p', 8], ['e1', 4],", "        ['p', 8], ['a1', 4], ['h1', 8], ['h1', 8], ['ais1', 8], ['ais1', 4],", "        ['g1', 6], ['e2', 6], ['g2', 6], ['a2', 4], ['f2', 8], ['g2', 8],", "        ['p', 8], ['e2', 4], ['c2', 8], ['d2', 8], ['h1', 4], ['p', 8],", "        ['c2', 4], ['p', 8], ['g1', 8], ['g1', 8], ['p', 8], ['e1', 4],", "        ['p', 4], ['a1', 4], ['h1', 8], ['h1', 8], ['ais1', 8], ['ais1', 4],", "        ['g1', 6], ['e2', 6], ['g2', 6], ['a2', 4], ['f2', 8], ['g2', 8],", "        ['p', 8], ['e2', 4], ['c2', 8], ['d2', 8], ['h1', 4], ['p', 8],", "        ['p', 4], ['g2', 8], ['fis2', 8], ['fis2', 8], ['dis2', 4], ['e2', 8],", "        ['p', 8], ['gis1', 8], ['a1', 8], ['c2', 8], ['p', 8], ['a1', 8], ['c2', 8], ['d2', 8],", "        ['p', 4], ['g2', 8], ['fis2', 8], ['fis2', 8], ['dis2', 4], ['e2', 8],", "        ['p', 8], ['c3', 4], ['c3', 8], ['c3', 4], ['p', 4],", "        ['p', 4], ['g2', 8], ['fis2', 8], ['fis2', 8], ['dis2', 4], ['e2', 8],", "        ['p', 8], ['gis1', 8], ['a1', 8], ['c2', 8], ['p', 8], ['a1', 8], ['c2', 8], ['d2', 8],"], "file_path": "static/music.js"}
{"Link_to_commit": "https://github.com/ajaysskumar/dev-arena/commit/cfdeba944cd1abe1b31e871226ab444b16729d8c", "n-gram matched": "generated by copilot", "n_lines_longer_change": 5, "n_files_impacted": 2, "longest_chunk": ["        new(\"Understanding the Single Responsibility Principle\",", "            \"/blog/software-practices-solid-srp\",", "            new DateTime(2025, 5, 10),", "            \"images/blog/software-practices/solid-srp/banner.png\",", "            [\"Software Practices\", \"SOLID\", \"SRP\"], false),"], "file_path": "TestArena/Blog/Common/NavigationUtils/SiteMap.cs"}
{"Link_to_commit": "https://github.com/kimjeffsj/starclone-backend/commit/7a95c1a723bde3e0b2edf7e373b953edd2962550", "n-gram matched": "generated by copilot", "n_lines_longer_change": 144, "n_files_impacted": 3, "longest_chunk": ["import { NextFunction, Request, Response } from \"express\";", "import { FollowService } from \"../services/follow.service\";", "import { followUserSchema } from \"../validations/follow.schema\";", "import { UnauthorizedError, ValidationError } from \"@/utils/errors.utils\";", "", "export class FollowController {", "  private followService = new FollowService();", "", "  /**", "   * Follow a user", "   */", "  followUser = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      if (!req.user || !req.user.id) {", "        throw new UnauthorizedError(\"Not authenticated\");", "      }", "", "      const validationResult = followUserSchema.safeParse(req.body);", "      if (!validationResult.success) {", "        throw new ValidationError(validationResult.error.format());", "      }", "", "      const result = await this.followService.followUser(", "        req.user.id,", "        validationResult.data.username", "      );", "", "      res.status(200).json({", "        message: \"Successfully followed user\",", "        ...result,", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Unfollow a user", "   */", "  unfollowUser = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      if (!req.user || !req.user.id) {", "        throw new UnauthorizedError(\"Not authenticated\");", "      }", "", "      const { username } = req.params;", "", "      const result = await this.followService.unfollowUser(", "        req.user.id,", "        username", "      );", "", "      res.status(200).json({", "        message: \"Successfully unfollowed user\",", "        ...result,", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Check follow status", "   */", "  checkFollowStatus = async (", "    req: Request,", "    res: Response,", "    next: NextFunction", "  ) => {", "    try {", "      if (!req.user || !req.user.id) {", "        throw new UnauthorizedError(\"Not authenticated\");", "      }", "", "      const { username } = req.params;", "", "      const result = await this.followService.checkFollowStatus(", "        req.user.id,", "        username", "      );", "", "      res.status(200).json(result);", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Get followers of a user", "   */", "  getFollowers = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { username } = req.params;", "      const page = req.query.page ? parseInt(req.query.page as string) : 1;", "      const limit = req.query.limit ? parseInt(req.query.limit as string) : 20;", "", "      const result = await this.followService.getFollowers(", "        username,", "        page,", "        limit", "      );", "", "      res.status(200).json(result);", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Get users that a user is following", "   */", "  getFollowing = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { username } = req.params;", "      const page = req.query.page ? parseInt(req.query.page as string) : 1;", "      const limit = req.query.limit ? parseInt(req.query.limit as string) : 20;", "", "      const result = await this.followService.getFollowing(", "        username,", "        page,", "        limit", "      );", "", "      res.status(200).json(result);", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Get follow counts", "   */", "  getFollowCounts = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { username } = req.params;", "", "      const result = await this.followService.getFollowCounts(username);", "", "      res.status(200).json(result);", "    } catch (error) {", "      next(error);", "    }", "  };", "}"], "file_path": "src/features/follow/index.ts"}
{"Link_to_commit": "https://github.com/kimjeffsj/starclone-backend/commit/417e320954c74f1f0c44eb36760f0f138c1ebf86", "n-gram matched": "generated by copilot", "n_lines_longer_change": 200, "n_files_impacted": 4, "longest_chunk": ["import { AppDataSource } from \"@/config/database\";", "import { Follow } from \"@/entities/Follow.entity\";", "import { User } from \"@/entities/User.entity\";", "import { ForbiddenError, NotFoundError } from \"@/utils/errors.utils\";", "", "export class FollowService {", "  private followRepository = AppDataSource.getRepository(Follow);", "  private userRepository = AppDataSource.getRepository(User);", "", "  /**", "   * Follow user", "   */", "  async followUser(followerUserId: string, usernameToFollow: string) {", "    // Find follower", "    const follower = await this.userRepository.findOneBy({", "      id: followerUserId,", "    });", "    if (!follower) {", "      throw new NotFoundError(\"User not found\");", "    }", "", "    // Find user to follow", "    const userToFollow = await this.userRepository.findOneBy({", "      username: usernameToFollow,", "    });", "    if (!userToFollow) {", "      throw new NotFoundError(\"User to follow not found\");", "    }", "", "    // Cannot follow yourself", "    if (follower.id === userToFollow.id) {", "      throw new ForbiddenError(\"You cannot follow yourself\");", "    }", "", "    // Check if already following", "    const existingFollow = await this.followRepository.findOne({", "      where: {", "        follower: { id: followerUserId },", "        following: { id: userToFollow.id },", "      },", "    });", "", "    if (existingFollow) {", "      throw new ForbiddenError(\"You are already following this user\");", "    }", "", "    // Create follow relation", "    const follow = this.followRepository.create({", "      follower,", "      following: userToFollow,", "    });", "", "    await this.followRepository.save(follow);", "", "    return { success: true };", "  }", "", "  /**", "   * Unfollow a user", "   */", "  async unfollowUser(followerUserId: string, usernameToUnfollow: string) {", "    // Find user to unfollow", "    const userToUnfollow = await this.userRepository.findOneBy({", "      username: usernameToUnfollow,", "    });", "    if (!userToUnfollow) {", "      throw new NotFoundError(\"User to unfollow not found\");", "    }", "", "    // Check if following", "    const follow = await this.followRepository.findOne({", "      where: {", "        follower: { id: followerUserId },", "        following: { id: userToUnfollow.id },", "      },", "    });", "", "    if (!follow) {", "      throw new ForbiddenError(\"You are not following this user\");", "    }", "", "    // Remove follow relationship", "    await this.followRepository.remove(follow);", "", "    return { success: true };", "  }", "", "  /**", "   * Check if one user follows another", "   */", "  async checkFollowStatus(followerUserId: string, usernameToCheck: string) {", "    const userToCheck = await this.userRepository.findOneBy({", "      username: usernameToCheck,", "    });", "    if (!userToCheck) {", "      throw new NotFoundError(\"User not found\");", "    }", "", "    const follow = await this.followRepository.findOne({", "      where: {", "        follower: { id: followerUserId },", "        following: { id: userToCheck.id },", "      },", "    });", "", "    return { following: !!follow };", "  }", "", "  /**", "   * Get followers of a user", "   */", "  async getFollowers(username: string, page = 1, limit = 20) {", "    const user = await this.userRepository.findOneBy({ username });", "    if (!user) {", "      throw new NotFoundError(\"User not found\");", "    }", "", "    const skip = (page - 1) * limit;", "", "    const [follows, total] = await this.followRepository", "      .createQueryBuilder(\"follow\")", "      .leftJoinAndSelect(\"follow.follower\", \"follower\")", "      .where(\"follow.following.id = :userId\", { userId: user.id })", "      .skip(skip)", "      .take(limit)", "      .orderBy(\"follow.createdAt\", \"DESC\")", "      .getManyAndCount();", "", "    // Extract follower users only", "    const followers = follows.map((follow) => follow.follower);", "", "    return {", "      followers,", "      meta: {", "        total,", "        page,", "        limit,", "        totalPages: Math.ceil(total / limit),", "      },", "    };", "  }", "", "  /**", "   * Get users that a user is following", "   */", "  async getFollowing(username: string, page = 1, limit = 20) {", "    const user = await this.userRepository.findOneBy({ username });", "    if (!user) {", "      throw new NotFoundError(\"User not found\");", "    }", "", "    const skip = (page - 1) * limit;", "", "    const [follows, total] = await this.followRepository", "      .createQueryBuilder(\"follow\")", "      .leftJoinAndSelect(\"follow.following\", \"following\")", "      .where(\"follow.follower.id = :userId\", { userId: user.id })", "      .skip(skip)", "      .take(limit)", "      .orderBy(\"follow.createdAt\", \"DESC\")", "      .getManyAndCount();", "", "    // Extract following users only", "    const following = follows.map((follow) => follow.following);", "", "    return {", "      following,", "      meta: {", "        total,", "        page,", "        limit,", "        totalPages: Math.ceil(total / limit),", "      },", "    };", "  }", "", "  /**", "   * Get follower/following counts", "   */", "  async getFollowCounts(username: string) {", "    const user = await this.userRepository.findOneBy({ username });", "    if (!user) {", "      throw new NotFoundError(\"User not found\");", "    }", "", "    const followersCount = await this.followRepository.count({", "      where: { following: { id: user.id } },", "    });", "", "    const followingCount = await this.followRepository.count({", "      where: { follower: { id: user.id } },", "    });", "", "    return {", "      username,", "      followersCount,", "      followingCount,", "    };", "  }", "}"], "file_path": "src/features/follow/validations/follow.schema.ts"}
{"Link_to_commit": "https://github.com/kimjeffsj/starclone-backend/commit/833593ac7ea754f432d212e43080991e6a61025c", "n-gram matched": "generated by copilot", "n_lines_longer_change": 121, "n_files_impacted": 6, "longest_chunk": ["import { NextFunction, Request, Response } from \"express\";", "", "import {", "  ValidationError,", "  UnauthorizedError,", "  NotFoundError,", "} from \"@/utils/errors.utils\";", "import { updateProfileSchema } from \"../validations/user.schema\";", "import { UserService } from \"../services/user.service\";", "", "export class UserController {", "  private userService = new UserService();", "", "  /**", "   * Get user profile by username", "   */", "  getUserProfile = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { username } = req.params;", "", "      const user = await this.userService.getUserByUsername(username);", "", "      if (!user) {", "        throw new NotFoundError(\"User not found\");", "      }", "", "      res.status(200).json({", "        user: user.toJSON(),", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Update user profile", "   */", "  updateProfile = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      if (!req.user || !req.user.id) {", "        throw new UnauthorizedError(\"Not authenticated\");", "      }", "", "      // Validate request", "      const validationResult = updateProfileSchema.safeParse(req.body);", "      if (!validationResult.success) {", "        throw new ValidationError(validationResult.error.format());", "      }", "", "      const updatedUser = await this.userService.updateProfile(", "        req.user.id,", "        validationResult.data", "      );", "", "      res.status(200).json({", "        message: \"Profile updated successfully\",", "        user: updatedUser.toJSON(),", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Get posts by username", "   */", "  getUserPosts = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { username } = req.params;", "      const page = req.query.page ? parseInt(req.query.page as string) : 1;", "      const limit = req.query.limit ? parseInt(req.query.limit as string) : 10;", "", "      const result = await this.userService.getUserPosts(username, page, limit);", "", "      res.status(200).json({", "        posts: result.posts,", "        meta: {", "          total: result.total,", "          totalPages: result.totalPages,", "          page,", "          limit,", "        },", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "", "  /**", "   * Search users by username or fullName", "   */", "  searchUsers = async (req: Request, res: Response, next: NextFunction) => {", "    try {", "      const { query } = req.query;", "      const page = req.query.page ? parseInt(req.query.page as string) : 1;", "      const limit = req.query.limit ? parseInt(req.query.limit as string) : 10;", "", "      if (!query || typeof query !== \"string\") {", "        throw new ValidationError({ message: \"Search query is required\" });", "      }", "", "      const { users, total, totalPages } = await this.userService.searchUsers(", "        query,", "        page,", "        limit", "      );", "", "      res.status(200).json({", "        users,", "        meta: {", "          total,", "          totalPages,", "          page,", "          limit,", "        },", "      });", "    } catch (error) {", "      next(error);", "    }", "  };", "}"], "file_path": "src/features/user/index.ts"}
{"Link_to_commit": "https://github.com/ILoveDotNet/ilovedotnet/commit/f9145bb2d893963f21efb544c73fae4b1ca22503", "n-gram matched": "generated by copilot", "n_lines_longer_change": 12, "n_files_impacted": 1, "longest_chunk": ["                                <a class=\"[ flex flex-col items-center ]\" href=\"/career\">", "                                    <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"[ icon icon-tabler icons-tabler-outline icon-tabler-briefcase ]\"", "                                        width=\"30\" height=\"30\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\"", "                                        stroke-linecap=\"round\" stroke-linejoin=\"round\">", "                                        <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\" />", "                                        <path d=\"M3 7m0 2a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v9a2 2 0 0 1 -2 2h-14a2 2 0 0 1 -2 -2z\" />", "                                        <path d=\"M8 7v-2a2 2 0 0 1 2 -2h4a2 2 0 0 1 2 2v2\" />", "                                        <path d=\"M12 12l0 .01\" />", "                                        <path d=\"M3 13a20 20 0 0 0 18 0\" />", "                                    </svg>", "                                    <span class=\"[ text-xs text-center ]\">Career</span>", "                                </a>"], "file_path": "UITests/Components/Navigation/NavigationTests.cs"}
{"Link_to_commit": "https://github.com/kimjeffsj/starclone-frontend/commit/62f3d2244a1fdad9410be42e12b7015100df6adf", "n-gram matched": "generated by copilot", "n_lines_longer_change": 90, "n_files_impacted": 6, "longest_chunk": ["  // Add preview", "  addPreview: (files: File[]) => {", "    const newPreviews = files.map((file) => ({", "      id: crypto.randomUUID(),", "      file,", "      previewUrl: URL.createObjectURL(file),", "      isUploaded: false,", "    }));", "", "    set((state) => ({", "      previewMedia: [...state.previewMedia, ...newPreviews],", "    }));", "  },", "", "  // Delete preview", "  removePreview: (previewId: string) => {", "    set((state) => {", "      // delete preview url", "      const previewToRemove = state.previewMedia.find(", "        (p) => p.id === previewId", "      );", "      if (previewToRemove) {", "        URL.revokeObjectURL(previewToRemove.previewUrl);", "      }", "", "      return {", "        previewMedia: state.previewMedia.filter((p) => p.id !== previewId),", "      };", "    });", "  },", "", "  // Delete all previews", "  clearPreviews: () => {", "    const { previewMedia } = get();", "", "    // delete all preview urls", "    previewMedia.forEach((preview) => {", "      URL.revokeObjectURL(preview.previewUrl);", "    });", "", "    set({ previewMedia: [] });", "  },", "", "  // Upload all previews to server", "  uploadAllPreviews: async (options: MediaUploadOptions) => {", "    const { previewMedia } = get();", "    set({ isUploading: true, uploadProgress: 0 });", "", "    const uploadedItems: Media[] = [];", "    const totalFiles = previewMedia.length;", "    let processedCount = 0;", "", "    try {", "      for (const preview of previewMedia) {", "        if (!preview.isUploaded) {", "          const media = await get().uploadMedia(preview.file, options);", "          if (media) {", "            uploadedItems.push(media);", "", "            // change states to uploaded", "            set((state) => ({", "              previewMedia: state.previewMedia.map((p) =>", "                p.id === preview.id ? { ...p, isUploaded: true } : p", "              ),", "            }));", "          }", "        }", "", "        processedCount++;", "        const percentCompleted = Math.round(", "          (processedCount * 100) / totalFiles", "        );", "        set({ uploadProgress: percentCompleted });", "      }", "", "      // Clear preview after uploaded", "      get().clearPreviews();", "", "      set({ isUploading: false, uploadProgress: 100 });", "      return uploadedItems;", "    } catch (error) {", "      console.error(\"Failed to upload previews:\", error);", "      set({", "        isUploading: false,", "        error: error instanceof Error ? error.message : \"Upload failed\",", "      });", "      return [];", "    }", "  },", ""], "file_path": "src/store/mediaStore.ts"}
{"Link_to_commit": "https://github.com/coderangel117/python_game/commit/07598692f7b230677aa76ecd7391736b5a29185e", "n-gram matched": "generated by copilot", "n_lines_longer_change": 90, "n_files_impacted": 1, "longest_chunk": ["import unittest", "from unittest.mock import patch, mock_open, MagicMock", "", "from user_manager import get_all_users, new_user, get_user_info, delete_user, update_username, add_win, add_played_game, \\", "    add_fail, find_user, save_user, merge_json_files", "", "", "class TestUserManager(unittest.TestCase):", "", "    @patch('user_manager.glob.glob', return_value=['user1.json', 'user2.json', 'users.json'])", "    @patch('builtins.open', new_callable=mock_open, read_data='[{\"username\": \"user1\"}, {\"username\": \"user2\"}]')", "    def test_get_all_users(self, mock_file, mock_glob):", "        users = get_all_users()", "        self.assertIn('user1.json', users)", "        self.assertIn('user2.json', users)", "        self.assertNotIn('users.json', users)", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open)", "    def test_new_user(self, mock_file, mock_glob):", "        new_user('user2')", "        mock_file.assert_called_with('user2.json', 'w')", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open,", "           read_data='{\"username\": \"user1\", \"played_games\": 0, \"nbfail\": 0, \"nbwin\": 0}')", "    def test_get_user_info(self, mock_file, mock_glob):", "        with patch('builtins.print') as mocked_print:", "            get_user_info('user1')", "            mocked_print.assert_called_with('User user1 have never played')", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('os.remove')", "    def test_delete_user(self, mock_remove, mock_glob):", "        with patch('builtins.print') as mocked_print:", "            delete_user('user1')", "            mock_remove.assert_called_with('user1.json')", "            mocked_print.assert_called_with('User user1 has been successfully deleted')", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open, read_data='{\"username\": \"user1\"}')", "    @patch('os.rename')", "    def test_update_username(self, mock_rename, mock_file, mock_glob):", "        with patch('builtins.print') as mocked_print:", "            update_username('user1', 'user2')", "            mock_rename.assert_called_with('user1.json', 'user2.json')", "            mocked_print.assert_called_with(' The username user1 has been changed to user2')", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open, read_data='{\"username\": \"user1\", \"nbwin\": 0}')", "    def test_add_win(self, mock_file, mock_glob):", "        add_win('user1')", "        mock_file().write.assert_called()", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open, read_data='{\"username\": \"user1\", \"played_games\": 0}')", "    def test_add_played_game(self, mock_file, mock_glob):", "        add_played_game('user1')", "        mock_file().write.assert_called()", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    @patch('builtins.open', new_callable=mock_open, read_data='{\"username\": \"user1\", \"nbfail\": 0}')", "    def test_add_fail(self, mock_file, mock_glob):", "        add_fail('user1')", "        mock_file().write.assert_called()", "", "    @patch('user_manager.glob.glob', return_value=['user1.json'])", "    def test_find_user(self, mock_glob):", "        self.assertTrue(find_user('user1'))", "        self.assertFalse(find_user('user2'))", "", "    @patch('builtins.open', new_callable=mock_open)", "    def test_save_user(self, mock_file):", "        user = MagicMock()", "        user.username = 'user1'", "        user.played_games = 0", "        user.nbfail = 0", "        user.nbwin = 0", "        user.greatest_score = 0", "        save_user(user)", "        mock_file.assert_called_with('user1.json', 'w')", "", "    @patch('builtins.open', new_callable=mock_open, read_data='{\"username\": \"user1\"}')", "    def test_merge_json_files(self, mock_file):", "        merge_json_files(['user1.json'])", "        mock_file.assert_called_with('users.json', 'w')", "", "", "if __name__ == '__main__':", "    unittest.main()"], "file_path": "tests/test_user_manager.py"}
{"Link_to_commit": "https://github.com/kimjeffsj/empcon_backend/commit/78dbf6d2dff8127b688dec405597c441b5f50953", "n-gram matched": "generated by copilot", "n_lines_longer_change": 89, "n_files_impacted": 1, "longest_chunk": ["import { NextFunction, Request, Response } from \"express\";", "import { authService } from \"./auth.service\";", "import {", "  UnauthorizedError,", "  ValidationError,", "} from \"@/common/middleware/error.middleware\";", "import { logger } from \"@/common/utils/logger.utils\";", "", "export class AuthController {", "  /**", "   * Login", "   */", "  async login(req: Request, res: Response, next: NextFunction) {", "    try {", "      const { email, password } = req.body;", "", "      if (!email || !password) {", "        throw new ValidationError({", "          message: \"Email and Password are required\",", "        });", "      }", "", "      const result = await authService.login({ email, password });", "", "      return res.status(200).json({", "        message: \"Login successful\",", "        ...result,", "      });", "    } catch (error) {", "      next(error);", "    }", "  }", "", "  /**", "   * Refresh Token", "   */", "  async refreshToken(req: Request, res: Response, next: NextFunction) {", "    try {", "      const { refreshToken } = req.body;", "", "      if (!refreshToken) {", "        throw new UnauthorizedError(\"Refresh token is required\");", "      }", "    } catch (error) {}", "  }", "", "  /**", "   * Request Password reset", "   */", "  async requestPasswordReset(req: Request, res: Response, next: NextFunction) {", "    try {", "      const { email } = req.body;", "", "      if (!email) {", "        throw new ValidationError({ message: \"Email is required\" });", "      }", "", "      const result = await authService.requestPasswordReset({ email });", "", "      return res.status(200).json(result);", "    } catch (error) {", "      logger.error(\"Password reset request error: \", error);", "      next(error);", "    }", "  }", "", "  /**", "   * Reset Password", "   * */", "  async resetPassword(req: Request, res: Response, next: NextFunction) {", "    try {", "      const { token, password } = req.body;", "", "      if (!token || !password) {", "        throw new ValidationError({", "          message: \"Token and new password are required\",", "        });", "      }", "", "      const result = await authService.resetPassword({ token, password });", "", "      return res.status(200).json(result);", "    } catch (error) {", "      next(error);", "    }", "  }", "}", "", "export const authController = new AuthController();"], "file_path": "src/features/auth/auth.controller.ts"}
{"Link_to_commit": "https://github.com/mosajjal/sniproxy/commit/d4b0a51baa7875df04c3b5ecff27aaa21941de92", "n-gram matched": "generated by copilot", "n_lines_longer_change": 7, "n_files_impacted": 2, "longest_chunk": ["// isValidFQDN validates if the given hostname is a valid FQDN", "func isValidFQDN(hostname string) bool {", "\t// Regular expression to match a valid FQDN", "\tvar fqdnRegex = regexp.MustCompile(`^(?i:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?\\.)+(?:[a-z]{2,})$`)", "\treturn fqdnRegex.MatchString(hostname)", "}", ""], "file_path": "pkg/https_sni.go"}
{"Link_to_commit": "https://github.com/frank1li/ipv6-ftp-server-AI-generated/commit/6debfc65580b73f2fe5d5a08f7b16b4906c77dc3", "n-gram matched": "generated by copilot", "n_lines_longer_change": 119, "n_files_impacted": 20, "longest_chunk": ["import os", "import hashlib", "import threading", "", "from pyftpdlib.authorizers import DummyAuthorizer", "from pyftpdlib.handlers import FTPHandler", "from pyftpdlib.servers import FTPServer", "", "from src.config.settings import (", "    HOME_DIRECTORY,", "    PASSWORD,", "    SERVER_ADDRESS,", "    SERVER_PORT,", "    USER,", ")", "", "", "class FTPServerHandler:", "    def __init__(self):", "        self.server = None", "        self.server_thread = None", "", "    def init_server(self):", "        # Check and create working directory if not exists", "        if not os.path.exists(HOME_DIRECTORY):", "            os.makedirs(HOME_DIRECTORY)", "            print(f\"Created working directory: {HOME_DIRECTORY}\")", "", "        # Create an authorizer", "        authorizer = DummyAuthorizer()", "", "        # Add user with settings from config", "        authorizer.add_user(USER, PASSWORD, HOME_DIRECTORY, perm=\"elradfmwMT\")", "", "        # Create FTP handler", "        handler = FTPHandler", "        handler.authorizer = authorizer", "", "        # Set IPv6 address and port", "        address = (SERVER_ADDRESS, SERVER_PORT)", "", "        # Create FTP server", "        self.server = FTPServer(address, handler)", "", "    def start(self):", "        \"\"\"Start FTP server in a separate thread\"\"\"", "        if self.server is None:", "            self.init_server()", "", "        self.server_thread = threading.Thread(", "            target=self.server.serve_forever,", "            daemon=True,  # Set as daemon thread so it will exit when main program exits", "        )", "        self.server_thread.start()", "        print(f\"FTP server is running at [{SERVER_ADDRESS}]:{SERVER_PORT}\")", "", "    def stop(self):", "        \"\"\"Stop the FTP server\"\"\"", "        if self.server:", "            self.server.close_all()", "            print(\"FTP server stopped\")", "", "    def add_binary_file(self, filename: str, content: bytes) -> bool:", "        \"\"\"Add a binary file to the FTP server's home directory", "        ", "        Args:", "            filename: Name of the file to create", "            content: Binary content to write", "            ", "        Returns:", "            bool: True if successful, False otherwise", "        \"\"\"", "        try:", "            filepath = os.path.join(HOME_DIRECTORY, filename)", "            with open(filepath, 'wb') as f:", "                f.write(content)", "            return True", "        except Exception as e:", "            print(f\"Error adding file: {e}\")", "            return False", "", "    def get_file_sha256(self, filename: str) -> str:", "        \"\"\"Get SHA256 hash of a file in the FTP server's home directory", "        ", "        Args:", "            filename: Name of the file to hash", "            ", "        Returns:", "            str: SHA256 hash of the file, or empty string if file not found", "        \"\"\"", "        try:", "            filepath = os.path.join(HOME_DIRECTORY, filename)", "            sha256_hash = hashlib.sha256()", "            with open(filepath, 'rb') as f:", "                for byte_block in iter(lambda: f.read(4096), b''):", "                    sha256_hash.update(byte_block)", "            return sha256_hash.hexdigest()", "        except Exception as e:", "            print(f\"Error calculating hash: {e}\")", "            return ''", "", "", "def main():", "    # Usage example", "    ftp_server = FTPServerHandler()", "    try:", "        ftp_server.start()", "        # Keep main thread running", "        while True:", "            input(\"Press Enter to stop the server...\")", "            break", "    except KeyboardInterrupt:", "        print(\"\\nReceived exit signal\")", "    finally:", "        ftp_server.stop()", "", "", "if __name__ == \"__main__\":", "    main()"], "file_path": "src/utils/__init__.py"}
{"Link_to_commit": "https://github.com/kimjeffsj/empcon_backend/commit/8f02ed761704205ac94ca00202f45b8161f0fcbe", "n-gram matched": "generated by copilot", "n_lines_longer_change": 364, "n_files_impacted": 3, "longest_chunk": ["import {", "  ConflictError,", "  NotFoundError,", "} from \"@/common/middleware/error.middleware\";", "import { dateUtils, getPaginationParams } from \"@/common/utils/helpers.utils\";", "import { logger } from \"@/common/utils/logger.utils\";", "import prisma from \"@/entities/prisma\";", "import bcrypt from \"bcryptjs\";", "import {", "  CreateUserDto,", "  PaginatedUserResponse,", "  UpdateUserDto,", "  UpdateUserProfileDto,", "  UserQueryParams,", "} from \"./dto/user.dto\";", "import { Prisma, UserProfile } from \"@prisma/client\";", "import {", "  defaultUserSelect,", "  UserListSelect,", "  userListSelect,", "  userWithRelationsSelect,", "  UserWithRelationsSelect,", "} from \"./users.selections\";", "", "export class UsersService {", "  /**", "   * Find all users with pagination and filtering", "   */", "  async findAll(queryParams: UserQueryParams): Promise<PaginatedUserResponse> {", "    const { page, limit, search, departmentId, role, isActive } = queryParams;", "    const pagination = getPaginationParams(page, limit);", "", "    // Build where clause", "    const where: Prisma.UserWhereInput = {};", "", "    // Search filter", "    if (search) {", "      where.OR = [", "        { firstName: { contains: search, mode: \"insensitive\" } },", "        { lastName: { contains: search, mode: \"insensitive\" } },", "        { email: { contains: search, mode: \"insensitive\" } },", "      ];", "    }", "", "    // Department filter", "    if (departmentId) {", "      where.departmentId = departmentId;", "    }", "", "    // Role filter", "    if (role) {", "      where.role = role;", "    }", "", "    // Active/Inactive filter", "    if (isActive !== undefined) {", "      const active = isActive === \"true\";", "      where.terminationDate = active ? null : { not: null };", "    }", "", "    // Count total matching records", "    const total = await prisma.user.count({ where });", "", "    // Get users with safe fields", "    const users = await prisma.user.findMany({", "      where,", "      select: userListSelect,", "      skip: pagination.skip,", "      take: pagination.limit,", "      orderBy: {", "        lastName: \"asc\",", "      },", "    });", "", "    return {", "      data: users,", "      total,", "      page: pagination.page,", "      limit: pagination.limit,", "      totalPages: Math.ceil(total / pagination.limit),", "    };", "  }", "", "  /**", "   * Find a single user by ID", "   */", "  async findById(id: string): Promise<UserWithRelationsSelect> {", "    const user = await prisma.user.findUnique({", "      where: { id },", "      select: userWithRelationsSelect,", "    });", "", "    if (!user) {", "      throw new NotFoundError(\"User\");", "    }", "", "    return user;", "  }", "", "  /**", "   * Create a new user", "   */", "  async create(createUserDto: CreateUserDto): Promise<UserWithRelationsSelect> {", "    const { email, password, profile, ...userData } = createUserDto;", "", "    // Check if user with this email already exists", "    const existingUser = await prisma.user.findUnique({", "      where: { email },", "    });", "", "    if (existingUser) {", "      throw new ConflictError(\"email\");", "    }", "", "    // Hash password", "    const hashedPassword = await bcrypt.hash(password, 10);", "", "    // Create user with profile in a transaction", "    try {", "      const user = await prisma.$transaction(async (tx) => {", "        // Create user", "        const newUser = await tx.user.create({", "          data: {", "            email,", "            password: hashedPassword,", "            ...userData,", "          },", "          select: defaultUserSelect,", "        });", "", "        // Create profile if provided", "        if (profile) {", "          await tx.userProfile.create({", "            data: {", "              ...profile,", "              userId: newUser.id,", "            },", "          });", "        }", "", "        return tx.user.findUnique({", "          where: { id: newUser.id },", "          select: userWithRelationsSelect,", "        });", "      });", "", "      if (!user) {", "        throw new Error(\"Failed to create user\");", "      }", "", "      return user;", "    } catch (error) {", "      logger.error(\"Error creating user:\", error);", "      throw error;", "    }", "  }", "", "  /**", "   * Update an existing user", "   */", "  async update(", "    id: string,", "    updateUserDto: UpdateUserDto", "  ): Promise<UserWithRelationsSelect> {", "    const { profile, password, ...userData } = updateUserDto;", "", "    // Check if user exists", "    const existingUser = await prisma.user.findUnique({", "      where: { id },", "      select: { id: true, email: true },", "    });", "", "    if (!existingUser) {", "      throw new NotFoundError(\"User\");", "    }", "", "    // If email is being updated, check for duplicates", "    if (userData.email && userData.email !== existingUser.email) {", "      const duplicateEmail = await prisma.user.findUnique({", "        where: { email: userData.email },", "      });", "", "      if (duplicateEmail) {", "        throw new ConflictError(\"email\");", "      }", "    }", "", "    // Prepare update data", "    const updateData: Prisma.UserUpdateInput = { ...userData };", "", "    // Hash password if provided", "    if (password) {", "      updateData.password = await bcrypt.hash(password, 10);", "    }", "", "    // Update user and profile in a transaction", "    try {", "      const user = await prisma.$transaction(async (tx) => {", "        // Update user", "        const updatedUser = await tx.user.update({", "          where: { id },", "          data: updateData,", "          select: defaultUserSelect,", "        });", "", "        // Update profile if provided", "        if (profile) {", "          // Check if profile exists", "          const existingProfile = await tx.userProfile.findUnique({", "            where: { userId: id },", "          });", "", "          if (existingProfile) {", "            await tx.userProfile.update({", "              where: { userId: id },", "              data: profile,", "            });", "          } else {", "            await tx.userProfile.create({", "              data: {", "                ...profile,", "                userId: id,", "              },", "            });", "          }", "        }", "", "        return tx.user.findUnique({", "          where: { id },", "          select: userWithRelationsSelect,", "        });", "      });", "", "      if (!user) {", "        throw new Error(\"Failed to update user\");", "      }", "", "      return user;", "    } catch (error) {", "      logger.error(\"Error updating user:\", error);", "      throw error;", "    }", "  }", "", "  /**", "   * Update user profile", "   */", "  async updateProfile(", "    userId: string,", "    updateProfileDto: UpdateUserProfileDto", "  ): Promise<UserProfile> {", "    // Check if user exists", "    const user = await prisma.user.findUnique({", "      where: { id: userId },", "      select: { id: true },", "    });", "", "    if (!user) {", "      throw new NotFoundError(\"User\");", "    }", "", "    // Check if profile exists", "    const existingProfile = await prisma.userProfile.findUnique({", "      where: { userId },", "    });", "", "    // Update or create profile", "    if (existingProfile) {", "      return prisma.userProfile.update({", "        where: { userId },", "        data: updateProfileDto,", "      });", "    } else {", "      return prisma.userProfile.create({", "        data: {", "          ...updateProfileDto,", "          userId,", "        },", "      });", "    }", "  }", "", "  /**", "   * Delete a user", "   */", "  async delete(id: string): Promise<void> {", "    // Check if user exists", "    const user = await prisma.user.findUnique({", "      where: { id },", "      select: { id: true },", "    });", "", "    if (!user) {", "      throw new NotFoundError(\"User\");", "    }", "", "    // Delete user and related data in a transaction", "    try {", "      await prisma.$transaction(async (tx) => {", "        // Delete profile if exists", "        const profile = await tx.userProfile.findUnique({", "          where: { userId: id },", "        });", "", "        if (profile) {", "          await tx.userProfile.delete({", "            where: { userId: id },", "          });", "        }", "", "        // Delete user", "        await tx.user.delete({", "          where: { id },", "        });", "      });", "    } catch (error) {", "      logger.error(\"Error deleting user:\", error);", "      throw error;", "    }", "  }", "", "  /**", "   * Get new employees (hired in the last 30 days)", "   */", "  async getNewEmployees(): Promise<UserListSelect[]> {", "    const thirtyDaysAgo = dateUtils.daysAgo(30);", "", "    const newUsers = await prisma.user.findMany({", "      where: {", "        hireDate: {", "          gte: thirtyDaysAgo,", "        },", "        terminationDate: null,", "      },", "      select: userListSelect,", "      orderBy: {", "        hireDate: \"desc\",", "      },", "    });", "", "    return newUsers;", "  }", "", "  /**", "   * Get resigned employees", "   */", "  async getResignedEmployees(): Promise<UserListSelect[]> {", "    const resignedUsers = await prisma.user.findMany({", "      where: {", "        terminationDate: {", "          not: null,", "        },", "      },", "      select: userListSelect,", "      orderBy: {", "        terminationDate: \"desc\",", "      },", "    });", "", "    return resignedUsers;", "  }", "}", "", "export const usersService = new UsersService();"], "file_path": "src/features/users/users.service.ts"}
{"Link_to_commit": "https://github.com/mozilla-ai/lumigator/commit/ac0c942615ab6f505f3c7acb1db8e3512c020d84", "n-gram matched": "generated by copilot", "n_lines_longer_change": 195, "n_files_impacted": 7, "longest_chunk": ["from unittest.mock import MagicMock, patch", "", "import pytest", "from inference_config import InferenceJobConfig", "from model_clients.huggingface_clients import (", "    HuggingFaceCausalLMClient,", "    HuggingFaceSeq2SeqSummarizationClient,", ")", "", "from schemas import PredictionResult, TaskType", "", "", "class TestHuggingFaceSeq2SeqSummarizationClient:", "    @pytest.fixture", "    def mock_config(self):", "        \"\"\"Create a mock InferenceJobConfig for testing seq2seq client.\"\"\"", "        config = MagicMock(spec=InferenceJobConfig)", "        config.hf_pipeline = MagicMock()", "        config.hf_pipeline.model_name_or_path = \"mock-seq2seq-model\"", "        config.hf_pipeline.task = TaskType.SUMMARIZATION", "        config.hf_pipeline.use_fast = True", "        config.hf_pipeline.trust_remote_code = False", "        config.hf_pipeline.torch_dtype = \"float32\"", "        config.hf_pipeline.revision = \"main\"", "        config.hf_pipeline.device = \"cpu\"", "", "        config.generation_config = MagicMock()", "        config.generation_config.max_new_tokens = 100", "", "        return config", "", "    @patch(\"model_clients.huggingface_clients.AutoTokenizer\")", "    @patch(\"model_clients.huggingface_clients.AutoModelForSeq2SeqLM\")", "    @patch(\"model_clients.huggingface_clients.pipeline\")", "    def test_initialization(self, mock_pipeline, mock_automodel, mock_tokenizer, mock_config):", "        \"\"\"Test initialization of the seq2seq client.\"\"\"", "        # Setup mocks", "        mock_model = MagicMock()", "        mock_model.config.max_position_embeddings = 512", "        mock_automodel.from_pretrained.return_value = mock_model", "", "        mock_tokenizer_instance = MagicMock()", "        mock_tokenizer_instance.model_max_length = 512", "        mock_tokenizer.from_pretrained.return_value = mock_tokenizer_instance", "", "        mock_pipeline_instance = MagicMock()", "        mock_pipeline_instance.model = mock_model", "        mock_pipeline_instance.tokenizer = mock_tokenizer_instance", "        mock_pipeline.return_value = mock_pipeline_instance", "", "        # Initialize client", "        client = HuggingFaceSeq2SeqSummarizationClient(mock_config)", "", "        # Verify initialization", "        mock_tokenizer.from_pretrained.assert_called_once()", "        mock_automodel.from_pretrained.assert_called_once()", "        mock_pipeline.assert_called_once()", "        assert client._pipeline == mock_pipeline_instance", "", "    @patch(\"model_clients.huggingface_clients.AutoTokenizer\")", "    @patch(\"model_clients.huggingface_clients.AutoModelForSeq2SeqLM\")", "    @patch(\"model_clients.huggingface_clients.pipeline\")", "    def test_predict(self, mock_pipeline, mock_automodel, mock_tokenizer, mock_config):", "        \"\"\"Test the predict method of the seq2seq client.\"\"\"", "        # Setup mocks", "        mock_model = MagicMock()", "        mock_model.config.max_position_embeddings = 512", "        mock_automodel.from_pretrained.return_value = mock_model", "", "        mock_tokenizer_instance = MagicMock()", "        mock_tokenizer_instance.model_max_length = 512", "        mock_tokenizer.from_pretrained.return_value = mock_tokenizer_instance", "", "        mock_pipeline_instance = MagicMock()", "        mock_pipeline_instance.model = mock_model", "        mock_pipeline_instance.tokenizer = mock_tokenizer_instance", "        mock_pipeline_instance.return_value = [{\"summary_text\": \"This is a summary.\"}]", "        mock_pipeline.return_value = mock_pipeline_instance", "", "        # Initialize client and call predict", "        client = HuggingFaceSeq2SeqSummarizationClient(mock_config)", "        result = client.predict(\"This is a test prompt.\")", "", "        # Verify prediction", "        assert isinstance(result, PredictionResult)", "        assert result.prediction == \"This is a summary.\"", "        mock_pipeline_instance.assert_called_once_with(\"This is a test prompt.\", max_new_tokens=100, truncation=True)", "", "    @patch(\"model_clients.huggingface_clients.AutoTokenizer\")", "    @patch(\"model_clients.huggingface_clients.AutoModelForSeq2SeqLM\")", "    @patch(\"model_clients.huggingface_clients.pipeline\")", "    def test_max_token_adjustment(self, mock_pipeline, mock_automodel, mock_tokenizer, mock_config):", "        \"\"\"Test that the client adjusts max tokens if over model limits.\"\"\"", "        # Setup mocks with limited max position embeddings", "        mock_model = MagicMock()", "        mock_model.config.max_position_embeddings = 50  # Lower than config.max_new_tokens", "        mock_automodel.from_pretrained.return_value = mock_model", "", "        mock_tokenizer_instance = MagicMock()", "        mock_tokenizer_instance.model_max_length = 512", "        mock_tokenizer.from_pretrained.return_value = mock_tokenizer_instance", "", "        mock_pipeline_instance = MagicMock()", "        mock_pipeline_instance.model = mock_model", "        mock_pipeline_instance.tokenizer = mock_tokenizer_instance", "        mock_pipeline.return_value = mock_pipeline_instance", "", "        # Set the initial max_new_tokens to a value higher than model's max_position_embeddings", "        mock_config.generation_config.max_new_tokens = 100", "        # Initialize client - which should trigger the token adjustment", "        client = HuggingFaceSeq2SeqSummarizationClient(mock_config)", "        # Verify the max_new_tokens was adjusted down to the model's max_position_embeddings", "        assert client._config.generation_config.max_new_tokens == 50", "", "        # Now test with a value that's already within limits", "        mock_config.generation_config.max_new_tokens = 30  # Less than max_position_embeddings", "        # Initialize a new client", "        client = HuggingFaceSeq2SeqSummarizationClient(mock_config)", "        # Verify max_new_tokens was NOT adjusted since it was already within limits", "        assert client._config.generation_config.max_new_tokens == 30", "", "", "class TestHuggingFaceCausalLMClient:", "    @pytest.fixture", "    def mock_config(self):", "        \"\"\"Create a mock InferenceJobConfig for testing causal LM client.\"\"\"", "        config = MagicMock(spec=InferenceJobConfig)", "        config.hf_pipeline = MagicMock()", "        config.hf_pipeline.model_name_or_path = \"mock-causal-model\"", "        config.hf_pipeline.task = TaskType.TEXT_GENERATION", "        config.hf_pipeline.model_dump.return_value = {", "            \"model_name_or_path\": \"mock-causal-model\",", "            \"task\": TaskType.TEXT_GENERATION,", "        }", "", "        config.system_prompt = \"You are a helpful assistant.\"", "        config.generation_config = MagicMock()", "        config.generation_config.max_new_tokens = 100", "", "        return config", "", "    @patch(\"model_clients.huggingface_clients.pipeline\")", "    def test_initialization(self, mock_pipeline, mock_config):", "        \"\"\"Test initialization of the causal LM client.\"\"\"", "        # Setup mocks", "        mock_pipeline_instance = MagicMock()", "        mock_pipeline.return_value = mock_pipeline_instance", "", "        # Initialize client", "        client = HuggingFaceCausalLMClient(mock_config)", "", "        # Verify initialization", "        mock_pipeline.assert_called_once()", "        assert client._pipeline == mock_pipeline_instance", "        assert client._system_prompt == \"You are a helpful assistant.\"", "", "    @patch(\"model_clients.huggingface_clients.pipeline\")", "    def test_with_summarization_task(self, mock_pipeline, mock_config):", "        \"\"\"Test the causal LM client with a summarization task through system prompt.\"\"\"", "        # Set task to summarization and use appropriate system prompt", "        mock_config.hf_pipeline.task = TaskType.SUMMARIZATION", "        mock_config.system_prompt = \"Summarize the following text.\"", "", "        # Ensure pipeline config is still set to text-generation (overridden in client init)", "        mock_config.hf_pipeline.model_dump.return_value = {", "            \"model_name_or_path\": \"mock-causal-model\",", "            \"task\": TaskType.TEXT_GENERATION,  # Should still be text-generation in dumped config", "        }", "", "        # Setup mock pipeline response", "        mock_response = [", "            {", "                \"generated_text\": [", "                    {\"role\": \"system\", \"content\": \"Summarize the following text.\"},", "                    {\"role\": \"user\", \"content\": \"Long article about climate change...\"},", "                    {\"role\": \"assistant\", \"content\": \"Climate change is affecting the planet in various ways.\"},", "                ]", "            }", "        ]", "        mock_pipeline_instance = MagicMock()", "        mock_pipeline_instance.return_value = mock_response", "        mock_pipeline.return_value = mock_pipeline_instance", "", "        # Initialize client and call predict", "        client = HuggingFaceCausalLMClient(mock_config)", "        result = client.predict(\"Long article about climate change...\")", "", "        # Verify prediction", "        assert isinstance(result, PredictionResult)", "        assert result.prediction == \"Climate change is affecting the planet in various ways.\"", "", "        # Verify pipeline task was correctly overridden to text-generation", "        mock_pipeline.assert_called_once()", "        pipeline_args = mock_pipeline.call_args[1]", "        assert pipeline_args[\"task\"] == TaskType.TEXT_GENERATION"], "file_path": "lumigator/jobs/inference/tests/test_huggingface_clients.py"}
{"Link_to_commit": "https://github.com/kimjeffsj/empcon_backend/commit/0433d2285bca54aef0c5399dbc053e414cbae47b", "n-gram matched": "generated by copilot", "n_lines_longer_change": 79, "n_files_impacted": 1, "longest_chunk": ["/**", " * Utility function to remove password field from data", " */", "export function excludePassword<T extends { password: string }>(", "  user: T", "): Omit<T, \"password\"> {", "  const { password, ...userWithoutPassword } = user;", "  return userWithoutPassword;", "}", "", "/**", " * Utility function to remove password fields from an array of objects", " */", "export function excludePasswordFromArray<T extends { password: string }>(", "  users: T[]", "): Omit<T, \"password\">[] {", "  return users.map((user) => excludePassword(user));", "}", "", "/**", " * Date utility functions with date range capabilities", " */", "export const dateUtils = {", "  /**", "   * Returns current date", "   */", "  now(): Date {", "    return new Date();", "  },", "", "  /**", "   * Returns date from n days ago", "   */", "  daysAgo(days: number): Date {", "    const date = new Date();", "    date.setDate(date.getDate() - days);", "    return date;", "  },", "", "  /**", "   * Returns date n days from now", "   */", "  daysFromNow(days: number): Date {", "    const date = new Date();", "    date.setDate(date.getDate() + days);", "    return date;", "  },", "", "  /**", "   * Calculate days between two dates", "   */", "  daysBetween(start: Date, end: Date): number {", "    const diffTime = Math.abs(end.getTime() - start.getTime());", "    return Math.ceil(diffTime / (1000 * 60 * 60 * 24));", "  },", "", "  /**", "   * Convert date to YYYY-MM-DD format string", "   */", "  formatDate(date: Date): string {", "    return date.toISOString().split(\"T\")[0];", "  },", "};", "", "/**", " * Utility function for pagination", " */", "export function getPaginationParams(page?: string, limit?: string) {", "  const parsedPage = parseInt(page || \"1\", 10);", "  const parsedLimit = parseInt(limit || \"10\", 10);", "", "  return {", "    page: parsedPage > 0 ? parsedPage : 1,", "    limit: parsedLimit > 0 ? parsedLimit : 10,", "    skip:", "      (parsedPage > 0 ? parsedPage - 1 : 0) *", "      (parsedLimit > 0 ? parsedLimit : 10),", "  };", "}"], "file_path": "src/common/utils/helpers.utils.ts"}
{"Link_to_commit": "https://github.com/kimjeffsj/empcon_backend/commit/1b16d19cc104c4b522cda25081555f0ad8f9320d", "n-gram matched": "generated by copilot", "n_lines_longer_change": 61, "n_files_impacted": 4, "longest_chunk": ["import { PrismaClient } from \"@prisma/client\";", "import bcrypt from \"bcryptjs\";", "import dotenv from \"dotenv\";", "import path from \"path\";", "", "dotenv.config({ path: path.resolve(__dirname, \"../.env\") });", "", "import { appConfig } from \"../src/config/app.config\";", "", "const prisma = new PrismaClient();", "", "async function main() {", "  // Get admin information from environment variables", "  const adminEmail = appConfig.admin.email;", "  const adminPassword = appConfig.admin.password;", "", "  if (!adminEmail) {", "    throw new Error(\"Admin email is not defined in environment variables\");", "  }", "", "  if (!adminPassword) {", "    throw new Error(\"Admin password is not defined in environment variables\");", "  }", "", "  // Hash admin password", "  const hashedPassword = await bcrypt.hash(adminPassword, 10);", "", "  // Check if admin already exists", "  const existingAdmin = await prisma.user.findUnique({", "    where: { email: adminEmail },", "  });", "", "  // Create admin if not exists", "  if (!existingAdmin) {", "    const admin = await prisma.user.create({", "      data: {", "        email: adminEmail,", "        password: hashedPassword,", "        firstName: \"Admin\",", "        lastName: \"User\",", "        hireDate: new Date(),", "        role: \"ADMIN\",", "      },", "    });", "", "    console.log(`Admin user created with ID: ${admin.id}`);", "    console.log(`Email: ${adminEmail}`);", "    console.log(\"Password: [Set in environment variables]\");", "  } else {", "    console.log(\"Admin user already exists\");", "  }", "}", "", "main()", "  .catch((e) => {", "    console.error(\"Seed error:\", e);", "    process.exit(1);", "  })", "  .finally(async () => {", "    await prisma.$disconnect();", "  });"], "file_path": "src/app.ts"}
{"Link_to_commit": "https://github.com/jedisct1/libsodium.js/commit/e9a5966606d9e7cf1150f2fa5b53c0f393965f28", "n-gram matched": "generated by copilot", "n_lines_longer_change": 14, "n_files_impacted": 1, "longest_chunk": ["});", "", "test(\"crypto_scalarmult\", () => {", "    const aliceKeypair = sodium.crypto_box_keypair();", "    const aliceSecret = aliceKeypair.privateKey;", "    const alicePublic = aliceKeypair.publicKey;", "    const bobKeypair = sodium.crypto_box_keypair();", "    const bobSecret = bobKeypair.privateKey;", "    const bobPublic = bobKeypair.publicKey;", "", "    const shared1 = sodium.crypto_scalarmult(aliceSecret, bobPublic);", "    const shared2 = sodium.crypto_scalarmult(bobSecret, alicePublic);", "    expect(shared1).toEqual(shared2);", "});"], "file_path": "test/sodium.test.ts"}
{"Link_to_commit": "https://github.com/venzy/chirpy/commit/b85d274386730bd5d46a5b75dd74fc659a7d6ba0", "n-gram matched": "generated by copilot", "n_lines_longer_change": 39, "n_files_impacted": 4, "longest_chunk": ["}", "", "func (cfg *apiConfig) handleDeleteChirpByID(response http.ResponseWriter, request *http.Request, userID uuid.UUID) {", "\t// Parse request params", "\tchirpID, err := uuid.Parse(request.PathValue(\"chirpID\"))", "\tif err != nil {", "\t\tmsg := fmt.Sprintf(\"chirps: Problem parsing chirpID from request: %s\", err)", "\t\tlog.Println(msg)", "\t\trespondWithError(response, http.StatusBadRequest, msg)", "\t\treturn", "\t}", "", "\t// Fetch chirp to confirm user owns it", "\trow, err := cfg.db.GetChirpByID(request.Context(), chirpID)", "\tif err != nil {", "\t\tmsg := fmt.Sprintf(\"chirps: Problem retrieving chirp with id '%s': %s\", chirpID, err)", "\t\tlog.Println(msg)", "\t\trespondWithError(response, http.StatusNotFound, msg)", "\t\treturn", "\t}", "", "\tif row.UserID != userID {", "\t\tmsg := fmt.Sprintf(\"chirps: User '%s' does not own chirp '%s'\", userID, chirpID)", "\t\tlog.Println(msg)", "\t\trespondWithError(response, http.StatusForbidden, msg)", "\t\treturn", "\t}", "", "\t// Delete chirp", "\terr = cfg.db.DeleteChirpByID(request.Context(), chirpID)", "\tif err != nil {\t", "\t\tmsg := fmt.Sprintf(\"chirps: Problem deleting chirp with id '%s': %s\", chirpID, err)", "\t\tlog.Println(msg)", "\t\trespondWithError(response, http.StatusInternalServerError, msg)", "\t\treturn", "\t}", "", "\t// Respond with success", "\tresponse.WriteHeader(http.StatusNoContent)"], "file_path": "handler_chirps.go"}
{"Link_to_commit": "https://github.com/mihaigalos/mkdocs-breadcrumbs-plugin/commit/aafeaf64c4150e6c0a5e1e1047760a2375dd99b4", "n-gram matched": "generated by copilot", "n_lines_longer_change": 8, "n_files_impacted": 1, "longest_chunk": ["            ", "            if self.config['use_page_titles']:", "                title = page.meta.get('title', unquote(part))", "            else:", "                title = unquote(part)", "                ", "            breadcrumbs.append(f\"[{title}]({crumb_url})\")", "            self.logger.debug(f'Added breadcrumb: {title} with URL: {crumb_url}')"], "file_path": "mkdocs_breadcrumbs_plugin/plugin.py"}
{"Link_to_commit": "https://github.com/venzy/chirpy/commit/a64c798cc22535060ef70a7d553165bc1ab7165d", "n-gram matched": "generated by copilot", "n_lines_longer_change": 16, "n_files_impacted": 3, "longest_chunk": ["}", "", "func GetAPIKey(headers http.Header) (string, error) {", "\tauthHeader := headers.Get(\"Authorization\")", "\tif authHeader == \"\" {", "\t\treturn \"\", errors.New(\"Missing Authorization header\")", "\t}", "\tconst prefix = \"ApiKey \"", "\tif !strings.HasPrefix(authHeader, prefix) {", "\t\treturn \"\", errors.New(\"Authorization header must start with 'ApiKey '\")", "\t}", "\tapiKey := strings.TrimSpace(strings.TrimPrefix(authHeader, prefix))", "\tif apiKey == \"\" {", "\t\treturn \"\", errors.New(\"API key is empty\")", "\t}", "\treturn apiKey, nil"], "file_path": "internal/auth/auth.go"}
{"Link_to_commit": "https://github.com/fbartelt/robotics-experiments/commit/7d3ba60ffc4169c2df3a0c8f88eaa72b32396baa", "n-gram matched": "generated by copilot", "n_lines_longer_change": 23, "n_files_impacted": 3, "longest_chunk": ["/**", " * @brief Constructs a System object with the given parameters.", " *", " * @param l1_ The length of link 1.", " * @param l2_ The length of link 2.", " * @param lc1_ The distance from the origin to the center of mass of link 1.", " * @param lc2_ The distance from the origin to the center of mass of link 2.", " * @param m1_ The mass of link 1.", " * @param m2_ The mass of link 2.", " * @param m1_bar_ The mass uncertainty of link 1.", " * @param m2_bar_ The mass uncertainty of link 2.", " * @param g__ The acceleration due to gravity.", " * @param I1_ The moment of inertia of link 1.", " * @param I2_ The moment of inertia of link 2.", " * @param epsilon_ The barrier width.", " * @param l_ The adaptive parameter \\ell.", " * @param n_ The number of degrees of freedom.", " * @param varrho_ The parameter varrho.", " * @param A_ The matrix A.", " * @param B_ The matrix B.", " * @param L_ The matrix L.", " * @param Xi_ The matrix Xi.", " */"], "file_path": "cpp/cruzancona.cpp"}
{"Link_to_commit": "https://github.com/hkw1831/obsidian-action-status-updater/commit/7bd259675245dbfa1994f19aa08c086dc7e65e1c", "n-gram matched": "generated by copilot", "n_lines_longer_change": 150, "n_files_impacted": 3, "longest_chunk": ["import { ItemView, WorkspaceLeaf, TFile, Keymap, PaneType, Notice, Menu, MarkdownView } from 'obsidian';", "import { getRecentNotes, getRecentNotesWithInfo, RecentNoteInfo } from 'selfutil/getRecentNotes';", "import { getNoteType, NoteType } from 'selfutil/getTaskTag';", "", "export const VIEW_TYPE_RECENT_VIEWED_NOTES = 'recent-viewed-notes-view';", "", "class RecentViewedNotesView extends ItemView {", "  public currentNotesPath: string;", "", "  constructor(leaf: WorkspaceLeaf, notesTypeTag: string) {", "    super(leaf);", "    this.currentNotesPath = notesTypeTag;", "  }", "", "  getViewType() {", "    return VIEW_TYPE_RECENT_VIEWED_NOTES;", "  }", "", "  getDisplayText() {", "    return 'Recent Viewed Notes';", "  }", "", "  async onOpen() {", "    this.redraw(true);", "  }", "", "  public getIcon(): string {", "    return 'history';", "  }", "", "  public readonly redraw = async (forceRedraw: boolean): Promise<void> => {", "    this.containerEl.empty();", "    ", "    // Get the combined and sorted list of recently viewed and modified notes", "    const recentlyViewedNotes = getRecentNotesWithInfo(this.app, 100);", "    ", "    const rootEl = this.containerEl.createDiv({ cls: 'nav-folder mod-root scrollable' });", "    const childrenEl = rootEl.createDiv({ cls: 'nav-folder-children' });", "    ", "    for (let noteInfo of recentlyViewedNotes) {", "      const file = this.app.vault.getAbstractFileByPath(noteInfo.path);", "      if (!file || !(file instanceof TFile)) continue;", "      ", "      const navFile = childrenEl.createDiv({", "        cls: 'tree-item nav-file recent-viewed-notes-file',", "      });", "      ", "      const navFileTitle = navFile.createDiv({", "        cls: 'tree-item-self is-clickable nav-file-title recent-viewed-notes-title',", "      });", "      ", "      const navFileTitleContent = navFileTitle.createDiv({", "        cls: 'tree-item-inner nav-file-title-content recent-viewed-notes-title-content internal-link self-wrap-content',", "      });", "      ", "      // Just display the filename without the path for cleaner UI", "      const noteType : NoteType | null = getNoteType(file.path)", "      const prefix = noteType ? (noteType.prefix ? noteType.prefix + \" \" : \"\") : \"\"", "      navFileTitleContent.setText(prefix + file.path);", "      ", "      // Add metadata as subtitle with time info", "      const navFileSubtitle = navFileTitle.createDiv({", "        cls: 'tree-item-flair recent-viewed-notes-subtitle',", "      });", "", "     // Show folder path and relative time info", "     const formattedDate = this.getRelativeTimeString(noteInfo);", "     navFileSubtitle.setText(` \u2022 ${formattedDate}`);", "      ", "      // Add right-click menu", "      navFileTitle.addEventListener('contextmenu', (event: MouseEvent) => {", "        const menu = new Menu();", "        menu.addItem((item) =>", "          item", "            .setSection('action')", "            .setTitle('Open in new tab')", "            .setIcon('file-plus')", "            .onClick(() => {", "              this.focusFile(file, 'tab');", "            })", "        );", "        ", "        this.app.workspace.trigger(", "          'file-menu',", "          menu,", "          file,", "          'link-context-menu',", "        );", "        ", "        menu.showAtPosition({ x: event.clientX, y: event.clientY });", "      });", "", "      // Add click handler to open the file", "      navFileTitle.addEventListener('click', (event: MouseEvent) => {  ", "        const newLeaf = Keymap.isModEvent(event);", "        this.focusFile(file, newLeaf);", "      });", "    }", "    ", "    // Add a message if no recently viewed notes are found", "    if (recentlyViewedNotes.length === 0) {", "      const emptyState = childrenEl.createDiv({", "        cls: 'nav-folder-empty-state',", "      });", "      emptyState.setText('No recently viewed notes found');", "    }", "  }", "  ", "  // Helper method to format the time display based on recency", "  private getRelativeTimeString(noteInfo: RecentNoteInfo): string {", "    const now = Date.now();", "    // Use the most recent time between last viewed and modified", "    const mostRecentTime = Math.max(noteInfo.lastViewed, noteInfo.mtime);", "    const diffMinutes = Math.floor((now - mostRecentTime) / 60000);", "    ", "    if (diffMinutes < 1) return 'just now';", "    if (diffMinutes < 60) return `${diffMinutes}m ago`;", "    ", "    const diffHours = Math.floor(diffMinutes / 60);", "    if (diffHours < 24) return `${diffHours}h ago`;", "    ", "    const diffDays = Math.floor(diffHours / 24);", "    if (diffDays < 7) return `${diffDays}d ago`;", "    ", "    // For older items, show the actual date", "    return new Date(mostRecentTime).toLocaleDateString();", "  }", "  ", "  async onClose() {", "    // Cleanup if necessary", "  }", "  ", "  private readonly focusFile = (file: TFile, newLeaf: boolean | PaneType): void => {", "    if (file) {", "      const leaf = this.app.workspace.getLeaf(newLeaf);", "      leaf.openFile(file).then(() => {", "        const view = this.app.workspace.getActiveViewOfType(MarkdownView);", "        if (view) {", "          // Focus on the beginning of the file", "          view.editor.setCursor({ line: 0, ch: 0 });", "          view.editor.scrollIntoView({ from: { line: 0, ch: 0 }, to: { line: 0, ch: 0 } }, true);", "        }", "      });", "    } else {", "      new Notice('Cannot find a file with that name');", "    }", "  };", "}", "", "export { RecentViewedNotesView };"], "file_path": "recentViewedNotesView.ts"}
{"Link_to_commit": "https://github.com/dbedggood/trademe-property-blacklist/commit/2887f84909f8bdf774e0adbc50c264faf8960094", "n-gram matched": "generated by copilot", "n_lines_longer_change": 23, "n_files_impacted": 4, "longest_chunk": ["<!DOCTYPE html>", "<html>", "  <head>", "    <title>Trademe Property Blacklist</title>", "    <style>", "      body {", "        width: 200px;", "        height: 100px;", "        display: flex;", "        justify-content: center;", "        align-items: center;", "      }", "      button {", "        padding: 10px;", "        font-size: 16px;", "      }", "    </style>", "  </head>", "  <body>", "    <button id=\"changeColor\">Change Color</button>", "    <script src=\"popup.js\"></script>", "  </body>", "</html>"], "file_path": "popup.js"}
{"Link_to_commit": "https://github.com/scottcode/wordle-model/commit/44dd4a9b1d90c1b513629c626a72fa11d0f1907a", "n-gram matched": "generated by copilot", "n_lines_longer_change": 29, "n_files_impacted": 1, "longest_chunk": ["import unittest", "from wordle import Color, Feedback, Attempt, give_feedback, Game", "", "class TestWordle(unittest.TestCase):", "    def test_feedback_is_correct(self):", "        feedback = Feedback([Color.green, Color.green, Color.green, Color.green, Color.green])", "        self.assertTrue(feedback.is_correct())", "", "    def test_attempt_is_correct(self):", "        attempt = Attempt('helps', [Color.green, Color.green, Color.green, Color.green, Color.green])", "        self.assertTrue(attempt.is_correct())", "", "    def test_give_feedback(self):", "        attempt = give_feedback('smile', 'helps')", "        self.assertEqual(attempt.feedback, [Color.grey, Color.green, Color.grey, Color.grey, Color.grey])", "", "    def test_game_guess_word(self):", "        game = Game('helps')", "        attempt = game.guess_word('smile')", "        self.assertEqual(attempt.feedback, [Color.grey, Color.green, Color.grey, Color.grey, Color.grey])", "", "    def test_game_n_attempts(self):", "        game = Game('helps')", "        game.guess_word('smile')", "        game.guess_word('tells')", "        self.assertEqual(game.n_attempts, 2)", "", "if __name__ == '__main__':", "    unittest.main()"], "file_path": "tests_from_copilot.py"}
{"Link_to_commit": "https://github.com/Allexsen/Learning-Project/commit/263fcadf9221e5e48a53dcfbb14afa90bf362f62", "n-gram matched": "generated by copilot", "n_lines_longer_change": 10, "n_files_impacted": 3, "longest_chunk": ["\tID            int64  `db:\"id\" json:\"id,omitempty\"`                           // Unique user id", "\tFirstname     string `db:\"firstname\" json:\"first_name,omitempty\"`            // Firstname", "\tLastname      string `db:\"lastname\" json:\"last_name,omitempty\"`              // Lastname", "\tEmail         string `db:\"email\" json:\"email,omitempty\"`                     // Email", "\tUsername      string `db:\"username\" json:\"username,omitempty\"`               // Unique username", "\tFriendsCount  int    `db:\"friends_count\" json:\"friends_count,omitempty\"`     // Number of friends", "\tProfilePicURL string `db:\"profile_pic_url\" json:\"profile_pic_url,omitempty\"` // Profile picture", "\tPostsCount    int    `db:\"posts_count\" json:\"posts_count,omitempty\"`         // Number of posts", "\tCommentsCount int    `db:\"comments_count\" json:\"comments_count,omitempty\"`   // Number of comments", "\tLikesCount    int    `db:\"likes_count\" json:\"likes_count,omitempty\"`         // Number of likes"], "file_path": "internal/models/user/user_model.go"}
{"Link_to_commit": "https://github.com/ariel-ortiz/202411-tc2005b.402/commit/39cce3f92499c1e3b7a965bac62edd40e1002543", "n-gram matched": "generated by copilot", "n_lines_longer_change": 6, "n_files_impacted": 1, "longest_chunk": ["const dwarfs = ['Thorin', 'Balin', 'Dwalin', 'Fili', 'Kili', 'Dori', 'Nori',", "                'Ori', 'Oin', 'Gloin', 'Bifur', 'Bofur', 'Bombur'];", "", "for (const dwarf of dwarfs) {", "    console.log(dwarf);", "}"], "file_path": "4. JavaScript servidor/Ejemplo 2/dwarfs.js"}
{"Link_to_commit": "https://github.com/EllsworthLogan/417final/commit/d7bd9c96db3d890658d05a765fee09c3478a83c2", "n-gram matched": "generated by copilot", "n_lines_longer_change": 30, "n_files_impacted": 1, "longest_chunk": ["import org.junit.jupiter.api.Test;", "import static org.junit.jupiter.api.Assertions.assertEquals;", "", "public class TriangleTest {", "", "    @Test", "    public void testInvalidTriangle() {", "        assertEquals(TriangleType.INVALID, Triangle.classify(0, 0, 0));", "        assertEquals(TriangleType.INVALID, Triangle.classify(-1, 2, 3));", "        assertEquals(TriangleType.INVALID, Triangle.classify(1, -2, 3));", "        assertEquals(TriangleType.INVALID, Triangle.classify(1, 2, -3));", "    }", "", "    @Test", "    public void testEquilateralTriangle() {", "        assertEquals(TriangleType.EQUILATERAL, Triangle.classify(5, 5, 5));", "    }", "", "    @Test", "    public void testIsoscelesTriangle() {", "        assertEquals(TriangleType.ISOSCELES, Triangle.classify(5, 5, 3));", "        assertEquals(TriangleType.ISOSCELES, Triangle.classify(3, 5, 5));", "        assertEquals(TriangleType.ISOSCELES, Triangle.classify(5, 3, 5));", "    }", "", "    @Test", "    public void testScaleneTriangle() {", "        assertEquals(TriangleType.SCALENE, Triangle.classify(3, 4, 5));", "    }", "}"], "file_path": "prompt1.java"}
{"Link_to_commit": "https://github.com/chantalsantos7/dfa-challenge-3-address-book/commit/38b187cebe88a79f11c0862a15ff7969bd6bb863", "n-gram matched": "generated by copilot", "n_lines_longer_change": 8, "n_files_impacted": 1, "longest_chunk": ["    /**", "     * Validates the given contact detail based on the specified type. Documentation generated by Copilot.", "     *", "     * @param contactDetail The contact detail to validate. This should be a phone number or an email address.", "     * @param contactDetailType The type of the contact detail. This should be PHONE_NUMBER or EMAIL_ADDRESS.", "     * @return true if the contact detail is valid, false otherwise.", "     * @throws IllegalArgumentException If the contactDetail is null or empty.", "     */"], "file_path": "src/main/java/com/challenges/helpers/ValidatorHelpers.java"}
{"Link_to_commit": "https://github.com/venzy/chirpy/commit/416c083648d21283c3622fe6bef93c144b2f3d91", "n-gram matched": "generated by copilot", "n_lines_longer_change": 89, "n_files_impacted": 8, "longest_chunk": ["// Code generated by sqlc. DO NOT EDIT.", "// versions:", "//   sqlc v1.28.0", "// source: refresh_tokens.sql", "", "package database", "", "import (", "\t\"context\"", "\t\"database/sql\"", "\t\"time\"", "", "\t\"github.com/google/uuid\"", ")", "", "const createRefreshToken = `-- name: CreateRefreshToken :one", "INSERT INTO refresh_tokens (token, created_at, updated_at, user_id, expires_at)", "VALUES (", "    $1,         -- token", "    NOW(),      -- created_at", "    NOW(),      -- updated_at", "    $2,         -- user_id", "    $3          -- expires_at", ")", "RETURNING token, created_at, updated_at, user_id, expires_at, revoked_at", "`", "", "type CreateRefreshTokenParams struct {", "\tToken     string", "\tUserID    uuid.UUID", "\tExpiresAt time.Time", "}", "", "func (q *Queries) CreateRefreshToken(ctx context.Context, arg CreateRefreshTokenParams) (RefreshToken, error) {", "\trow := q.db.QueryRowContext(ctx, createRefreshToken, arg.Token, arg.UserID, arg.ExpiresAt)", "\tvar i RefreshToken", "\terr := row.Scan(", "\t\t&i.Token,", "\t\t&i.CreatedAt,", "\t\t&i.UpdatedAt,", "\t\t&i.UserID,", "\t\t&i.ExpiresAt,", "\t\t&i.RevokedAt,", "\t)", "\treturn i, err", "}", "", "const deleteRefreshTokenByToken = `-- name: DeleteRefreshTokenByToken :exec", "DELETE FROM refresh_tokens WHERE token = $1", "`", "", "func (q *Queries) DeleteRefreshTokenByToken(ctx context.Context, token string) error {", "\t_, err := q.db.ExecContext(ctx, deleteRefreshTokenByToken, token)", "\treturn err", "}", "", "const getUserIDWithRefreshToken = `-- name: GetUserIDWithRefreshToken :one", "SELECT ", "    users.id AS user_id,", "    refresh_tokens.expires_at,", "    refresh_tokens.revoked_at", "FROM refresh_tokens", "JOIN users ON refresh_tokens.user_id = users.id", "WHERE refresh_tokens.token = $1", "`", "", "type GetUserIDWithRefreshTokenRow struct {", "\tUserID    uuid.UUID", "\tExpiresAt time.Time", "\tRevokedAt sql.NullTime", "}", "", "func (q *Queries) GetUserIDWithRefreshToken(ctx context.Context, token string) (GetUserIDWithRefreshTokenRow, error) {", "\trow := q.db.QueryRowContext(ctx, getUserIDWithRefreshToken, token)", "\tvar i GetUserIDWithRefreshTokenRow", "\terr := row.Scan(&i.UserID, &i.ExpiresAt, &i.RevokedAt)", "\treturn i, err", "}", "", "const revokeRefreshToken = `-- name: RevokeRefreshToken :exec", "UPDATE refresh_tokens", "SET revoked_at = NOW(), updated_at = NOW()", "WHERE token = $1 AND revoked_at IS NULL", "`", "", "func (q *Queries) RevokeRefreshToken(ctx context.Context, token string) error {", "\t_, err := q.db.ExecContext(ctx, revokeRefreshToken, token)", "\treturn err", "}"], "file_path": "main.go"}
{"Link_to_commit": "https://github.com/ariel-ortiz/202411-tc2005b.402/commit/01adcb98584b1087e2ec705df07475a4f53cbe17", "n-gram matched": "generated by copilot", "n_lines_longer_change": 14, "n_files_impacted": 1, "longest_chunk": ["const http = require('http');", "", "const PORT = 8080;", "const IP = '52.20.170.244';", "", "const server = http.createServer((req, res) => {", "    res.statusCode = 200;", "    res.setHeader('Content-Type', 'text/plain');", "    res.end('I am Groot\\n');", "});", "", "server.listen(PORT, () => {", "    console.log(`Server running at http://${IP}:${PORT}/`);", "});"], "file_path": "4. JavaScript servidor/Ejemplo 3/server.js"}
{"Link_to_commit": "https://github.com/RealDotNetDave/dotNetTips.Spargine.8/commit/3a6fcc24b516c8daeeaabf74838fbfefbbfc38d4", "n-gram matched": "generated by copilot", "n_lines_longer_change": 12, "n_files_impacted": 2, "longest_chunk": ["\t\tforeach (var item in items)", "\t\t{", "\t\t\tawait channel.WriteAsync(item);", "\t\t}", "", "\t\tchannel.Lock(); // Lock the channel to allow ListenAsync to complete.", "", "\t\tvar readItems = new List<int>();", "\t\tawait foreach (var item in channel.ListenAsync())", "\t\t{", "\t\t\treadItems.Add(item);", "\t\t}"], "file_path": "source/Unit Tests/dotNetTips.Spargine.Core.Tests/Collections/Generic/Concurrent/ChannelQueueTests.cs"}
{"Link_to_commit": "https://github.com/chantalsantos7/dfa-challenge-3-address-book/commit/8bc57e411577d596c31cdab7c0b067410a9c9223", "n-gram matched": "generated by copilot", "n_lines_longer_change": 29, "n_files_impacted": 4, "longest_chunk": ["        //COPILOT PROMPT: The phone and email overload for findContact should allow searching for an empty string", "        //So it should return the first Contact that has an empty string for phone number and email respectively", "", "        //Below tests generated by Copilot", "        @Test", "        @DisplayName(\"FindContact should return the first Contact with an empty phone number if searchCriteria is an empty string\")", "        public void testFindContactReturnsContactWithEmptyPhoneNumberIfSearchCriteriaIsEmptyString()", "        {", "            Contact contact = mock(Contact.class);", "            when(contact.getName()).thenReturn(\"emptyPhoneNumber\");", "            when(contact.getPhoneNumber()).thenReturn(\"\");", "            when(contact.getEmailAddress()).thenReturn(\"testEmail\");", "            addressBook.addContact(contact);", "            assertEquals(contact, addressBook.findContact(\"\", ContactDetailType.PHONE_NUMBER));", "        }", "", "        @Test", "        @DisplayName(\"FindContact should return the first Contact with an empty email if searchCriteria is an empty string\")", "        public void testFindContactReturnsContactWithEmptyEmailIfSearchCriteriaIsEmptyString()", "        {", "            Contact contact = mock(Contact.class);", "            when(contact.getName()).thenReturn(\"emptyEmail\");", "            when(contact.getPhoneNumber()).thenReturn(\"12345678910\");", "            when(contact.getEmailAddress()).thenReturn(\"\");", "            addressBook.addContact(contact);", "            assertEquals(contact, addressBook.findContact(\"\", ContactDetailType.EMAIL_ADDRESS));", "        }", "", ""], "file_path": "src/test/java/com/challenges/addressbook/AddressBookTest.java"}
{"Link_to_commit": "https://github.com/mixicz/homeassistant-tower-discovery/commit/ee2001f04fc85adc074fca7e97a65f92a9574607", "n-gram matched": "generated by copilot", "n_lines_longer_change": 86, "n_files_impacted": 1, "longest_chunk": ["import time", "import paho.mqtt.client as mqtt", "import json", "import os", "import argparse", "from jinja2 import Environment, FileSystemLoader", "from flask import Flask", "", "", "class Configuration:", "    def __init__(self):", "        self.mqtt_broker = \"mqtt.example.com\"", "        self.mqtt_port = 1883", "        self.mqtt_topic_discovery = \"gateway/{id}/nodes/get\"", "        self.mqtt_topic_nodes = \"gateway/{id}/nodes\"", "        self.mqtt_topic_advertisement = \"homeassistant/devices\"", "        self.advertise_interval = None", "        self.firmware_dir = \"firmware\"", "", "    def load_from_env(self):", "        self.mqtt_broker = os.getenv(\"MQTT_BROKER\", self.mqtt_broker)", "        self.mqtt_port = os.getenv(\"MQTT_PORT\", self.mqtt_port)", "        self.mqtt_topic_discovery = os.getenv(\"MQTT_TOPIC_DISCOVERY\", self.mqtt_topic_discovery)", "        self.mqtt_topic_nodes = os.getenv(\"MQTT_TOPIC_NODES\", self.mqtt_topic_nodes)", "        self.mqtt_topic_advertisement = os.getenv(\"MQTT_TOPIC_ADVERTISEMENT\", self.mqtt_topic_advertisement)", "", "    def parse_cmd_args(self):", "        parser = argparse.ArgumentParser()", "        parser.add_argument(\"--interval\", type=int, help=\"Advertisement interval in seconds\")", "        args = parser.parse_args()", "        if args.interval:", "            self.advertise_interval = args.interval", "        ", "", "config = Configuration()", "config.load_from_env()", "config.parse_cmd_args()", "", "# Jinja template configuration", "template_loader = FileSystemLoader(config.firmware_dir)", "template_env = Environment(loader=template_loader)", "", "# MQTT client setup", "client = mqtt.Client()", "", "def on_connect(client, userdata, flags, rc):", "    print(\"Connected to MQTT broker\")", "    client.subscribe(config.mqtt_topic_nodes)", "", "def on_message(client, userdata, msg):", "    if msg.topic == config.mqtt_topic_nodes:", "        devices = json.loads(msg.payload)", "        advertise_devices(devices)", "", "def send_discovery_message():", "    client.publish(config.mqtt_topic_discovery, \"\")", "", "def advertise_devices(devices):", "    for device in devices:", "        template = template_env.get_template(device[\"firmware\"] + \".yaml\")", "        json_message = template.render(device=device)", "        client.publish(config.mqtt_topic_advertisement, json_message)", "", "def main():", "    client.on_connect = on_connect", "    client.on_message = on_message", "", "    client.connect(config.mqtt_broker, config.mqtt_port, 60)", "", "    if config.advertise_interval:", "        client.loop_start()", "        while True:", "            send_discovery_message()", "            time.sleep(config.advertise_interval)", "    else:", "        client.loop_forever()", "", "# Flask app setup", "app = Flask(__name__)", "", "@app.route('/health')", "def health_check():", "    return 'OK'", "", "if __name__ == \"__main__\":", "    main()"], "file_path": "src/ha-tower-discovery.py"}
{"Link_to_commit": "https://github.com/valhio/webstore-app/commit/5bb71196a2e11da952a3f80d24b2762d37a7d756", "n-gram matched": "generated by copilot", "n_lines_longer_change": 315, "n_files_impacted": 1, "longest_chunk": ["", "", "", "", "// Some more tests for the StoreService", "describe('StoreService', () => {", "  let service: StoreService;", "  let httpMock: HttpTestingController;", "", "  const STORE_BASE_URL = 'http://localhost:8080/api/v1';", "", "  beforeEach(() => {", "    TestBed.configureTestingModule({", "      imports: [HttpClientTestingModule],", "      providers: [StoreService],", "    });", "    service = TestBed.inject(StoreService);", "    httpMock = TestBed.inject(HttpTestingController);", "  });", "", "  afterEach(() => {", "    httpMock.verify();", "  });", "", "  it('should be created', () => {", "    expect(service).toBeTruthy();", "  });", "", "  it('should fetch API data with default parameters', () => {", "    const keyword = '';", "    const page = 0;", "    const size = 10;", "    const sort = 'asc';", "    const expectedUrl = `${STORE_BASE_URL}/products?keyword=${keyword}&page=${page}&size=${size}&sort=${sort}`;", "    const expectedResponse: ApiResponse<Page<Product[]>> = {", "      data: {", "        content: [],", "        totalPages: 0,", "        totalElements: 0,", "        number: 0,", "        size: 10,", "        pageable: {", "          sort: {", "            empty: false,", "            sorted: false,", "            unsorted: false", "          },", "          offset: 0,", "          pageNumber: 0,", "          pageSize: 0,", "          paged: false,", "          unpaged: false", "        },", "        last: false,", "        sort: {", "          empty: false,", "          sorted: false,", "          unsorted: false", "        },", "        numberOfElements: 0,", "        first: false,", "        empty: false", "      },", "      timeStamp: '',", "      statusCode: 0,", "      status: '',", "      message: ''", "    };", "", "    service.fetchApiData().subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should fetch API data with custom parameters', () => {", "    const keyword = 'test';", "    const page = 1;", "    const size = 12;", "    const sort = 'name-asc';", "    const expectedUrl = `${STORE_BASE_URL}/products?keyword=${keyword}&page=${page}&size=${size}&sort=${sort}`;", "    const expectedResponse: ApiResponse<Page<Product[]>> = {", "      data: {", "        content: [],", "        totalPages: 0,", "        totalElements: 0,", "        number: 0,", "        size: 10,", "        pageable: {", "          sort: {", "            empty: false,", "            sorted: false,", "            unsorted: false", "          },", "          offset: 0,", "          pageNumber: 0,", "          pageSize: 0,", "          paged: false,", "          unpaged: false", "        },", "        last: false,", "        sort: {", "          empty: false,", "          sorted: false,", "          unsorted: false", "        },", "        numberOfElements: 0,", "        first: false,", "        empty: false", "      },", "      timeStamp: '',", "      statusCode: 0,", "      status: '',", "      message: ''", "    };", "", "    service.fetchApiData(keyword, page, size, sort).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should find product by id', () => {", "    const productId = 1;", "    const expectedUrl = `${STORE_BASE_URL}/products/${productId}`;", "    const expectedResponse = { id: 1, name: 'Test Product', price: 9.99 };", "", "    service.findProductById(productId).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should place order', () => {", "    const order = { id: 1, name: 'Test Order', total: 9.99 };", "    const expectedUrl = `${STORE_BASE_URL}/orders/new`;", "    const expectedResponse: ApiResponse<any> = {", "      data: order,", "      timeStamp: '',", "      statusCode: 0,", "      status: '',", "      message: ''", "    };", "", "    service.placeOrder(order).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('POST');", "    req.flush(expectedResponse);", "  });", "", "  it('should get orders for user', () => {", "    const userId = '1';", "    const expectedUrl = `${STORE_BASE_URL}/orders/user/${userId}`;", "    const expectedResponse = [{ id: 1, name: 'Test Order', total: 9.99 }];", "", "    service.getOrdersForUser(userId).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should get order by order id', () => {", "    const orderId = '1';", "    const expectedUrl = `${STORE_BASE_URL}/orders/id/${orderId}`;", "    const expectedResponse = { id: 1, name: 'Test Order', total: 9.99 };", "", "    service.getOrderById(orderId).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should get product by product id', () => {", "    const productId = '1';", "    const expectedUrl = `${STORE_BASE_URL}/products/${productId}`;", "    const expectedResponse = { id: 1, name: 'Test Product', price: 9.99 };", "", "    service.getProductByProductId(productId).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should update order status', () => {", "    const orderId = '1';", "    const status = 'SHIPPED';", "    const expectedUrl = `${STORE_BASE_URL}/orders/${orderId}/status/${status}`;", "    const expectedResponse = { id: 1, name: 'Test Order', total: 9.99, status: 'SHIPPED' };", "", "    service.updateOrderStatus(orderId, status).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    req.flush(expectedResponse);", "  });", "", "  it('should update order item status', () => {", "    const orderNumber = '1';", "    const orderItemId = '1';", "    const status = 'SHIPPED';", "    const expectedUrl = `${STORE_BASE_URL}/orders/${orderNumber}/orderItem/${orderItemId}/status/${status}`;", "    const expectedResponse = { id: '1', name: 'Test Order Item', total: 9.99, status: 'SHIPPED' };", "", "    service.updateOrderItemStatus(orderNumber, orderItemId, status).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    req.flush(expectedResponse);", "  });", "", "  it('should get user by user id', () => {", "    const userId = '1';", "    const expectedUrl = `${STORE_BASE_URL}/user/${userId}`;", "    const expectedResponse = { id: '1', name: 'Test User' };", "", "    service.getUserByUserId(userId).subscribe((res) => {", "      expect(res).toEqual(expectedResponse);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('GET');", "    req.flush(expectedResponse);", "  });", "", "  it('should update user first name', () => {", "    const userId = '1';", "    const firstName = 'John';", "    const expectedUrl = `${STORE_BASE_URL}/user/${userId}/first-name`;", "", "    service.updateUserFirstName(userId, firstName).subscribe((res) => {", "      expect(res).toEqual(firstName);", "    });", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    expect(req.request.body).toBe(firstName);", "    req.flush(firstName);", "  });", "", "  it('should update user last name', () => {", "    const userId = '1';", "    const lastName = 'Doe';", "    const expectedUrl = `${STORE_BASE_URL}/user/${userId}/last-name`;", "", "    service.updateUserLastName(userId, lastName).subscribe();", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    expect(req.request.body).toBe(lastName);", "    req.flush(null);", "  });", "", "  it('should update user email', () => {", "    const email = 'test@example.com';", "    const newEmail = 'newtest@example.com';", "    const expectedUrl = `${STORE_BASE_URL}/user/update-email?email=${email}&newEmail=${newEmail}`;", "", "    service.updateUserEmail(email, newEmail).subscribe();", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    req.flush(null);", "  });", "", "  it('should update user phone number', () => {", "    const userId = '1';", "    const phone = '1234567890';", "    const expectedUrl = `${STORE_BASE_URL}/user/${userId}/phone-number`;", "", "    service.updateUserPhoneNumber(userId, phone).subscribe();", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    expect(req.request.body).toBe(phone);", "    req.flush(null);", "  });", "", "  it('should update user address', () => {", "    const userId = '1';", "    const address = '123 Foo St';", "    const expectedUrl = `${STORE_BASE_URL}/user/${userId}/address`;", "", "    service.updateUserAddress(userId, address).subscribe();", "", "    const req = httpMock.expectOne(expectedUrl);", "    expect(req.request.method).toBe('PUT');", "    expect(req.request.body).toBe(address);", "    req.flush(null);", "  });", "});"], "file_path": "src/app/services/store.service.spec.ts"}
{"Link_to_commit": "https://github.com/SalamanderCtesiphon/ticTacToeProject/commit/5023ce46731af48ac967175171638de634430176", "n-gram matched": "copilot to create", "n_lines_longer_change": 83, "n_files_impacted": 1, "longest_chunk": ["    let gameBoard = Array(9).fill(null);", "    let currentPlayer = 'X';", "    let gameOver = false;", "    let winner = null;", "    let moveCount = 0;", "    const winningCombinations = [", "        [0, 1, 2], [3, 4, 5], [6, 7, 8], // Rows", "        [0, 3, 6], [1, 4, 7], [2, 5, 8], // Columns", "        [0, 4, 8], [2, 4, 6] // Diagonals", "    ];", "    const players = {", "        X: { name: 'Player 1', symbol: 'X' },", "        O: { name: 'Player 2', symbol: 'O' }", "    };", "    const gameStatus = {", "        getCurrentPlayer: () => currentPlayer,", "        getGameOver: () => gameOver,", "        getWinner: () => winner,", "        getMoveCount: () => moveCount,", "        getGameBoard: () => gameBoard.slice(),", "        getPlayers: () => players", "    };", "    const gameActions = {", "        makeMove: (index) => {", "            if (gameOver || gameBoard[index] !== null) return false;", "            gameBoard[index] = currentPlayer;", "            moveCount++;", "            if (checkWinner()) {", "                gameOver = true;", "            } else if (moveCount === 9) {", "                gameOver = true; // Draw", "            } else {", "                currentPlayer = currentPlayer === 'X' ? 'O' : 'X';", "            }", "            return true;", "        },", "        resetGame: () => {", "            gameBoard.fill(null);", "            currentPlayer = 'X';", "            gameOver = false;", "            winner = null;", "            moveCount = 0;", "        }", "    };", "    function checkWinner() {", "        for (const combination of winningCombinations) {", "            const [a, b, c] = combination;", "            if (gameBoard[a] && gameBoard[a] === gameBoard[b] && gameBoard[a] === gameBoard[c]) {", "                winner = gameBoard[a];", "                return true;", "            }", "        }", "        return false;", "    }", "    return { gameStatus, gameActions }; ", "}", "", "// Example usage:", "const ticTacToe = createGame();", "console.log(ticTacToe.gameStatus.getGameBoard()); // Initial empty board", "ticTacToe.gameActions.makeMove(0); // Player X makes a move     ", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(1); // Player O makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(3); // Player X makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(4); // Player O makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(6); // Player X makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(7); // Player O makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "ticTacToe.gameActions.makeMove(8); // Player X makes a move", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after move", "console.log(ticTacToe.gameStatus.getWinner()); // Check winner", "console.log(ticTacToe.gameStatus.getGameOver()); // Check if game is over", "ticTacToe.gameActions.resetGame(); // Reset the game", "console.log(ticTacToe.gameStatus.getGameBoard()); // Board after reset", "console.log(ticTacToe.gameStatus.getCurrentPlayer()); // Check current player after reset", "console.log(ticTacToe.gameStatus.getMoveCount()); // Check move count after reset", "console.log(ticTacToe.gameStatus.getPlayers()); // Check players information", "// This code implements a simple Tic Tac Toe game using factory functions.", "// It allows two players to take turns making moves, checks for a winner, and provides methods to reset the game."], "file_path": "app.js"}
{"Link_to_commit": "https://github.com/francke-iot/ics_calendar/commit/8be22375fdb807ca6eb36aa8f288a3e8bb8fd1d1", "n-gram matched": "copilot to create", "n_lines_longer_change": 53, "n_files_impacted": 3, "longest_chunk": ["#!/usr/bin/env python3", "from ics import Calendar, Event", "from datetime import datetime", "import argparse", "import pytz", "", "def parse_arguments():", "    parser = argparse.ArgumentParser(description='Create an ICS file for an event.')", "    parser.add_argument('event_name', type=str, help='Name of the event')", "    parser.add_argument('event_begin', type=str, help='Start time of the event (YYYY-MM-DD HH:MM)')", "    parser.add_argument('event_end', type=str, help='End time of the event (YYYY-MM-DD HH:MM)')", "    parser.add_argument('file_name', type=str, help='Name of the output ICS file')", "    return parser.parse_args()", "", "def create_ics_file(event_name, event_begin, event_end, file_name):", "    ", "", "    # Create a new calendar", "    calendar = Calendar()", "", "    # Create a new event", "    event = Event()", "    event.name = event_name", "    event.begin = event_begin  # CET is UTC+1", "    event.end = event_end  # CET is UTC+1", "    event.organizer = \"Alan Francke:mailto:alan@francke-iot.com\"", "    event.location = \"Microsoft Teams\"", "", "    # Add the event to the calendar", "    calendar.events.add(event)", "", "    # Prompt user to enter meeting description", "", "    event.description = input(\"Enter the description for the event: \")", "", "    # Write the calendar to a file", "    with open(file_name, 'w') as f:", "        f.writelines(calendar)", "", "if __name__ == \"__main__\":", "    args = parse_arguments()", "    cet = pytz.timezone('CET')", "    event_begin = cet.localize(datetime.strptime(args.event_begin, '%Y-%m-%d %H:%M'))", "    event_end = cet.localize(datetime.strptime(args.event_end, '%Y-%m-%d %H:%M'))", "    create_ics_file(args.event_name, event_begin, event_end, args.file_name)", "", "# Example usage", "# event_name = \"Meeting with Bob\"", "# event_begin = datetime(2023, 10, 25, 10, 0)", "# event_end = datetime(2023, 10, 25, 11, 0)", "# file_name = \"meeting.ics\"", "", "#create_ics_file(event_name, event_begin, event_end, file_name)"], "file_path": "main.py"}
{"Link_to_commit": "https://github.com/braelynnesandreth/ProjectSandrethF24/commit/0ee74c6ec4c882729279ce303f657551438ce71c", "n-gram matched": "copilot to create", "n_lines_longer_change": 63, "n_files_impacted": 1, "longest_chunk": ["        public IActionResult CreateTestData()", "        {", "            Officer testOfficer7 = new Officer", "            {", "                Id = \"7\",", "                Firstname = \"Test\",", "                Lastname = \"Officer7\",", "                PhoneNumber = \"123-456-7890\",", "                Email = \"testofficer7@example.com\",", "                SupervisorsOfOfficer = new List<Supervises>()", "            };", "", "            Officer testOfficer8 = new Officer", "            {", "                Id = \"8\",", "                Firstname = \"Test\",", "                Lastname = \"Officer8\",", "                PhoneNumber = \"123-456-7891\",", "                Email = \"testofficer8@example.com\",", "                SupervisorsOfOfficer = new List<Supervises>()", "            };", "", "            Supervisor testSupervisor9 = new Supervisor", "            {", "                Id = \"9\",", "                Firstname = \"Test\",", "                Lastname = \"Supervisor9\",", "                PhoneNumber = \"123-456-7892\",", "                Email = \"testsupervisor9@example.com\",", "                OfficersSupervised = new List<Supervises>()", "            };", "", "            Supervisor testSupervisor10 = new Supervisor", "            {", "                Id = \"10\",", "                Firstname = \"Test\",", "                Lastname = \"Supervisor10\",", "                PhoneNumber = \"123-456-7893\",", "                Email = \"testsupervisor10@example.com\",", "                OfficersSupervised = new List<Supervises>()", "            };", "", "            // Establish the relationship between Officer 7 and Supervisor 9", "            Supervises supervises = new Supervises", "            {", "                Officer = testOfficer7,", "                Supervisor = testSupervisor9,", "                StartDate = DateTime.Now", "            };", "", "            testOfficer7.SupervisorsOfOfficer.Add(supervises);", "            testSupervisor9.OfficersSupervised.Add(supervises);", "", "            // Add the test data to the database", "            _database.Officer.Add(testOfficer7);", "            _database.Officer.Add(testOfficer8);", "            _database.Supervisor.Add(testSupervisor9);", "            _database.Supervisor.Add(testSupervisor10);", "            _database.Supervises.Add(supervises);", "            _database.SaveChanges();", "", "            return RedirectToAction(\"Index\");", "        }"], "file_path": "F24S2DiscussionSolutionSandreth/DiscussionMvcSandreth/Controllers/OfficerController.cs"}
{"Link_to_commit": "https://github.com/AdamJCavanaugh/BrainGames/commit/ee23d26fb63239989d05977278db7b36bcf84a9d", "n-gram matched": "copilot to create", "n_lines_longer_change": 172, "n_files_impacted": 7, "longest_chunk": ["class Game {", "    constructor() {", "        this.currentWord = '';", "        this.maxAttempts = 6;", "        this.currentAttempts = 0;", "        this.guessedWords = [];", "    }", "", "    startGame() {", "        this.currentWord = WordChecker.giveNewWord()", "        console.log(this.currentWord)", "        this.currentAttempts = 0;", "        this.guessedWords = [];", "        this.updateUI();", "        this.setFeedback('New game started. Guess the word!');", "    }", "", "    guessWord(word) {", "        if (this.currentAttempts >= this.maxAttempts) {", "            this.setFeedback('No more attempts left!');", "            return;", "        }", "", "        if (!WordChecker.isValidWord(word)) {", "            this.setFeedback('Invalid word. Try again.');", "            return;", "        }", "", "        this.guessedWords.push(this.generateFeedbackHTML(word));", "        this.currentAttempts++;", "", "        if (this.checkWin(word)) {", "            this.updateUI();", "            this.setFeedback('Congratulations! You guessed the word!');", "        } else if (this.checkLoss()) {", "            this.updateUI();", "            this.setFeedback(`Game over! The word was ${this.currentWord}.`);", "        } else {", "            this.updateUI();", "        }", "    }", "", "    checkWin(word) {", "        if (word === this.currentWord) {", "            document.getElementById('guessInput').style.display = 'none';", "            document.getElementById('makeGuess').style.display = 'none';", "            return true;", "        }", "        return false;", "    }", "", "    checkLoss() {", "        if (this.currentAttempts >= this.maxAttempts) {", "            document.getElementById('guessInput').style.display = 'none';", "            document.getElementById('makeGuess').style.display = 'none';", "            return true;", "        }", "        return false;", "    }", "", "    setFeedback(message) {", "        document.getElementById('feedback').innerText = message;", "    }", "", "    updateUI() {", "        document.getElementById('attemptsLeft').innerText = `${this.maxAttempts - this.currentAttempts} attempts left.`;", "        document.getElementById('guessedWords').innerHTML = `Guessed Words:<br>${this.guessedWords.join('<br>')}`;", "    }", "", "    generateFeedbackHTML(word) {", "        const feedback = WordChecker.compareWords(word, this.currentWord);", "        let feedbackHTML = '';", "", "        for (let i = 0; i < word.length; i++) {", "            if (feedback[i] === word[i].toUpperCase()) {", "                feedbackHTML += `<span class=\"correct\">${word[i]}</span>`;", "            } else if (feedback[i] === word[i].toLowerCase()) {", "                feedbackHTML += `<span class=\"misplaced\">${word[i]}</span>`;", "            } else {", "                feedbackHTML += `<span class=\"incorrect\">${word[i]}</span>`;", "            }", "        }", "", "        return feedbackHTML;", "    }", "}", "", "class Player {", "    constructor(name) {", "        this.name = name;", "        this.score = 0;", "    }", "", "    makeGuess(game, word) {", "        game.guessWord(word);", "    }", "}", "", "class WordChecker {", "    constructor(wordList) {", "        this.wordList = wordList;", "    }", "", "    static async loadWords() {", "        try {", "            const response = await fetch('words.txt');", "            const text = await response.text();", "            this.wordList = text.split('\\n').map(word => word.trim()).filter(word => word.length === 5);", "        } catch (error) {", "            console.error('Error loading words:', error);", "        }", "    }", "", "    static giveNewWord() {", "        return this.wordList[Math.floor(Math.random() * this.wordList.length)];", "    }", "", "    static isValidWord(word) {", "        if (this.wordList.includes(word)) {", "            return true", "        }", "        return false;", "    }", "", "    static compareWords(guess, target) {", "        let feedback = '';", "", "        for (let i = 0; i < guess.length; i++) {", "            if (guess[i] === target[i]) {", "                feedback += guess[i].toUpperCase();", "            } else if (target.includes(guess[i])) {", "                feedback += guess[i].toLowerCase();", "            } else {", "                feedback += '_';", "            }", "        }", "", "        return feedback;", "    }", "}", "", "const game = new Game();", "const wordList = new WordChecker()", "const player = new Player('John');", "", "function makeGuess() {", "    const guessInput = document.getElementById('guessInput').value.toLowerCase();", "    if (guessInput.length === 5) {", "        player.makeGuess(game, guessInput);", "        document.getElementById('guessInput').value = '';", "    } else {", "        game.setFeedback('Please enter a 5-letter word.');", "    }", "}", "", "function resetGame() {", "    document.getElementById('guessInput').style.display = 'inline';", "    document.getElementById('guessInput').value = '';", "    document.getElementById('makeGuess').style.display = 'inline';", "    game.startGame();", "}", "", "window.onload = async () => {", "    await WordChecker.loadWords();", "    game.startGame();", "}", "", "document.getElementById('guessInput').addEventListener('keydown', function(event) {", "    if (event.key === 'Enter') {", "        makeGuess();", "    }", "});"], "file_path": "wordle/game.js"}
{"Link_to_commit": "https://github.com/Itablera/learning-demystify-ai/commit/0d0e8bd8707cccba3115f7bb20ac2acee5362c8b", "n-gram matched": "copilot to create", "n_lines_longer_change": 199, "n_files_impacted": 64, "longest_chunk": ["import { ingestDocument, searchDocuments } from '@workspace/use-cases'", "import {", "  IngestDocumentRequestSchema,", "  SearchDocumentsRequestSchema,", "  DocumentListSchema,", "  SearchResultsSchema,", "  BaseResponseSchema,", "  DataResponseSchema,", "  DataResponse,", "  SearchResults,", "} from '@workspace/api'", "import { getDocumentRepository } from '@/repositories'", "import { langchain } from '@workspace/integrations'", "import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter'", "import { RoutesProvider } from '@/index'", "import { DocumentSchema } from '@workspace/domains'", "import z from 'zod'", "import config from '@workspace/env'", "", "const docParam = z.object({", "  id: z.string().uuid('Invalid document ID'),", "})", "", "/**", " * Document domain routes for the API", " */", "export async function documentRoutes(routes: RoutesProvider): Promise<void> {", "  // Initialize dependencies", "  const textSplitter = new RecursiveCharacterTextSplitter({", "    chunkSize: 1000,", "    chunkOverlap: 200,", "  })", "  const documentRepository = getDocumentRepository()", "  const vectorStore = new langchain.QdrantVectorStore(config.vectorDb.qdrantUrl, 'documents')", "", "  // Get a list of all documents", "  routes.get('/', {", "    schema: {", "      tags: ['documents'],", "      response: {", "        200: DataResponseSchema(DocumentListSchema),", "      },", "    },", "    handler: async () => {", "      const documents = await documentRepository.listDocuments()", "      return {", "        success: true,", "        timestamp: new Date().toISOString(),", "        data: { documents },", "      }", "    },", "  })", "", "  // Get a single document by ID", "  routes.get('/:id', {", "    schema: {", "      tags: ['documents'],", "      params: docParam,", "      response: {", "        200: DataResponseSchema(DocumentSchema),", "        404: BaseResponseSchema,", "      },", "    },", "    handler: async (request, reply) => {", "      const { id } = request.params", "      const document = await documentRepository.getDocument(id)", "", "      if (!document) {", "        return reply.code(404).send({", "          success: false,", "          message: 'Document not found',", "          timestamp: new Date().toISOString(),", "        })", "      }", "", "      return {", "        success: true,", "        timestamp: new Date().toISOString(),", "        data: document,", "      }", "    },", "  })", "", "  // Ingest a new document", "  routes.post('/', {", "    schema: {", "      tags: ['documents'],", "      body: IngestDocumentRequestSchema,", "      response: {", "        200: DataResponseSchema(DocumentSchema),", "        500: BaseResponseSchema,", "      },", "    },", "    handler: async (request, reply) => {", "      try {", "        const { content, metadata, chunkingOptions } = request.body as {", "          content: string", "          metadata?: Record<string, unknown>", "          chunkingOptions?: { chunkSize: number; chunkOverlap: number }", "        }", "", "        const document = await ingestDocument(", "          content,", "          metadata || {},", "          chunkingOptions || { chunkSize: 1000, chunkOverlap: 200 },", "          { documentRepository, textSplitter, vectorStore }", "        )", "", "        return {", "          success: true,", "          timestamp: new Date().toISOString(),", "          data: document,", "        }", "      } catch (error) {", "        routes.log.error(error)", "        return reply.code(500).send({", "          success: false,", "          message: error instanceof Error ? error.message : 'Failed to ingest document',", "          timestamp: new Date().toISOString(),", "        })", "      }", "    },", "  })", "", "  // Delete a document", "  routes.delete('/:id', {", "    schema: {", "      tags: ['documents'],", "      params: docParam,", "      response: {", "        200: BaseResponseSchema,", "        404: BaseResponseSchema,", "      },", "    },", "    handler: async (request, reply) => {", "      const { id } = request.params", "      const document = await documentRepository.getDocument(id)", "", "      if (!document) {", "        return reply.code(404).send({", "          success: false,", "          message: 'Document not found',", "          timestamp: new Date().toISOString(),", "        })", "      }", "", "      await documentRepository.deleteDocument(id)", "      return {", "        success: true,", "        message: 'Document deleted successfully',", "        timestamp: new Date().toISOString(),", "      }", "    },", "  })", "", "  // Search documents", "  routes.post('/search', {", "    schema: {", "      tags: ['documents'],", "      body: SearchDocumentsRequestSchema,", "      response: {", "        200: DataResponseSchema(SearchResultsSchema),", "        500: BaseResponseSchema,", "      },", "    },", "    handler: async (request, reply) => {", "      try {", "        const {", "          query,", "          limit = 10,", "          threshold = 0.5,", "        } = request.body as {", "          query: string", "          limit?: number", "          threshold?: number", "        }", "", "        const results = await searchDocuments(query, { limit, threshold }, { vectorStore })", "        const response: DataResponse<SearchResults> = {", "          success: true,", "          timestamp: new Date().toISOString(),", "          data: {", "            results,", "            count: results.length,", "          },", "        }", "", "        return response", "      } catch (error) {", "        routes.log.error(error)", "        return reply.code(500).send({", "          success: false,", "          message: error instanceof Error ? error.message : 'Failed to search documents',", "          timestamp: new Date().toISOString(),", "        })", "      }", "    },", "  })", "}"], "file_path": "apps/api/src/domains/document/schema.ts"}
{"Link_to_commit": "https://github.com/Gal-Izhaky/SuperReminder/commit/88c4fefc8037391ea4c21ddceb02c4d244e89971", "n-gram matched": "copilot to create", "n_lines_longer_change": 66, "n_files_impacted": 37, "longest_chunk": ["// Internal imports", "import styles from \"./ItemView.styles\";", "import ChooseAmount from '../ChooseAmount/ChooseAmount';", "", "// Constants", "const DEFAULT_UNIT = \"\u05d9\u05d7'\";", "const WEIGHTED_UNITS = [\"100 \u05d2\u05e8\u05dd\", '100 \u05de\"\u05dc'];", "", "// Assets", "const delete_image = require(\"../../assets/images/delete.png\");", "", "/**", " * ItemView Component", " * Displays an item card with name, amount selector, and delete button", " *", " * @param {Object} item - The item to display", " * @param {Function} handleDelete - Callback for delete action", " * @param {Function} addAmount - Callback for amount changes", " */", "const ItemView = ({ item, handleDelete, addAmount }) => {", "    // Unit calculations if type is addItem", "", "    const unit = item.measurementUnit.replace('\u05e7\"\u05d2', \"100 \u05d2\u05e8\u05dd\").replace(\"\u05dc\u05d9\u05d8\u05e8\", '100 \u05de\"\u05dc');", "    const weighted = item.weighted && WEIGHTED_UNITS.includes(unit);", "", "    const finalUnit = weighted ? unit.replace(\"100 \", \"\") : DEFAULT_UNIT;", "    const unitCalcResults = {", "        step: weighted ? 100 : 1,", "        maxAmount: finalUnit == \"\u05d9\u05d7'\" ? 10000 : 100000,", "        finalUnit: finalUnit,", "        weighted: weighted,", "    };", "", "", "    return (", "        <View style={[styles.card, styles.shadow]}>", "            {/* Item name */}", "            <Text", "                style={[styles.right, styles.text]}", "                numberOfLines={2}", "                adjustsFontSizeToFit={true}", "            >", "                {item.name}", "            </Text>", "", "            {/* Amount selector and delete button container */}", "            <View style={styles.alignLeft}>", "                {/* Amount selector */}", "                <ChooseAmount", "                    unitCalcResults={unitCalcResults}", "                    onAmountChange={(amount) => addAmount(amount)}", "                    item={item}", "                    displayReset={false}", "                    small={true}", "                />", "", "                {/* Delete button */}", "                <TouchableOpacity onPress={handleDelete} activeOpacity={1}>", "                    <Image style={styles.delete} source={delete_image} />", "                </TouchableOpacity>", "            </View>", "        </View>", "    );", "};", "", "export default ItemView;"], "file_path": "src/components/ItemView/ItemView.js"}
{"Link_to_commit": "https://github.com/PICO443/dickens/commit/5cf3654ec47b1940e7959214941da2f480bc2ff7", "n-gram matched": "chatgpt to implement", "n_lines_longer_change": 85, "n_files_impacted": 21, "longest_chunk": ["// TODO remove, this demo shouldn't need to reset the theme.", "const defaultTheme = createTheme();", "", "export function StudentProfileCard() {", "  const [open, setOpen] = React.useState(true);", "  const toggleDrawer = () => {", "    setOpen(!open);", "  };", "", "  return (", "    <ThemeProvider theme={defaultTheme}>", "      <Box sx={{ display: \"flex\" }}>", "        <CssBaseline />", "        <AppBar position=\"absolute\" open={open}>", "          <Toolbar", "            sx={{", "              pr: \"24px\", // keep right padding when drawer closed", "            }}", "          >", "            <IconButton", "              edge=\"start\"", "              color=\"inherit\"", "              aria-label=\"open drawer\"", "              onClick={toggleDrawer}", "              sx={{", "                marginRight: \"36px\",", "                ...(open && { display: \"none\" }),", "              }}", "            >", "              <MenuIcon />", "            </IconButton>", "            <Typography", "              component=\"h1\"", "              variant=\"h6\"", "              color=\"inherit\"", "              noWrap", "              sx={{ flexGrow: 1 }}", "            >", "              Dashboard", "            </Typography>", "            <IconButton color=\"inherit\">", "              <Badge badgeContent={4} color=\"secondary\">", "                <NotificationsIcon />", "              </Badge>", "            </IconButton>", "          </Toolbar>", "        </AppBar>", "        <Drawer variant=\"permanent\" open={open}>", "          <Toolbar", "            sx={{", "              display: \"flex\",", "              alignItems: \"center\",", "              justifyContent: \"flex-end\",", "              px: [1],", "            }}", "          >", "            <IconButton onClick={toggleDrawer}>", "              <ChevronLeftIcon />", "            </IconButton>", "          </Toolbar>", "          <Divider />", "          <List component=\"nav\">", "            {mainListItems}", "            <Divider sx={{ my: 1 }} />", "            {secondaryListItems}", "          </List>", "        </Drawer>", "        <Box", "          component=\"main\"", "          sx={{", "            backgroundColor: (theme) =>", "              theme.palette.mode === \"light\"", "                ? theme.palette.grey[100]", "                : theme.palette.grey[900],", "            flexGrow: 1,", "            height: \"100vh\",", "            overflow: \"auto\",", "          }}", "        >", "          ", "        </Box>", "      </Box>", "    </ThemeProvider>", "  );", "}"], "file_path": "src/components/StudentProfile/listItems.js"}
{"Link_to_commit": "https://github.com/otabeknarz/smartfit-backend/commit/930b685d21f495a96878270f1b61650efbf14436", "n-gram matched": "help of chatgpt", "n_lines_longer_change": 85, "n_files_impacted": 2, "longest_chunk": ["from rest_framework.permissions import AllowAny", "from django.utils.decorators import method_decorator", "from django.views.decorators.csrf import csrf_exempt", "from django.shortcuts import get_object_or_404", "from decimal import Decimal", "from payments.models import Payment", "", "", "@method_decorator(csrf_exempt, name=\"dispatch\")", "class PaymeAPIView(APIView):", "    permission_classes = [AllowAny]", "", "    def post(self, request):", "        data = request.data", "        method = data.get(\"method\")", "        params = data.get(\"params\", {})", "        request_id = data.get(\"id\")", "", "        handler = {", "            \"CheckPerformTransaction\": self.check_perform_transaction,", "            \"CreateTransaction\": self.create_transaction,", "            \"PerformTransaction\": self.perform_transaction,", "            \"CheckTransaction\": self.check_transaction,", "            \"CancelTransaction\": self.cancel_transaction,", "        }.get(method)", "", "        if handler:", "            return handler(params, request_id)", "", "        return Response({", "            \"jsonrpc\": \"2.0\",", "            \"error\": {\"code\": -32601, \"message\": \"Method not found\"},", "            \"id\": request_id", "        })", "", "    def check_perform_transaction(self, params, request_id):", "        try:", "            payment_id = params[\"account\"][\"payment_id\"]", "            amount = Decimal(params[\"amount\"]) / 100  # Payme sends amount in tiyin", "            payment = get_object_or_404(Payment, id=payment_id)", "", "            if payment.status != Payment.StatusChoices.PENDING:", "                return self.error_response(-31050, \"Transaction already processed\", request_id)", "", "            if amount != payment.amount:", "                return self.error_response(-31001, \"Incorrect amount\", request_id)", "", "            return self.success_response({\"allow\": True}, request_id)", "        except Exception:", "            return self.error_response(-31099, \"Error in checking transaction\", request_id)", "", "    def create_transaction(self, params, request_id):", "        try:", "            payment_id = params[\"account\"][\"payment_id\"]", "            payme_transaction_id = params[\"id\"]", "            payment = get_object_or_404(Payment, id=payment_id)", "", "            if payment.transaction_id and payment.transaction_id != payme_transaction_id:", "                return self.error_response(-31008, \"Transaction already exists\", request_id)", "", "            payment.transaction_id = payme_transaction_id", "            payment.save()", "", "            return self.success_response({", "                \"create_time\": int(time.time() * 1000),", "                \"transaction\": payme_transaction_id,", "                \"state\": 1,", "                \"receivers\": None,", "            }, request_id)", "", "        except Exception:", "            return self.error_response(-31099, \"Failed to create transaction\", request_id)", "", "    def perform_transaction(self, params, request_id):", "        try:", "            transaction_id = params[\"id\"]", "            payment = get_object_or_404(Payment, transaction_id=transaction_id)", "", "            if payment.status == Payment.StatusChoices.COMPLETED:", "                return self.success_response({", "                    \"transaction\": transaction_id,", "                    \"perform_time\": int(payment.updated_at.timestamp() * 1000),", "                    \"state\": 2,", "                }, request_id)", ""], "file_path": "payments/api/views.py"}
{"Link_to_commit": "https://github.com/DivyanshuSinghania/LangChain/commit/cad5f67c1253fd0602f5193b2e0c64bda989627f", "n-gram matched": "help of chatgpt", "n_lines_longer_change": 10, "n_files_impacted": 5, "longest_chunk": ["# Serve static files (CSS, JS)", "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")", "", "# Templates", "templates = Jinja2Templates(directory=\"frontend\")", "", "@app.get(\"/\", response_class=HTMLResponse)", "async def home(request: Request):", "    return templates.TemplateResponse(\"index.html\", {\"request\": request})", ""], "file_path": "LC_Basics/app.py"}
{"Link_to_commit": "https://github.com/merbinr/bug-bounty/commit/90fe978a990500d29234aa7e33caa40f045a275c", "n-gram matched": "help of chatgpt", "n_lines_longer_change": 80, "n_files_impacted": 17, "longest_chunk": ["import subprocess", "import os", "import json", "from typing import List", "from modules import config", "", "", "def prepare_nuclei_target_file(groups: List[List[dict]], target_name: str) -> str:", "    \"\"\"", "    Each group is a list of items (each item from httpx).", "    We want to choose 1 URL from each group for scanning,", "    plus any items that had missing fields.", "    Writes them to `nuclei_targets_{target_name}.txt`.", "    Returns the path to that file.", "    \"\"\"", "    output_file = f\"nuclei_targets_{target_name}.txt\"", "    urls = []", "    for group in groups:", "        # Just pick the first item in each group", "        if group and len(group) > 0:", "            item = group[0]", "            urls.append(item[\"url\"])", "", "    # Write to file", "    with open(output_file, \"w\", encoding=\"utf-8\") as fh:", "        for url in urls:", "            fh.write(url + \"\\n\")", "", "    return output_file", "", "", "def run_nuclei(target_file: str, target_name: str) -> str:", "    \"\"\"", "    Runs nuclei using the target_file, saves JSON results to config.NUCLEI_OUTPUT_JSON", "    For clarity, let's store separate JSON for each domain to avoid collisions:", "    e.g. nuclei_scan_output_{target_name}.json", "    Returns path to the JSON file.", "    \"\"\"", "    output_json = f\"nuclei_scan_output_{target_name}.json\"", "    cmd = [", "        config.NUCLEI_BIN,", "        \"-l\",", "        target_file,", "        \"-t\",", "        config.NUCLEI_TEMPLATES,", "        \"-c\",", "        \"50\",", "        \"-bs\",", "        \"100\",", "        \"--json-export\",", "        output_json,", "    ]", "    subprocess.run(cmd, check=True)", "    return output_json", "", "", "def parse_nuclei_output(json_export_file: str) -> List[dict]:", "    \"\"\"", "    Nuclei's --json-export produces a JSON array of objects.", "    Each object has keys like `info.description`, `info.severity`, and `url`.", "    Returns a list of dicts with the relevant fields.", "    \"\"\"", "    if not os.path.exists(json_export_file):", "        return []", "", "    with open(json_export_file, \"r\", encoding=\"utf-8\") as fh:", "        try:", "            data = json.load(fh)", "        except:", "            data = []", "", "    # data is a list of objects", "    results = []", "    for item in data:", "        description = item.get(\"info\", {}).get(\"description\", \"N/A\")", "        severity = item.get(\"info\", {}).get(\"severity\", \"N/A\")", "        url = item.get(\"host\", \"N/A\")  # or item.get(\"matched\")", "        results.append({\"url\": url, \"description\": description, \"severity\": severity})", "", "    return results"], "file_path": "modules/screenshot.py"}
