
LINK NUMBER 1
Not enough lines

LINK NUMBER 2

File path: src/main/java/net/enabify/mBFPorter/MBFPorter.java
"<?xml version=""1.0"" encoding=""UTF-8""?>
<project xmlns=""http://maven.apache.org/POM/4.0.0""
         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
    <modelVersion>4.0.0</modelVersion>

    <groupId>net.enabify</groupId>
    <artifactId>MBFPorter</artifactId>
    <version>1.0-SNAPSHOT</version>
    <packaging>jar</packaging>

    <name>MBFPorter</name>

    <properties>
        <java.version>17</java.version>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>

    <build>
        <defaultGoal>clean package</defaultGoal>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.13.0</version>
                <configuration>
                    <source>${java.version}</source>
                    <target>${java.version}</target>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-shade-plugin</artifactId>
                <version>3.5.3</version>
                <executions>
                    <execution>
                        <phase>package</phase>
                        <goals>
                            <goal>shade</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
        <resources>
            <resource>
                <directory>src/main/resources</directory>
                <filtering>true</filtering>
            </resource>
        </resources>
    </build>

    <repositories>
        <repository>
            <id>papermc-repo</id>
            <url>https://repo.papermc.io/repository/maven-public/</url>
        </repository>
        <repository>
            <id>sonatype</id>
            <url>https://oss.sonatype.org/content/groups/public/</url>
        </repository>
        <repository>
            <id>sk89q-repo</id>
            <url>https://maven.enginehub.org/repo/</url>
        </repository>
    </repositories>

    <dependencies>
        <dependency>
            <groupId>dev.folia</groupId>
            <artifactId>folia-api</artifactId>
            <version>1.20.4-R0.1-SNAPSHOT</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.sk89q.worldguard</groupId>
            <artifactId>worldguard-bukkit</artifactId>
            <version>7.0.13</version>
            <scope>provided</scope>
        </dependency>
    </dependencies>
</project>"

LINK NUMBER 3

File path: rag_chatbot.py
"from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import os
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from typing import List

app = FastAPI()

with open(""train.json"", ""r"", encoding=""utf-8"") as f:
    tickets = json.load(f)

embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

ticket_texts = []
ticket_responses = []
ticket_metadata = []

for ticket in tickets:
    metadata = f""Title: {ticket['title']}\nCategory: {ticket['category']}\nDescription: {ticket['description']}""
    dialog = ""\n"".join([f""{m['role'].capitalize()}: {m['text']}"" for m in ticket[""history""]])
    combined_text = f""{metadata}\nConversation:\n{dialog}""
    ticket_texts.append(combined_text)
    ticket_responses.append(ticket[""next_engineer_reply""])
    ticket_metadata.append({""category"": ticket[""category""]})

embeddings = embedding_model.encode(ticket_texts, convert_to_numpy=True)
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None

def generate_reply(messages, model=""gpt-4"", provider=""openai"", **kwargs):
    if provider == ""openai"":
        if OpenAI is None:
            raise ImportError(""OpenAI client not available."")
        api_key = os.getenv(""OPENAI_API_KEY"")
        if not api_key:
            raise ValueError(""Set the OPENAI_API_KEY environment variable."")
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=kwargs.get(""temperature"", 0.4)
        )
        return response.choices[0].message.content.strip()
    else:
        raise ValueError(f""Unsupported provider: {provider}"")

class Message(BaseModel):
    role: str
    text: str

class TicketInput(BaseModel):
    title: str
    category: str
    description: str
    history: List[Message]

@app.post(""/predict"")
def predict_reply(ticket: TicketInput):
    query_metadata = f""Title: {ticket.title}\nCategory: {ticket.category}\nDescription: {ticket.description}""
    dialog = ""\n"".join([f""{m.role.capitalize()}: {m.text}"" for m in ticket.history])
    query_text = f""{query_metadata}\nConversation:\n{dialog}""
    query_embedding = embedding_model.encode([query_text], convert_to_numpy=True)

    distances, indices = index.search(query_embedding, 20)

    boosted, fallback = [], []
    for dist, idx in zip(distances[0], indices[0]):
        candidate_category = ticket_metadata[idx]['category']
        adjusted_dist = dist * 0.85 if candidate_category == ticket.category else dist
        (boosted if candidate_category == ticket.category else fallback).append((adjusted_dist, idx))

    boosted.sort(key=lambda x: x[0])
    fallback.sort(key=lambda x: x[0])
    needed = 3 - len(boosted)
    top_adjusted = boosted + fallback[:needed] if needed > 0 else boosted[:3]

    prompt_parts = [""You are a helpful technical support engineer.\n""]
    for _, idx in top_adjusted:
        prompt_parts.append(f""Example:\n{ticket_texts[idx]}\nEngineer: {ticket_responses[idx]}\n"")
    prompt_parts.append(""Now, consider this support case:\n"")
    prompt_parts.append(query_text)
    prompt_parts.append(""Engineer:"")
    full_prompt = ""\n"".join(prompt_parts)

    messages = [
        {""role"": ""system"", ""content"": ""You are a technical support engineer.""},
        {""role"": ""user"", ""content"": full_prompt}
    ]

    try:
        reply = generate_reply(messages)
        return {""reply"": reply}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == ""__main__"":
    uvicorn.run(""rag_api_server:app"", host=""0.0.0.0"", port=8000, reload=True)"

LINK NUMBER 4
Not enough lines

LINK NUMBER 5
Error fetching diff

LINK NUMBER 6
Error fetching diff

LINK NUMBER 7
Error fetching diff

LINK NUMBER 8
Not enough lines

LINK NUMBER 9

File path: chatGPT/initial/fileServer/server.js
"const express = require('express');
const session = require('express-session');
const cookieParser = require('cookie-parser');
const bcrypt = require('bcrypt');

const app = express();
const PORT = 3000;

// In-memory ""database""
const users = {};

app.use(express.urlencoded({ extended: true }));
app.use(express.json());
app.use(cookieParser());

// Session configuration
app.use(session({
  secret: 'super-secret-key',
  resave: false,
  saveUninitialized: false,
  cookie: { maxAge: 60000 } // 1 minute for demo
}));

// Home route
app.get('/', (req, res) => {
  if (req.session.username) {
    res.send(`Welcome back, ${req.session.username}! <a href=""/logout"">Logout</a>`);
  } else {
    res.send('Hello, guest! <a href=""/login"">Login</a> or <a href=""/register"">Register</a>');
  }
});

// Registration route
app.get('/register', (req, res) => {
  res.send(`
    <form method=""POST"" action=""/register"">
      <input name=""username"" placeholder=""Username"" required />
      <input name=""password"" type=""password"" placeholder=""Password"" required />
      <button type=""submit"">Register</button>
    </form>
  `);
});

app.post('/register', async (req, res) => {
  const { username, password } = req.body;
  if (users[username]) {
    return res.send('User already exists. <a href=""/register"">Try again</a>');
  }
  const hashedPassword = await bcrypt.hash(password, 10);
  users[username] = { username, password: hashedPassword };
  res.send('Registration successful! <a href=""/login"">Login</a>');
});

// Login route
app.get('/login', (req, res) => {
  res.send(`
    <form method=""POST"" action=""/login"">
      <input name=""username"" placeholder=""Username"" required />
      <input name=""password"" type=""password"" placeholder=""Password"" required />
      <button type=""submit"">Login</button>
    </form>
  `);
});

app.post('/login', async (req, res) => {
  const { username, password } = req.body;
  const user = users[username];
  if (!user || !(await bcrypt.compare(password, user.password))) {
    return res.send('Invalid credentials. <a href=""/login"">Try again</a>');
  }
  req.session.username = username;
  res.redirect('/');
});

// Logout route
app.get('/logout', (req, res) => {
  req.session.destroy(err => {
    if (err) return res.send('Error logging out.');
    res.clearCookie('connect.sid');
    res.redirect('/');
  });
});

// Start server
app.listen(PORT, () => {
  console.log(`Server running at http://localhost:${PORT}`);
});
"

LINK NUMBER 10
Not enough lines

LINK NUMBER 11
Not enough lines

LINK NUMBER 12
Error fetching diff

LINK NUMBER 13
Error fetching diff

LINK NUMBER 14
Error fetching diff

LINK NUMBER 15
Not enough lines

LINK NUMBER 16
Not enough lines

LINK NUMBER 17
Not enough lines

LINK NUMBER 18
Not enough lines

LINK NUMBER 19
Error fetching diff

LINK NUMBER 20
Error fetching diff

LINK NUMBER 21
Error fetching diff

LINK NUMBER 22
Not enough lines

LINK NUMBER 23

File path: Mati_blocks.py
"import tkinter as tk
import random

class NumberTableApp:
    def __init__(self, root):
        self.root = root
        self.root.title(""Szám táblázat"")
        
        self.rows = 5
        self.cols = 4
        self.table = [[None for _ in range(self.cols)] for _ in range(self.rows)]
        
        self.buttons = []
        for col in range(self.cols):
            btn = tk.Button(root, text=f""Oszlop {col+1}"", command=lambda c=col: self.add_number_to_column(c))
            btn.grid(row=0, column=col)
            self.buttons.append(btn)
        
        self.cells = [[tk.Label(root, text="""", width=10, height=2, relief=""ridge"", borderwidth=2) 
                       for _ in range(self.cols)] for _ in range(self.rows)]
        
        for r in range(self.rows):
            for c in range(self.cols):
                self.cells[r][c].grid(row=r+1, column=c)
        
        self.number_var = tk.StringVar(value=str(random.choice([2, 4, 8, 16, 32, 64])))
        tk.Label(root, text=""Következő szám:"").grid(row=self.rows+1, column=0, columnspan=2)
        self.number_entry = tk.Entry(root, textvariable=self.number_var, font=(""Arial"", 14))
        self.number_entry.grid(row=self.rows+1, column=2, columnspan=2)
    
    def add_number_to_column(self, col):
        new_number = int(self.number_var.get())
        last_empty = None
        
        for row in range(self.rows):  # Fentről lefelé keres
            if self.table[row][col] is None:
                last_empty = row
                break
            
        if last_empty is not None:
            self.table[last_empty][col] = new_number
        else:
            return  # Ha tele van az oszlop, nem csinál semmit
        
        for row in range(self.rows - 1, 0, -1):  # Ellenőrzi az összevonást
            if self.table[row][col] is not None and self.table[row][col] == self.table[row - 1][col]:
                self.table[row - 1][col] *= 2
                self.table[row][col] = None
                last_empty = row
        
        self.update_display()
        self.generate_new_number()
    
    def update_display(self):
        for r in range(self.rows):
            for c in range(self.cols):
                self.cells[r][c].config(text=str(self.table[r][c]) if self.table[r][c] is not None else """")
    
    def generate_new_number(self):
        self.number_var.set(str(random.choice([2, 4, 8, 16, 32, 64])))

if __name__ == ""__main__"":
    root = tk.Tk()
    app = NumberTableApp(root)
    root.mainloop()"

LINK NUMBER 24
Not enough lines

LINK NUMBER 25

File path: phase-1/hard/eval-95/gpt/test.py
"class TestCheckDictCase(unittest.TestCase):
    def setUp(self):
        # If check_dict_case is in another module, replace with the proper import.
        from __main__ import check_dict_case  # noqa: E402
        self.func: Callable = check_dict_case

    # --- Positive cases ------------------------------------------------------
    def test_all_lowercase_keys(self):
        self.assertTrue(
            self.func({""a"": ""apple"", ""b"": ""banana"", ""c"": ""cherry""}),
            ""Should return True when every key is lower-case."",
        )

    def test_all_uppercase_keys(self):
        self.assertTrue(
            self.func({""ZIP"": ""27514"", ""STATE"": ""NC""}),
            ""Should return True when every key is upper-case."",
        )

    # --- Negative cases ------------------------------------------------------
    def test_empty_dict_returns_false(self):
        self.assertFalse(self.func({}), ""Empty dictionary must return False."")

    def test_mixed_case_keys_returns_false(self):
        self.assertFalse(
            self.func({""a"": ""apple"", ""B"": ""banana""}),
            ""Mixed lower- and upper-case keys must return False."",
        )

    def test_non_string_key_returns_false(self):
        self.assertFalse(
            self.func({""a"": 1, 3: ""three""}),
            ""Presence of non-string keys must return False."",
        )"

LINK NUMBER 26
Error fetching diff

LINK NUMBER 27
Error fetching diff

LINK NUMBER 28
Error fetching diff

LINK NUMBER 29
Not enough lines

LINK NUMBER 30
Not enough lines

LINK NUMBER 31
Not enough lines

LINK NUMBER 32
Not enough lines

LINK NUMBER 33
Error fetching diff

LINK NUMBER 34
Error fetching diff

LINK NUMBER 35
Error fetching diff

LINK NUMBER 36

File path: src/app.js
"// app.js
import { Column } from ""./components/Column.js"";

const { createElement: h, useEffect, useState } = React;
const { createRoot } = ReactDOM;

function App() {
  const [projects, setProjects] = useState([]);
  const [statuses, setStatuses] = useState({});
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    async function load() {
      const token = localStorage.getItem(""github_pat"") || prompt(""Enter GitHub Personal Access Token:"");
      if (!token) return;
      localStorage.setItem(""github_pat"", token);

      try {
        const userRes = await fetch(""https://api.github.com/graphql"", {
          method: ""POST"",
          headers: {
            Authorization: `Bearer ${token}`,
            ""Content-Type"": ""application/json"",
          },
          body: JSON.stringify({ query: `query { viewer { login }}` }),
        });
        const userData = await userRes.json();
        const login = userData.data.viewer.login;

        const projectRes = await fetch(""https://api.github.com/graphql"", {
          method: ""POST"",
          headers: {
            Authorization: `Bearer ${token}`,
            ""Content-Type"": ""application/json"",
          },
          body: JSON.stringify({
            query: `query {
              user(login: ""${login}"") {
                projectsV2(first: 20) {
                  nodes {
                    id
                    title
                    url
                  }
                }
              }
            }`,
          }),
        });

        const projectData = await projectRes.json();
        const fetchedProjects = projectData.data.user.projectsV2.nodes;
        setProjects(fetchedProjects);

        const statusRes = await fetch(""./statuses.json"");
        const statusJson = await statusRes.json();
        setStatuses(statusJson);
      } catch (e) {
        console.error(e);
        setError(""Failed to load GitHub Projects or statuses."");
      } finally {
        setLoading(false);
      }
    }
    load();
  }, []);

  function updateProjectStatus(projectId, newStatus) {
    const updated = { ...statuses, [projectId]: newStatus };
    setStatuses(updated);

    fetch(""./statuses.json"", {
      method: ""PUT"",
      headers: { ""Content-Type"": ""application/json"" },
      body: JSON.stringify(updated, null, 2),
    });
  }

  if (loading) return h(""div"", { className: ""text-center mt-10"" }, ""Loading..."");
  if (error) return h(""div"", { className: ""text-red-500 text-center mt-10"" }, error);

  const columns = [""todo"", ""doing"", ""done""];

  return h(""div"", { className: ""grid grid-cols-1 sm:grid-cols-3 gap-4"" },
    columns.map(status =>
      h(Column, {
        key: status,
        status,
        projects: projects.filter(p => statuses[p.id] === status || (!statuses[p.id] && status === ""todo"")),
        onDrop: (id) => updateProjectStatus(id, status)
      })
    )
  );
}

const root = createRoot(document.getElementById(""root""));
root.render(h(App));"

LINK NUMBER 37
Not enough lines

LINK NUMBER 38

File path: phase1/src/server.cpp
"                log_.log(""task_candidate"", {
                    {""task"", req->task_id()},
                    {""peer"", id},
                    {""score"", score}
                });"

LINK NUMBER 39

File path: src/PCN_pipeline.py
"async def make_themisto_index_for_genome(genome_id, themisto_ref_dir, themisto_index_dir):
    """"""build a Themisto index for a single genome""""""
    ref_fasta_dir = os.path.join(themisto_ref_dir, genome_id)
    if not os.path.isdir(ref_fasta_dir):
        return
    
    index_input_filelist = os.path.join(ref_fasta_dir, genome_id + "".txt"")
    genome_index_dir = os.path.join(themisto_index_dir, genome_id)
    os.makedirs(genome_index_dir, exist_ok=True)
    
    index_prefix = os.path.join(genome_index_dir, genome_id)
    tempdir = os.path.join(genome_index_dir, ""temp"")
    os.makedirs(tempdir, exist_ok=True)
    
    themisto_build_args = [
        ""themisto"", ""build"", ""-k"", ""31"", ""-i"", index_input_filelist,
        ""--index-prefix"", index_prefix, ""--temp-dir"", tempdir,
        ""--mem-gigas"", ""8"", ""--n-threads"", ""8"", ""--file-colors""
    ]
    themisto_build_string = "" "".join(themisto_build_args)
    print(themisto_build_string)
    
    await run_command_with_retry(themisto_build_string, tempdir)


async def make_themisto_indices(themisto_ref_dir, themisto_index_dir):
    """"""Create Themisto indices for all genomes in the themisto reference directory.""""""
    os.makedirs(themisto_index_dir, exist_ok=True)
    
    tasks = [
        make_themisto_index_for_genome(genome_id, themisto_ref_dir, themisto_index_dir)
        for genome_id in os.listdir(themisto_ref_dir)
        if os.path.isdir(os.path.join(themisto_ref_dir, genome_id))
    ]
    
    await asyncio.gather(*tasks)
"

LINK NUMBER 40
Error fetching diff

LINK NUMBER 41
Error fetching diff

LINK NUMBER 42
Error fetching diff

LINK NUMBER 43
Not enough lines

LINK NUMBER 44
Not enough lines

LINK NUMBER 45
Not enough lines

LINK NUMBER 46
Not enough lines

LINK NUMBER 47
Error fetching diff

LINK NUMBER 48
Error fetching diff

LINK NUMBER 49
Error fetching diff

LINK NUMBER 50
Not enough lines

LINK NUMBER 51
Not enough lines

LINK NUMBER 52

File path: main.cpp
"This is simple pcg solver in c++ generated by chatgpt and modified after. 

The objectif of this TP is not to understand the c++, but to practice git. 

In fact, in the program, serveral lines were commented. What you need to do is to remove ""//"" before those lines to let the program output informations.

As there are several files, you can work in groupe (2 personnes) to achieve the efficiency. 

1. One of the teammate forks this repository to his own git private repository.

2. This teammate invite the other teammate as a team member to work with him is this project. 

3. After that, each teammate will do a ""git clone"" to get the private repository to his local repository after done a ""git init"" in his local repository.

4. Dev A removes the comments in pcg.cpp file to enable print; Dev B removes the comments in main.cpp to enable print.

5. Each Dev commits their modifications 

6. Publish the new code to your remote repository.

You can try to run the code to see if it can print something.

To compile to code, you need gcc compile 
	g++ main.cpp pcg.cpp -o a.out

To execute 
	./a.out"

LINK NUMBER 53

File path: test1.py
"[project]
name = ""udi-data-api-testing""
version = ""0.1.0""
description = ""Add your description here""
readme = ""README.md""
requires-python = "">=3.13""
dependencies = [
    ""pandas>=2.2.3"",
    ""requests>=2.32.3"",
]"

LINK NUMBER 54
Error fetching diff

LINK NUMBER 55
Error fetching diff

LINK NUMBER 56
Error fetching diff

LINK NUMBER 57

File path: ModelExploder.py
"import bpy
import bmesh
from mathutils import Vector, Matrix
from bpy.props import StringProperty, FloatProperty, IntProperty, PointerProperty, BoolProperty
from bpy.types import Operator, Panel, PropertyGroup
from collections import defaultdict
import math

bl_info = {
    ""name"": ""Spread Connected Mesh Groups"",
    ""blender"": (2, 80, 0),
    ""category"": ""Object"",
}

preview_object_prefix = ""PREVIEW_""
final_object_prefix = ""SPREAD_""

def update_preview_mesh(self, context):
    settings = context.scene.spread_settings
    target_obj = settings.target_object
    if not (target_obj and target_obj.type == 'MESH'):
        return

    preview_name = preview_object_prefix + target_obj.name
    preview_obj = bpy.data.objects.get(preview_name)

    if preview_obj:
        bpy.data.objects.remove(preview_obj, do_unlink=True)

    preview_obj = target_obj.copy()
    preview_obj.data = target_obj.data.copy()
    preview_obj.name = preview_name
    preview_obj.data.name = preview_name

    context.collection.objects.link(preview_obj)
    preview_obj.matrix_world = target_obj.matrix_world.copy()

    preview_obj.hide_select = True
    preview_obj.hide_render = True
    preview_obj.select_set(False)

    # Set preview material
    if ""SpreadPreviewMat"" not in bpy.data.materials:
        mat = bpy.data.materials.new(name=""SpreadPreviewMat"")
        mat.use_nodes = True
        bsdf = mat.node_tree.nodes.get(""Principled BSDF"")
        if bsdf:
            bsdf.inputs['Base Color'].default_value = (0.0, 0.4, 1.0, 1.0)
            bsdf.inputs['Alpha'].default_value = 0.4
        mat.blend_method = 'BLEND'
        mat.shadow_method = 'NONE'
    else:
        mat = bpy.data.materials[""SpreadPreviewMat""]

    if preview_obj.data.materials:
        preview_obj.data.materials[0] = mat
    else:
        preview_obj.data.materials.append(mat)

    preview_obj.display_type = 'SOLID'
    preview_obj.show_transparent = True

    bm = bmesh.new()
    bm.from_mesh(preview_obj.data)
    bm.verts.ensure_lookup_table()

    visited = set()
    groups = []

    def get_connected_group(start_vert):
        stack = [start_vert]
        group = []
        while stack:
            v = stack.pop()
            if v in visited:
                continue
            visited.add(v)
            group.append(v)
            for e in v.link_edges:
                stack.append(e.other_vert(v))
        return group

    for v in bm.verts:
        if v not in visited:
            group = get_connected_group(v)
            groups.append(group)

    deform_layer = bm.verts.layers.deform.verify()
    vg_name = settings.vertex_group_name.strip()
    vg_index = None
    if vg_name in preview_obj.vertex_groups:
        vg_index = preview_obj.vertex_groups[vg_name].index

    body_verts = set()
    if vg_index is not None:
        for v in bm.verts:
            d = v[deform_layer]
            if vg_index in d:
                body_verts.add(v)

    def group_centroid(group):
        return sum((v.co for v in group), Vector()) / len(group)

    group_centroids = [group_centroid(g) for g in groups]
    main_index = None

    if body_verts:
        for i, group in enumerate(groups):
            if any(v in body_verts for v in group):
                main_index = i
                break

    if main_index is None:
        distances = [c.length for c in group_centroids]
        main_index = distances.index(min(distances))

    tolerance = settings.tolerance
    distance_tolerance = settings.distance_tolerance
    group_spacing_x = settings.group_spacing_x
    group_spacing_y = settings.group_spacing_y
    group_spacing_z = settings.group_spacing_z
    local_spacing_x = settings.local_spacing_x
    local_spacing_y = settings.local_spacing_y
    local_spacing_z = settings.local_spacing_z
    preserve_symmetry = settings.preserve_symmetry

    poly_groups = defaultdict(list)
    for i, group in enumerate(groups):
        if i == main_index:
            continue
        polycount = len(group)
        has_x_zero = any(abs(v.co.x) < 1e-6 for v in group)
        key = f""{round(polycount / tolerance) * tolerance}""
        if has_x_zero:
            key += ""_x0""
        poly_groups[key].append(group)

    if preserve_symmetry:
        # Merge symmetrical groups
        keys = list(poly_groups.keys())
        merged = set()
        for i in range(len(keys)):
            for j in range(i + 1, len(keys)):
                if keys[i] in merged or keys[j] in merged:
                    continue
                group_list_a = poly_groups[keys[i]]
                group_list_b = poly_groups[keys[j]]
                for ga in group_list_a:
                    for gb in group_list_b:
                        if any((va.co - Vector((-vb.co.x, vb.co.y, vb.co.z))).length < 1e-4 for va in ga for vb in gb):
                            group_list_a.extend(group_list_b)
                            merged.add(keys[j])
                            break
                    if keys[j] in merged:
                        break
        for key in merged:
            del poly_groups[key]

    sorted_keys = sorted(poly_groups.keys())
    angle_step = 2 * math.pi / max(1, len(sorted_keys))

    for i, key in enumerate(sorted_keys):
        inner_groups = poly_groups[key]
        if len(inner_groups) <= 1:
            continue  # Skip solo groups

        angle = angle_step * i
        outer_offset = Vector((
            math.sin(angle) * group_spacing_x,
            math.cos(angle) * group_spacing_y,
            math.sin(angle) * group_spacing_z
        ))

        inner_centroids = [group_centroid(g) for g in inner_groups]
        inner_center = sum(inner_centroids, Vector()) / len(inner_centroids)

        for group in inner_groups:
            group_centroid_vec = group_centroid(group)
            direction = (group_centroid_vec - inner_center).normalized()
            if direction.length == 0:
                direction = Vector((0, 0, 1))
            local_offset = Vector((
                direction.x * local_spacing_x,
                direction.y * local_spacing_y,
                direction.z * local_spacing_z
            ))
            move_vec = outer_offset + local_offset

            bmesh.ops.translate(bm, verts=group, vec=move_vec)

    bm.normal_update()
    bm.to_mesh(preview_obj.data)
    bm.free()


class SpreadSettings(PropertyGroup):
    target_object: PointerProperty(
        name=""Target Object"",
        type=bpy.types.Object,
        description=""Object to spread mesh islands from"",
        update=update_preview_mesh
    )
    vertex_group_name: StringProperty(
        name=""Body Group"",
        description=""Name of the vertex group to leave in place"",
        default=""Body"",
        update=update_preview_mesh
    )
    tolerance: IntProperty(
        name=""Similarity Tolerance"",
        description=""How close polygon counts need to be to group islands together"",
        default=20,
        min=1,
        update=update_preview_mesh
    )
    distance_tolerance: FloatProperty(
        name=""Distance Tolerance"",
        description=""Maximum distance between group centroids to be grouped together"",
        default=5.0,
        min=0.0,
        update=update_preview_mesh
    )
    group_spacing_x: FloatProperty(
        name=""Group Spacing X"",
        description=""X direction distance between polygon groups"",
        default=0.0,
        min=0.0,
        update=update_preview_mesh
    )
    group_spacing_y: FloatProperty(
        name=""Group Spacing Y"",
        description=""Y direction distance between polygon groups"",
        default=10.0,
        min=0.0,
        update=update_preview_mesh
    )
    group_spacing_z: FloatProperty(
        name=""Group Spacing Z"",
        description=""Z direction distance between polygon groups"",
        default=10.0,
        min=0.0,
        update=update_preview_mesh
    )
    local_spacing_x: FloatProperty(
        name=""Island Spacing X"",
        description=""X direction spacing within a polygon group"",
        default=0.0,
        min=0.0,
        update=update_preview_mesh
    )
    local_spacing_y: FloatProperty(
        name=""Island Spacing Y"",
        description=""Y direction spacing within a polygon group"",
        default=2.0,
        min=0.0,
        update=update_preview_mesh
    )
    local_spacing_z: FloatProperty(
        name=""Island Spacing Z"",
        description=""Z direction spacing within a polygon group"",
        default=2.0,
        min=0.0,
        update=update_preview_mesh
    )
    preserve_symmetry: BoolProperty(
        name=""Preserve Symmetry"",
        description=""Ensure symmetrical groups are spread symmetrically"",
        default=True,
        update=update_preview_mesh
    )


class SpreadMeshPanel(Panel):
    bl_label = ""Model Exploder""
    bl_idname = ""VIEW3D_PT_model_exploder""
    bl_space_type = ""VIEW_3D""
    bl_region_type = ""UI""
    bl_category = ""Exploder""

    def draw(self, context):
        layout = self.layout
        settings = context.scene.spread_settings

        layout.label(text=""Spread Mesh Preview"")
        layout.prop(settings, ""target_object"")
        layout.prop(settings, ""vertex_group_name"")
        layout.prop(settings, ""tolerance"")
        layout.prop(settings, ""distance_tolerance"")
        layout.label(text=""Group Spacing"")
        layout.prop(settings, ""group_spacing_x"")
        layout.prop(settings, ""group_spacing_y"")
        layout.prop(settings, ""group_spacing_z"")
        layout.label(text=""Island Spacing"")
        layout.prop(settings, ""local_spacing_x"")
        layout.prop(settings, ""local_spacing_y"")
        layout.prop(settings, ""local_spacing_z"")
        layout.prop(settings, ""preserve_symmetry"")
        layout.operator(""object.spread_connected_verts"", text=""Preview"")
        layout.operator(""object.finalize_spread_mesh"", text=""Finalize Mesh"")


class SpreadGroups(Operator):
    bl_idname = ""object.spread_connected_verts""
    bl_label = ""Spread Connected Mesh Groups""

    def execute(self, context):
        update_preview_mesh(self, context)
        self.report({'INFO'}, ""Preview mesh updated"")
        return {'FINISHED'}


class FinalizeSpreadMesh(Operator):
    bl_idname = ""object.finalize_spread_mesh""
    bl_label = ""Finalize Spread Mesh""

    def execute(self, context):
        for obj in bpy.data.objects:
            if obj.name.startswith(preview_object_prefix):
                meshname = obj.name[len(preview_object_prefix):]
                obj.name = final_object_prefix + meshname
                obj.data.name = final_object_prefix + meshname
                if obj.active_material and obj.active_material.name == ""SpreadPreviewMat"":
                    obj.active_material = None
                obj.hide_select = False
                obj.hide_viewport = False
                obj.hide_render = False
                obj.select_set(True)
                context.view_layer.objects.active = obj

        for obj in list(bpy.data.objects):
            if obj.name.startswith(preview_object_prefix):
                if not obj.name.startswith(final_object_prefix):
                    bpy.data.objects.remove(obj, do_unlink=True)

        self.report({'INFO'}, ""Spread mesh finalized"")
        return {'FINISHED'}


def register():
    bpy.utils.register_class(SpreadSettings)
    bpy.types.Scene.spread_settings = PointerProperty(type=SpreadSettings)
    bpy.utils.register_class(SpreadMeshPanel)
    bpy.utils.register_class(SpreadGroups)
    bpy.utils.register_class(FinalizeSpreadMesh)


def unregister():
    bpy.utils.unregister_class(SpreadSettings)
    del bpy.types.Scene.spread_settings
    bpy.utils.unregister_class(SpreadMeshPanel)
    bpy.utils.unregister_class(SpreadGroups)
    bpy.utils.unregister_class(FinalizeSpreadMesh)


if __name__ == ""__main__"":
    register()"

LINK NUMBER 58

File path: Uppgift_1/src/main/java/com/davanddev/uppgift_1/controller/BookController.java
"    /**
     * Retrieves a book by its id.
     * If the book is not found, returns a 404 Not Found with an error message.
     *
     * @param id the id of the book.
     * @return a ResponseEntity containing the book or an error message.
     */"

LINK NUMBER 59

File path: src/PCN_pipeline.py
"
def make_themisto_indices(themisto_ref_dir, themisto_index_dir):
    """"""Create Themisto indices for all genomes in the themisto reference directory.""""""
    asyncio.run(make_themisto_indices_in_parallel(themisto_ref_dir, themisto_index_dir))
    return
    
"

LINK NUMBER 60

File path: Software/PC_UI.py
"import sys
import serial
import serial.tools.list_ports
import psutil
import time
import threading
from datetime import datetime
from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QPushButton, QComboBox, QSystemTrayIcon, QMenu, QAction
from PyQt5.QtCore import QTimer, Qt
from PyQt5.QtGui import QIcon

class SerialMonitor(QMainWindow):
    def __init__(self):
        super().__init__()

        # 设定窗口标题 & 禁止调整窗口大小
        self.setWindowTitle(""STM32桌面信息窗口"")
        self.setGeometry(100, 100, 300, 200)
        self.setFixedSize(300, 200)  # 锁定窗口大小

        # 串口选择框
        self.port_label = QLabel(""串口:"", self)
        self.port_label.move(20, 20)

        self.port_combo = QComboBox(self)
        self.port_combo.move(70, 18)
        self.refresh_ports()

        # 温湿度显示
        self.temp_label = QLabel(""温度: --°C"", self)
        self.temp_label.move(20, 60)

        self.humid_label = QLabel(""湿度: --%"", self)
        self.humid_label.move(150, 60)

        # 开始 & 停止按钮
        self.start_button = QPushButton(""连接"", self)
        self.start_button.move(50, 120)
        self.start_button.clicked.connect(self.start_monitoring)

        self.stop_button = QPushButton(""停止"", self)
        self.stop_button.move(150, 120)
        self.stop_button.clicked.connect(self.stop_monitoring)
        self.stop_button.setEnabled(False)

        # 定时器
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_info)

        # **系统托盘图标**
        icon_path = ""icon.png""  # 确保此路径下有图标文件（.ico）
        self.tray_icon = QSystemTrayIcon(QIcon(icon_path), self)
        self.tray_icon.setToolTip(""STM32桌面信息窗口"")  # 默认托盘提示

        # **托盘菜单**
        self.tray_menu = QMenu(self)
        restore_action = QAction(""显示窗口"", self)
        restore_action.triggered.connect(self.showNormal)

        exit_action = QAction(""退出"", self)
        exit_action.triggered.connect(self.exit_app)

        self.tray_menu.addAction(restore_action)
        self.tray_menu.addAction(exit_action)
        self.tray_icon.setContextMenu(self.tray_menu)

        # **托盘鼠标悬停更新**
        self.tray_icon.activated.connect(self.restore_from_tray)

        # 显示托盘
        self.tray_icon.show()

        # 串口线程
        self.serial_port = None
        self.is_running = False
        self.thread = None
        self.temp = ""--""
        self.humid = ""--""

    def refresh_ports(self):
        """"""刷新串口列表""""""
        self.port_combo.clear()
        ports = serial.tools.list_ports.comports()
        for port in ports:
            self.port_combo.addItem(port.device)

    def start_monitoring(self):
        """"""启动串口通信""""""
        selected_port = self.port_combo.currentText()
        if not selected_port:
            return

        try:
            self.serial_port = serial.Serial(selected_port, 9600, timeout=1)
            self.is_running = True
            self.start_button.setEnabled(False)
            self.stop_button.setEnabled(True)
            self.port_combo.setEnabled(False)  # 禁止修改串口选择框
            self.thread = threading.Thread(target=self.read_serial_data, daemon=True)
            self.thread.start()
            self.timer.start(1000)  # 每秒更新 CPU & 内存
        except Exception as e:
            print(f""串口打开失败: {e}"")

    def stop_monitoring(self):
        """"""停止串口通信""""""
        self.is_running = False
        self.start_button.setEnabled(True)
        self.stop_button.setEnabled(False)
        self.port_combo.setEnabled(True)  # 恢复串口选择框
        if self.serial_port:
            self.serial_port.close()
        self.timer.stop()

    def read_serial_data(self):
        """"""读取 STM32 发送的数据""""""
        while self.is_running:
            try:
                data = self.serial_port.read(2)  # 读取 2 个字节
                if len(data) == 2:
                    self.temp = data[0]
                    self.humid = data[1]
                    self.temp_label.setText(f""温度: {self.temp}°C"")
                    self.humid_label.setText(f""湿度: {self.humid}%"")
                    self.update_tray_tooltip()  # 更新托盘鼠标悬浮提示
            except Exception as e:
                print(f""串口读取错误: {e}"")
            time.sleep(1)

    def update_info(self):
        """"""发送 CPU 和内存使用情况到 STM32""""""
        if self.serial_port and self.serial_port.is_open:
            cpu_usage = int(psutil.cpu_percent(interval=1))
            memory_usage = int(psutil.virtual_memory().percent)
            now = datetime.now()

            data = [
                cpu_usage,
                memory_usage,
                now.year - 1900,
                now.month,
                now.day,
                now.hour,
                now.minute,
                now.second
            ]

            try:
                self.serial_port.write(bytes(data))
            except Exception as e:
                print(f""数据发送失败: {e}"")

    def update_tray_tooltip(self):
        """"""更新系统托盘悬浮提示信息""""""
        tooltip = f""温度: {self.temp}°C\n湿度: {self.humid}%""
        self.tray_icon.setToolTip(tooltip)

    def closeEvent(self, event):
        """"""拦截窗口关闭事件，最小化到系统托盘""""""
        event.ignore()
        self.hide()
        self.tray_icon.showMessage(""STM32桌面信息窗口"", ""程序已最小化到托盘"", QSystemTrayIcon.Information, 3000)

    def restore_from_tray(self, reason):
        """"""从托盘恢复窗口""""""
        if reason == QSystemTrayIcon.ActivationReason.Trigger:
            self.showNormal()

    def exit_app(self):
        """"""退出应用程序""""""
        self.tray_icon.hide()
        sys.exit()

if __name__ == ""__main__"":
    app = QApplication(sys.argv)
    window = SerialMonitor()
    window.show()
    sys.exit(app.exec_())"

LINK NUMBER 61
Error fetching diff

LINK NUMBER 62
Error fetching diff

LINK NUMBER 63
Error fetching diff

LINK NUMBER 64
Not enough lines

LINK NUMBER 65

File path: handlers/book.go
"package handlers

import (
    ""encoding/json""
    ""net/http""
)

func HandleBooks(w http.ResponseWriter, r *http.Request) {
    switch r.Method {
    case ""GET"":
        // Handle GET all books
    case ""POST"":
        // Handle POST create book
    case ""PUT"":
        // Handle PUT update book
    case ""DELETE"":
        // Handle DELETE book
    default:
        http.Error(w, ""Method not allowed"", http.StatusMethodNotAllowed)
    }
}"

LINK NUMBER 66
Not enough lines

LINK NUMBER 67
Not enough lines

LINK NUMBER 68
Error fetching diff

LINK NUMBER 69
Error fetching diff

LINK NUMBER 70
Error fetching diff

LINK NUMBER 71
Not enough lines

LINK NUMBER 72
Not enough lines

LINK NUMBER 73

File path: src/app/services/moderation-track.model.ts
"import { Component, OnInit } from '@angular/core';
import { CommonModule } from '@angular/common';
import { FormsModule } from '@angular/forms';
import { ModeratorService } from '../../services/moderator.service';
import { Moderator } from '../../services/moderator.model';

@Component({
  selector: 'app-moderators',
  standalone: true,
  imports: [CommonModule, FormsModule],
  templateUrl: './moderators.component.html',
  styleUrls: ['./moderators.component.scss']
})
export class ModeratorsComponent implements OnInit {

  moderators: Moderator[] = [];
  firstName: string = '';
  lastName: string = '';
  selectedFile: File | null = null;
  imagePreview: string | ArrayBuffer | null = null;

  constructor(private moderatorService: ModeratorService) {}

  ngOnInit(): void {
    this.loadModerators();
  }

  loadModerators(): void {
    this.moderatorService.getModerators().subscribe(data => {
      this.moderators = data;
    });
  }

  onFileSelected(event: any): void {
    const file = event.target.files[0];
    if (file) {
      this.selectedFile = file;

      const reader = new FileReader();
      reader.onload = () => {
        this.imagePreview = reader.result;
      };
      reader.readAsDataURL(file);
    }
  }

  addModerator(): void {
    if (!this.firstName || !this.lastName || !this.selectedFile) {
      alert('Please fill all fields and select an image.');
      return;
    }

    const formData = new FormData();
    formData.append('firstName', this.firstName);
    formData.append('lastName', this.lastName);

    if (this.selectedFile) {
      formData.append('image', this.selectedFile);
    }

    this.moderatorService.addModerator(formData).subscribe(() => {
      this.loadModerators();
      this.firstName = '';
      this.lastName = '';
      this.selectedFile = null;
      this.imagePreview = null;
    });
  }

  deleteModerator(id: string): void {
    this.moderatorService.deleteModerator(id).subscribe(() => {
      this.loadModerators();
    });
  }
}"

LINK NUMBER 74

File path: script.js
"<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <title>Tumblr Blog Viewer</title>
    <link rel=""stylesheet"" href=""styles.css"">
    <link href=""https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap"" rel=""stylesheet"">
    <link href=""https://fonts.googleapis.com/icon?family=Material+Icons"" rel=""stylesheet"">
</head>
<body>
    <header>
        <h1><span class=""material-icons"">rss_feed</span> Tumblr Blog Viewer</h1>
        <button id=""theme-toggle"" class=""button""><span class=""material-icons"">dark_mode</span></button>
        <button id=""admin-toggle"" class=""button""><span class=""material-icons"">settings</span></button>
    </header>

    <div class=""controls"">
        <input type=""text"" id=""search-input"" placeholder=""Search posts..."">
        <select id=""filter-select"">
            <option value=""all"">All Posts</option>
            <option value=""text"">Text</option>
            <option value=""photo"">Photo</option>
            <option value=""video"">Video</option>
        </select>
    </div>

    <main id=""posts-container""></main>

    <div class=""pagination"">
        <button id=""prev-page"" class=""button"" disabled>Previous</button>
        <span id=""page-info"">Page 1</span>
        <button id=""next-page"" class=""button"">Next</button>
    </div>

    <footer>
        <div class=""social-links"" id=""social-links""></div>
        <div class=""donation-links"" id=""donation-links"">
            <h3>Support Us</h3>
        </div>
    </footer>

    <div id=""admin-panel"" class=""hidden"">
        <h2>Edit Links</h2>
        <div id=""social-edit"">
            <h3>Social Media Links</h3>
            <input type=""text"" id=""twitter"" placeholder=""Twitter URL"">
            <input type=""text"" id=""facebook"" placeholder=""Facebook URL"">
            <input type=""text"" id=""instagram"" placeholder=""Instagram URL"">
            <input type=""text"" id=""tumblr"" placeholder=""Tumblr URL"">
        </div>

        <div id=""donation-edit"">
            <h3>Donation Links</h3>
            <input type=""text"" id=""venmo"" placeholder=""Venmo URL"">
            <input type=""text"" id=""paypal"" placeholder=""PayPal URL"">
            <input type=""text"" id=""cashapp"" placeholder=""Cash App URL"">
            <input type=""text"" id=""crypto"" placeholder=""Crypto URL"">
        </div>

        <button id=""save-links"">Save</button>
    </div>

    <script src=""script.js""></script>
</body>
</html>"

LINK NUMBER 75
Error fetching diff

LINK NUMBER 76
Error fetching diff

LINK NUMBER 77
Error fetching diff

LINK NUMBER 78
Not enough lines

LINK NUMBER 79
Not enough lines

LINK NUMBER 80
Not enough lines

LINK NUMBER 81

File path: app/src/main/java/com/jackingaming/thestraylightrun/accelerometer/game/drawers/DrawerStartFragment.java
"
        initMessageQueue();
    }

    private void initMessageQueue() {
        messageQueue = new ArrayList<>();
        String[] namesOfSenderDialogueArrayJavaLoops = getResources().getStringArray(R.array.names_of_sender_dialogue_array_java_loops);
        String[] messagesDialogueArrayJavaLoops = getResources().getStringArray(R.array.messages_dialogue_array_java_loops);
        String[] delayMsDialogueArrayJavaLoops = getResources().getStringArray(R.array.delay_ms_dialogue_array_java_loops);
        for (int i = 0; i < namesOfSenderDialogueArrayJavaLoops.length; i++) {
            String nameOfSender = namesOfSenderDialogueArrayJavaLoops[i];
            String message = messagesDialogueArrayJavaLoops[i];
            long delayMs = Long.parseLong(delayMsDialogueArrayJavaLoops[i]);

            messageQueue.add(new Message(nameOfSender, message, delayMs, false));
        }
        messageQueue.add(0, new Message(""player"", ""Muly: meow?"", 500L, true));
        messageQueue.add(2, new Message(""player"", ""Mulan: MEOW?"", 3500L, true));
        messageQueue.add(4, new Message(""player"", ""Muhang: meow"", 6000L, true));
        messageQueue.add(6, new Message(""player"", ""Mom: hello"", 9000L, true));
        messageQueue.add(8, new Message(""player"", ""Apsara: meow"", 11000L, true));
        messageQueue.add(10, new Message(""player"", ""Colin: silence"", 16000L, true));
    }

    public void startMessageQueue() {
        for (Message messageToAdd : messageQueue) {
            Handler handler = new Handler(Looper.getMainLooper());
            handler.postDelayed(new Runnable() {
                @Override
                public void run() {
                    addMessageToRecycleView(messageToAdd);
                }
            }, messageToAdd.getDelayMs());
        }
    }

    private void addMessageToRecycleView(Message message) {
        int indexNewMessage = messages.size();
        messages.add(message);
        adapter.notifyItemInserted(indexNewMessage);"

LINK NUMBER 82
Error fetching diff

LINK NUMBER 83
Error fetching diff

LINK NUMBER 84

File path: index.test.ts
"import { describe, expect, it } from ""bun:test"";
import { success, failure, Result } from ""./index"";

describe(""Result Type Tests"", () => {
  it(""should create a success result"", () => {
    const result = success(42);

    expect(result.done).toBe(true);
    expect(result.value).toBe(42);
    expect(result.failure).toBeUndefined();
  });

  it(""should create a failure result and throw on value access"", () => {
    const error = new Error(""Test error"");
    const result = failure(error);

    expect(result.done).toBe(true);
    expect(result.failure).toBe(error);

    expect(() => result.value).toThrow(error);
  });

  it(""should handle different success types"", () => {
    const stringResult = success(""Hello, world!"");
    expect(stringResult.value).toBe(""Hello, world!"");

    const objectResult = success({ key: ""value"" });
    expect(objectResult.value).toEqual({ key: ""value"" });
  });

  it(""should handle different failure types"", () => {
    const errorObject = { code: 500, message: ""Internal Server Error"" };
    const result = failure(errorObject);

    expect(result.failure).toBe(errorObject);
    expect(() => result.value).toThrow(errorObject);
  });
});"

LINK NUMBER 85
Not enough lines

LINK NUMBER 86
Not enough lines

LINK NUMBER 87
Not enough lines

LINK NUMBER 88
Error fetching diff

LINK NUMBER 89
Error fetching diff

LINK NUMBER 90

File path: app/src/androidTest/java/com/example/lengapp/ExampleInstrumentedTest.java
"package com.example.lengapp;

import android.content.Context;

import androidx.test.platform.app.InstrumentationRegistry;
import androidx.test.ext.junit.runners.AndroidJUnit4;

import org.junit.Test;
import org.junit.runner.RunWith;

import static org.junit.Assert.*;

/**
 * Instrumented test, which will execute on an Android device.
 *
 * @see <a href=""http://d.android.com/tools/testing"">Testing documentation</a>
 */
@RunWith(AndroidJUnit4.class)
public class ExampleInstrumentedTest {
    @Test
    public void useAppContext() {
        // Context of the app under test.
        Context appContext = InstrumentationRegistry.getInstrumentation().getTargetContext();
        assertEquals(""com.example.lengapp"", appContext.getPackageName());
    }
}"

LINK NUMBER 91

File path: app/src/main/java/com/example/lengapp/FlashcardUtils.java
"package com.example.lengapp;


public class Flashcard {
    private String word;           // The word in the source language
    private String translation;    // The translation of the word
    private String soundFileName;  // The file name of the sound associated with the word

    // Constructor
    public Flashcard(String word, String translation, String soundFileName) {
        this.word = word;
        this.translation = translation;
        this.soundFileName = soundFileName;
    }

    // Getters and Setters
    public String getWord() {
        return word;
    }

    public void setWord(String word) {
        this.word = word;
    }

    public String getTranslation() {
        return translation;
    }

    public void setTranslation(String translation) {
        this.translation = translation;
    }

    public String getSoundFileName() {
        return soundFileName;
    }

    public void setSoundFileName(String soundFileName) {
        this.soundFileName = soundFileName;
    }

    @Override
    public String toString() {
        return ""Flashcard{"" +
                ""word='"" + word + '\'' +
                "", translation='"" + translation + '\'' +
                "", soundFileName='"" + soundFileName + '\'' +
                '}';
    }
}"

LINK NUMBER 92
Not enough lines

LINK NUMBER 93

File path: kielet/data.js
"    ],
    ""gpt"": [
        { ""RU"": ""и"", ""EN-GB"": ""and"", ""FI"": ""ja"" },
        { ""RU"": ""в"", ""EN-GB"": ""in"", ""FI"": ""sisällä"" },
        { ""RU"": ""не"", ""EN-GB"": ""not"", ""FI"": ""ei"" },
        { ""RU"": ""он"", ""EN-GB"": ""he"", ""FI"": ""hän"" },
        { ""RU"": ""на"", ""EN-GB"": ""on"", ""FI"": ""päällä"" },
        { ""RU"": ""я"", ""EN-GB"": ""I"", ""FI"": ""minä"" },
        { ""RU"": ""с"", ""EN-GB"": ""with"", ""FI"": ""kanssa"" },
        { ""RU"": ""что"", ""EN-GB"": ""what"", ""FI"": ""mitä"" },
        { ""RU"": ""по"", ""EN-GB"": ""by"", ""FI"": ""kautta"" },
        { ""RU"": ""это"", ""EN-GB"": ""this"", ""FI"": ""tämä"" },
        { ""RU"": ""как"", ""EN-GB"": ""how"", ""FI"": ""kuinka"" },
        { ""RU"": ""мы"", ""EN-GB"": ""we"", ""FI"": ""me"" },
        { ""RU"": ""из"", ""EN-GB"": ""from"", ""FI"": ""from"" },
        { ""RU"": ""за"", ""EN-GB"": ""for"", ""FI"": ""varten"" },
        { ""RU"": ""вы"", ""EN-GB"": ""you"", ""FI"": ""te"", ""comment"": ""formal/plural"" },
        { ""RU"": ""так"", ""EN-GB"": ""so"", ""FI"": ""niin"" },
        { ""RU"": ""но"", ""EN-GB"": ""but"", ""FI"": ""mutta"" },
        { ""RU"": ""о"", ""EN-GB"": ""about"", ""FI"": ""noin"" },
        { ""RU"": ""же"", ""EN-GB"": ""same"", ""FI"": ""sama"" },
        { ""RU"": ""ты"", ""EN-GB"": ""you"", ""FI"": ""sinä"", ""comment"": ""informal"" },
        { ""RU"": ""мама"", ""EN-GB"": ""mom"", ""FI"": ""äiti"" },
        { ""RU"": ""отец"", ""EN-GB"": ""father"", ""FI"": ""isä"" },
        { ""RU"": ""женщина"", ""EN-GB"": ""woman"", ""FI"": ""nainen"" },
        { ""RU"": ""мужчина"", ""EN-GB"": ""man"", ""FI"": ""mies"" },
        { ""RU"": ""друг"", ""EN-GB"": ""friend"", ""FI"": ""ystävä"" },
        { ""RU"": ""брат"", ""EN-GB"": ""brother"", ""FI"": ""veli"" },
        { ""RU"": ""сестра"", ""EN-GB"": ""sister"", ""FI"": ""sisar"" },
        { ""RU"": ""город"", ""EN-GB"": ""city"", ""FI"": ""kaupunki"" },
        { ""RU"": ""лес"", ""EN-GB"": ""forest"", ""FI"": ""metsä"" },
        { ""RU"": ""гора"", ""EN-GB"": ""mountain"", ""FI"": ""vuori"" },
        { ""RU"": ""река"", ""EN-GB"": ""river"", ""FI"": ""joki"" },
        { ""RU"": ""море"", ""EN-GB"": ""sea"", ""FI"": ""meri"" },
        { ""RU"": ""небо"", ""EN-GB"": ""sky"", ""FI"": ""taivas"" },
        { ""RU"": ""солнце"", ""EN-GB"": ""sun"", ""FI"": ""aurinko"" },
        { ""RU"": ""звезда"", ""EN-GB"": ""star"", ""FI"": ""tähti"" },
        { ""RU"": ""месяц"", ""EN-GB"": ""month"", ""FI"": ""kuukausi"" },
        { ""RU"": ""деньги"", ""EN-GB"": ""money"", ""FI"": ""raha"" },
        { ""RU"": ""работа"", ""EN-GB"": ""work"", ""FI"": ""työ"" },
        { ""RU"": ""школа"", ""EN-GB"": ""school"", ""FI"": ""koulu"" },
        { ""RU"": ""учитель"", ""EN-GB"": ""teacher"", ""FI"": ""opettaja"" },
        { ""RU"": ""студент"", ""EN-GB"": ""student"", ""FI"": ""opiskelija"" }"

LINK NUMBER 94
Error fetching diff

LINK NUMBER 95
Error fetching diff

LINK NUMBER 96
Error fetching diff

LINK NUMBER 97

File path: js/main.js
"
// Cool terminal effect 
// generated by chatgpt

const commands = [
    { cmd: ""whoami"", output: [""root""] },
    { cmd: ""uname -a"", output: [""Linux server 5.15.0-79-generic #86-Ubuntu SMP x86_64 GNU/Linux""] },
    {
        cmd: ""ls -la"", output: [
            ""total 28"",
            ""drwxr-xr-x  3 root root 4096 Feb 23 12:34 ."",
            ""drwxr-xr-x 18 root root 4096 Feb 23 12:00 .."",
            ""-rw-r--r--  1 root root   21 Feb 23 12:30 .bashrc"",
            ""-rw-r--r--  1 root root   14 Feb 23 12:30 .profile"",
            ""drwx------  2 root root 4096 Feb 23 12:30 .ssh""
        ]
    },
    {
        cmd: ""cat /etc/os-release"", output: [
            'NAME=""Ubuntu""',
            'VERSION=""22.04.3 LTS (Jammy Jellyfish)""',
            'ID=ubuntu',
            'ID_LIKE=debian',
            'PRETTY_NAME=""Ubuntu 22.04.3 LTS""',
            'VERSION_ID=""22.04""',
        ]
    },
    {
        cmd: ""ping -c 3 8.8.8.8"", output: [
            ""PING 8.8.8.8 (8.8.8.8): 56 data bytes"",
            ""64 bytes from 8.8.8.8: icmp_seq=1 ttl=118 time=12.3 ms"",
            ""64 bytes from 8.8.8.8: icmp_seq=2 ttl=118 time=11.8 ms"",
            ""64 bytes from 8.8.8.8: icmp_seq=3 ttl=118 time=12.1 ms"",
            ""--- 8.8.8.8 ping statistics ---"",
            ""3 packets transmitted, 3 received, 0% packet loss, time 2000ms"",
            ""rtt min/avg/max/mdev = 11.8/12.0/12.3/0.2 ms""
        ]
    },
    {
        cmd: ""df -h"", output: [
            ""Filesystem      Size  Used Avail Use% Mounted on"",
            ""/dev/sda1        50G   25G   25G  50% /""
        ]
    },
    {
        cmd: ""top -n 1"", output: [
            ""top - 12:34:56 up 3 days,  5:42,  1 user,  load average: 0.24, 0.16, 0.15"",
            ""Tasks: 102 total,   1 running, 101 sleeping,   0 stopped,   0 zombie"",
            ""%Cpu(s):  1.3 us,  0.2 sy,  0.0 ni, 98.3 id,  0.1 wa,  0.0 hi,  0.1 si,  0.0 st"",
            ""KiB Mem :  8000000 total,  2000000 free,  3000000 used,  3000000 buff/cache"",
            ""KiB Swap:  4000000 total,  4000000 free,        0 used.  5000000 avail Mem ""
        ]
    },
    { cmd: ""clear"", output: [""clear""] }

];

let consoleElement = document.getElementById(""console"");
let index = 0;

function addPrompt() {
    let promptLine = document.createElement(""div"");
    promptLine.className = ""line"";
    promptLine.innerHTML = `<span class=""prompt"">root@server:~$</span> `;
    consoleElement.appendChild(promptLine);
    return promptLine;
}

function typeCommand(command, promptLine, callback) {
    let i = 0;

    function type() {
        if (i < command.length) {
            promptLine.innerHTML = `<span class=""prompt"">root@server:~$</span> ` + command.substring(0, i + 1) + '<span class=""cursor""></span>';
            i++;
            setTimeout(type, 50);
        } else {
            promptLine.innerHTML = `<span class=""prompt"">root@server:~$</span> ` + command;
            setTimeout(callback, 500);
        }
    }
    type();
}

function showOutput(output, callback) {
    if (output[0] === ""clear"") {
        consoleElement.innerHTML = """";
    } else {
        output.forEach(line => {
            let outputLine = document.createElement(""div"");
            outputLine.className = ""line"";
            outputLine.innerHTML = line;
            consoleElement.appendChild(outputLine);
        });

        cleanUpOldLines();
    }

    setTimeout(callback, 1000);
}

function cleanUpOldLines() {
    while (consoleElement.children.length > 7) {
        consoleElement.removeChild(consoleElement.children[0]);
    }
}

function runConsole() {
    if (index < commands.length) {
        const command = commands[index];

        let promptLine = addPrompt();

        setTimeout(() => {
            typeCommand(command.cmd, promptLine, () => {
                showOutput(command.output, () => {
                    index++;
                    runConsole();
                });
            });
        }, 500);

    } else {
        setTimeout(() => {
            consoleElement.innerHTML = """";
            index = 0;
            runConsole();
        }, 3000);
    }
}

runConsole();"

LINK NUMBER 98
Not enough lines

LINK NUMBER 99

File path: py/H1slit_controller.py
"import time
import serial
import subprocess

class H1SlitController:
    def __init__(self, port=""/dev/ttyUSB0"", baudrate=115200, filepath='pos.curr'):
        self.port = port
        self.baudrate = baudrate
        self.filepath = filepath
        self.client = None

    def open_ser(self):
        self.client = serial.Serial(
            self.port,
            self.baudrate,
            timeout=0.05,
            write_timeout=0.01,
            parity=serial.PARITY_EVEN,
            stopbits=serial.STOPBITS_ONE
        )

    def close_ser(self):
        if self.client:
            self.client.close()

    def execute(self, com, PRINT=True):
        com += self.crc16(com)
        if PRINT:
            print(com.encode('hex'))
        self.client.write(com)
        time.sleep(0.5)
        result = self.client.read(16)
        if PRINT:
            print(result.encode('hex'))
        return int(result.encode('hex'), 16)

    def to_bytes(self, n, length, endianess='big'):
        h = '%x' % n
        s = ('0'*(len(h) % 2) + h).zfill(length*2).decode('hex')
        return s if endianess != 'big' else s[::-1]

    def s32(self, val):
        return -(val & 0x80000000) | (val & 0x7fffffff)

    def crc16(self, data):
        data = bytearray(data)
        poly = 0xA001
        crc = 0xFFFF
        for b in data:
            crc ^= (0xFF & b)
            for _ in range(8):
                if crc & 0x0001:
                    crc = ((crc >> 1) & 0xFFFF) ^ poly
                else:
                    crc = ((crc >> 1) & 0xFFFF)
        return self.to_bytes(crc, 2)

    def read(self, seg, register, n):
        tmp = bytearray.fromhex('%02x' % seg)
        tmp.extend('\x03')
        tmp.extend(bytearray.fromhex('%04x' % register))
        tmp.extend(bytearray.fromhex('%04x' % n))
        return self.execute(bytes(tmp))

    def write(self, seg, register, nreg, nbyte, data):
        tmp = bytearray.fromhex('%02x' % seg)
        tmp.extend('\x10')
        tmp.extend(bytearray.fromhex('%04x' % register))
        tmp.extend(bytearray.fromhex('%04x' % nreg))
        tmp.extend(bytearray.fromhex('%02x' % nbyte))
        for d in data:
            tmp.extend(bytearray.fromhex('%08x' % d))
        self.execute(bytes(tmp))

    def polling(self, seg):
        counter = 0
        while self.isready(seg) == 0:
            time.sleep(0.1)
            counter += 1
            if counter % 10 == 0:
                print('.')
            if counter > 100:
                print(""timeout!!!"", seg)
                return False
        return True

    def isready(self, seg):
        _ = self.read(seg, 126, 2)
        ready2 = (self.read(seg, 377, 1) >> 20) & 0x1
        return ready2

    def off(self, seg):
        self.write(seg, 0x7c, 2, 4, [0x00])

    def start(self, seg):
        if self.polling(seg):
            self.write(seg, 0x7c, 2, 4, [0x08])
            time.sleep(0.1)
            self.off(seg)

    def set_params(self, seg, channel, mode, pos, speed=5000, rate1=1000, rate2=1000):
        base = 1024 + channel
        self.write(seg, base + 0 * 128, 2, 4, [pos])
        self.write(seg, base + 1 * 128, 2, 4, [speed])
        self.write(seg, base + 2 * 128, 2, 4, [mode])
        self.write(seg, base + 4 * 128, 2, 4, [rate1])
        self.write(seg, base + 5 * 128, 2, 4, [rate2])

    def get_position(self, seg):
        if self.polling(seg):
            result = self.read(seg, 0xcc, 2)
            pos = (result >> 16) & 0xffffffff
            print(pos, hex(pos))
            return self.s32(pos)

    def save_seg(self):
        serial = 1234
        xpos = self.get_position(2)
        ypos = self.get_position(1)
        s = f""{serial} {xpos} {ypos}  fin\n""
        with open(self.filepath, 'w') as f:
            f.write(s)
        subprocess.call(['scp', '-p', self.filepath, 'vme:/tmp/daq.txt'])

    def move(self, channel):
        x = (channel - 1) % 8
        y = (channel - 1) // 8
        xpos = 25750 * x
        ypos = 25900 * y
        print(x, y, xpos, ypos)
        self.set_params(2, 0, 1, xpos)
        self.set_params(1, 0, 1, ypos)
        self.start(1)
        self.start(2)

    def step(self, seg, count):
        self.set_params(seg, 0, 2, count)
        self.start(seg)
        self.save_seg()

    def absolute(self, seg, count):
        self.set_params(seg, 0, 1, count)
        self.start(seg)
        self.save_seg()

    def home(self, seg):
        if self.polling(seg):
            self.write(seg, 0x7c, 2, 4, [0x10])
            time.sleep(0.1)
            self.off(seg)
        self.get_position(seg)
        self.save_seg()

    def read_params(self, seg, channel):
        base = 1024 + channel
        offset = [0, 128, 2 * 128, 4 * 128, 5 * 128]
        names = ['pos', 'speed', 'mode', 'rate1', 'rate2']
        print('------- seg =', seg, 'channel =', channel)
        for offs, name in zip(offset, names):
          result = self.read(seg, base + offs, 2)
          val = (result >> 16) & 0xffff
          print(name, val)

    def reset_home(self, seg):
        cpos=self.get_position(seg)
        print('cpos:',cpos, 'is new origin (0)')
        if self.polling(seg):
          val=self.read(seg,0x018A,2)
          aaa=(val>>16&0x01)
          if aaa==1:
            self.write(seg,0x018A,2,4,[0x00])
          self.write(seg,0x018A,2,4,[0x01])


if __name__ == ""__main__"":
    controller = H1SlitController()
    controller.open_ser()

    controller.home(1)
    controller.read_params(1, 0)

    controller.close_ser()

#if __name__ == ""__main__"":
#    controller = H1SlitController()
#    controller.open_ser()
#
#    controller.home(1)
#    controller.read_params(1, 0)
#
#    controller.close_ser()"

LINK NUMBER 100

File path: VAEs_code_by_chatgpt.py
"import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import numpy as np
import cv2
import os
from glob import glob

# UNET Model Definition
class UNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(UNet, self).__init__()
        
        def conv_block(in_c, out_c):
            return nn.Sequential(
                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
                nn.ReLU(inplace=True)
            )
        
        self.encoder = nn.ModuleList([
            conv_block(in_channels, 64),
            conv_block(64, 128),
            conv_block(128, 256),
            conv_block(256, 512),
            conv_block(512, 1024),
        ])
        
        self.pool = nn.MaxPool2d(2)
        
        self.upconv = nn.ModuleList([
            nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2),
            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),
            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),
            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        ])
        
        self.decoder = nn.ModuleList([
            conv_block(1024, 512),
            conv_block(512, 256),
            conv_block(256, 128),
            conv_block(128, 64)
        ])
        
        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)
        
    def forward(self, x):
        encoder_outs = []
        for enc in self.encoder:
            x = enc(x)
            encoder_outs.append(x)
            x = self.pool(x)
        
        x = encoder_outs.pop()
        
        for up, dec in zip(self.upconv, self.decoder):
            x = up(x)
            enc_out = encoder_outs.pop()
            x = torch.cat([x, enc_out], dim=1)
            x = dec(x)
        
        return torch.sigmoid(self.final_conv(x))

# Custom Dataset
class SegmentationDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)
        
        img = cv2.resize(img, (256, 256))
        mask = cv2.resize(mask, (256, 256))
        
        img = img / 255.0
        mask = mask / 255.0
        
        img = np.transpose(img, (2, 0, 1)).astype(np.float32)
        mask = np.expand_dims(mask, axis=0).astype(np.float32)
        
        return torch.tensor(img), torch.tensor(mask)

# Load Dataset
image_paths = sorted(glob(""path/to/images/*.jpg""))
mask_paths = sorted(glob(""path/to/masks/*.png""))

dataset = SegmentationDataset(image_paths, mask_paths)
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# Training Setup
device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")
model = UNet().to(device)
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

def train(model, dataloader, criterion, optimizer, epochs=10):
    model.train()
    for epoch in range(epochs):
        epoch_loss = 0
        for img, mask in dataloader:
            img, mask = img.to(device), mask.to(device)
            optimizer.zero_grad()
            output = model(img)
            loss = criterion(output, mask)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        print(f""Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(dataloader):.4f}"")
    torch.save(model.state_dict(), ""unet_model.pth"")

# Inference Function
def infer(model, image_path):
    model.eval()
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (256, 256))
    img = img / 255.0
    img = np.transpose(img, (2, 0, 1)).astype(np.float32)
    img = torch.tensor(img).unsqueeze(0).to(device)
    
    with torch.no_grad():
        pred = model(img)
    pred = pred.squeeze().cpu().numpy()
    return (pred > 0.5).astype(np.uint8) * 255

# Example Usage
# train(model, dataloader, criterion, optimizer, epochs=10)
# mask = infer(model, ""path/to/sample.jpg"")
# cv2.imwrite(""output_mask.png"", mask)"

LINK NUMBER 101
Error fetching diff

LINK NUMBER 102
Error fetching diff

LINK NUMBER 103
Error fetching diff

LINK NUMBER 104

File path: src/app/components/moderators/moderators.component.ts
"<div class=""moderator-list"" style=""display: flex; flex-wrap: wrap; gap: 16px;"">
  <mat-card *ngFor=""let moderator of moderators"" class=""moderator-card"" style=""width: 200px; background-color: #ffffff;"">
    <img mat-card-image [src]=""moderator.imageData"" alt=""{{moderator.firstName}}"">
    <mat-card-content>
      <h3 style=""color: #e10000;"">{{ moderator.firstName }} {{ moderator.lastName }}</h3>
    </mat-card-content>
    <mat-card-actions>
      <button mat-raised-button color=""warn"" (click)=""deleteModerator(moderator.id!)"">Delete</button>
    </mat-card-actions>
  </mat-card>
</div>"

LINK NUMBER 105
Not enough lines

LINK NUMBER 106
Not enough lines

LINK NUMBER 107

File path: src/Spf/Spf.cs
"    private readonly IServiceProvider _serviceProvider;
    private readonly List<ISpfPromptHandler> _handlers;
    private readonly ISpfExitor? _exitor;
    private readonly ISpfNoPromptMatchHandler? _noMatchHandler;
    private readonly SpfState _state = new();

    public Spf(string[] args, IServiceCollection services)
    {
        var serviceProvider = services.BuildServiceProvider();
        _serviceProvider = serviceProvider;
        _handlers = DiscoverHandlers(serviceProvider);
        _exitor = serviceProvider.GetService<ISpfExitor>();
        _noMatchHandler = serviceProvider.GetService<ISpfNoPromptMatchHandler>();
    }

    private static List<ISpfPromptHandler> DiscoverHandlers(IServiceProvider serviceProvider)
    {
        return [.. AppDomain.CurrentDomain.GetAssemblies()
            .SelectMany(a => a.GetTypes())
            .Where(t => typeof(ISpfPromptHandler).IsAssignableFrom(t) && !t.IsInterface && !t.IsAbstract)
            .Select(t => (ISpfPromptHandler)serviceProvider.GetRequiredService(t))];
    }

    public async Task StartAsync()
    {
        while (true)
        {
            Console.Write("" > "");
            var input = Console.ReadLine()?.Trim();
            if (string.IsNullOrEmpty(input)) continue;

            if (input.Equals(""q"", StringComparison.OrdinalIgnoreCase) || input.Equals(""quit"", StringComparison.OrdinalIgnoreCase))
            {
                if (_exitor != null && !await _exitor.ExitAsync(_state))
                    continue;
                break;
            }

            var tokens = input.Split(' ', StringSplitOptions.RemoveEmptyEntries);
            if (tokens.Length == 0) continue;

            var (path, cmdInput) = TokenizeInput(tokens);
            var handler = _handlers.FirstOrDefault(h => MatchesHandler(h, path));

            if (handler != null)
            {
                await handler.HandlePromptAsync(path, cmdInput, _state);
            }
            else if (_noMatchHandler != null && await _noMatchHandler.HandleNoMatch(tokens, _state))
            {
                continue;
            }
            else
            {
                Console.WriteLine(""Error: Unrecognized command."");
            }
        }
    }

    private static (string[] path, string[] input) TokenizeInput(string[] tokens)
    {
        var lastIndex = tokens.ToList().FindLastIndex(t => char.IsUpper(t.FirstOrDefault()));
        if (lastIndex == -1) return (tokens, Array.Empty<string>());
        return (tokens[..(lastIndex + 1)], tokens[(lastIndex + 1)..]);
    }

    private static bool MatchesHandler(ISpfPromptHandler handler, string[] path)
    {
        var typeName = handler.GetType().Name;
        if (typeName.EndsWith(""SpfPromptHandler""))
            typeName = typeName[..^15];"

LINK NUMBER 108
Error fetching diff

LINK NUMBER 109
Error fetching diff

LINK NUMBER 110
Error fetching diff

LINK NUMBER 111
Not enough lines

LINK NUMBER 112

File path: scripts/personas.py
"# contains AI-generated artifacts.

personas = [
    {
        ""name"": ""Emily"",
        ""greeting"": ""Hi there, I'm Emily, a policy advisor. How can I assist you today?"",
        ""persona"": ""Emily is a 30-year-old policy advisor based in London. She specializes in education reform and has a background in sociology. Emily values clear, concise communication and frequently interacts with stakeholders from diverse sectors. She prefers formal yet accessible language to ensure inclusivity.""
    },
    {
        ""name"": ""Ahmed"",
        ""greeting"": ""Hello, I'm Ahmed, an IT manager. How can I help you today?"",
        ""persona"": ""Ahmed is a 42-year-old IT manager in Manchester. With a degree in computer science, he oversees digital infrastructure for public services. Ahmed is detail-oriented and appreciates precise, technical explanations when discussing projects.""
    },
    {
        ""name"": ""Priya"",
        ""greeting"": ""Hi, I'm Priya, a communications officer. What can I do for you today?"",
        ""persona"": ""Priya is a 28-year-old communications officer in Birmingham. She manages internal and external communications for her department. Priya is creative and enjoys tailoring messages to different audiences, ensuring clarity and accessibility.""
    },
    {
        ""name"": ""John"",
        ""greeting"": ""Good day, I'm John, a senior civil servant. How may I assist?"",
        ""persona"": ""John is a 55-year-old senior civil servant in Edinburgh. With over 30 years of experience, he focuses on strategic planning for economic development. John values professionalism and prefers formal communication that respects tradition.""
    },
    {
        ""name"": ""Sophie"",
        ""greeting"": ""Hello there, I'm Sophie, a graduate trainee. What do you need help with?"",
        ""persona"": ""Sophie is a 24-year-old graduate trainee in Cardiff. She is enthusiastic about public service and eager to learn. Sophie values approachable and clear language, as she is still familiarizing herself with technical jargon.""
    },
    {
        ""name"": ""Derek"",
        ""greeting"": ""Hey, I'm Derek, a regional coordinator. What's on your mind today?"",
        ""persona"": ""Derek is a 50-year-old regional coordinator in Belfast. He works with local councils to implement national policies. Derek has a hands-on approach and prefers practical, straightforward communication.""
    },
    {
        ""name"": ""Amara"",
        ""greeting"": ""Hi, I'm Amara, a social worker. How can I support you today?"",
        ""persona"": ""Amara is a 35-year-old social worker in Leeds. She advocates for vulnerable populations and ensures compliance with government welfare policies. Amara values empathetic, people-first language in her communications.""
    },
    {
        ""name"": ""George"",
        ""greeting"": ""Hello, I'm George, a statistician. What can I assist you with?"",
        ""persona"": ""George is a 60-year-old statistician in Bristol. He analyzes data to inform policy decisions. George is analytical and prefers precise, data-driven language but is also mindful of making his insights comprehensible to non-technical audiences.""
    },
    {
        ""name"": ""Yasmin"",
        ""greeting"": ""Hi there, I'm Yasmin, a diversity and inclusion officer. What do you need help with today?"",
        ""persona"": ""Yasmin is a 40-year-old diversity and inclusion officer in Liverpool. She ensures workplace policies promote equality and accessibility. Yasmin values inclusive language and is skilled at adapting her communication style to diverse audiences.""
    },
    {
        ""name"": ""Oliver"",
        ""greeting"": ""Good day, I'm Oliver, an environmental scientist. How may I help?"",
        ""persona"": ""Oliver is a 45-year-old environmental scientist in Glasgow. He works on sustainability initiatives and collaborates with various agencies. Oliver values clarity and conciseness, especially when conveying complex environmental issues to policymakers and the public.""
    }
]"

LINK NUMBER 113
Not enough lines

LINK NUMBER 114
Not enough lines

LINK NUMBER 115
Error fetching diff

LINK NUMBER 116
Error fetching diff

LINK NUMBER 117
Error fetching diff

LINK NUMBER 118
Not enough lines

LINK NUMBER 119
Not enough lines

LINK NUMBER 120
Not enough lines

LINK NUMBER 121

File path: Example/CeleryExample2/celery_config.py
"broker_url = 'redis://localhost:6379/0'
result_backend = 'redis://localhost:6379/1'

task_routes = {
    'tasks.cpu_tasks.*': {'queue': 'cpu_queue'},
    'tasks.io_tasks.*': {'queue': 'io_queue'},
}"

LINK NUMBER 122
Error fetching diff

LINK NUMBER 123
Error fetching diff

LINK NUMBER 124
Error fetching diff

LINK NUMBER 125
Not enough lines

LINK NUMBER 126

File path: PycharmProjects/Project_with_chatgpt/pong_pygame.py
"import pygame
import random

# Initialisation de Pygame
pygame.init()

# Dimensions de la fenêtre
WIDTH, HEIGHT = 800, 600
screen = pygame.display.set_mode((WIDTH, HEIGHT))
pygame.display.set_caption(""Jeu de Casse"")

# Couleurs
WHITE = (255, 255, 255)
RED = (255, 0, 0)
BLUE = (0, 0, 255)
GREEN = (0, 255, 0)
BLACK = (0, 0, 0)

# Police
font = pygame.font.Font(None, 36)


# Fonction pour afficher un bouton (Rejouer)
def draw_button():
    pygame.draw.rect(screen, RED, (WIDTH // 2 - 75, HEIGHT // 2, 150, 50))
    text = font.render(""Rejouer"", True, WHITE)
    screen.blit(text, (WIDTH // 2 - 40, HEIGHT // 2 + 10))


# Fonction pour afficher un écran de fin (victoire ou game over)
def show_end_screen(message):
    screen.fill(BLACK)
    text = font.render(message, True, WHITE)
    screen.blit(text, (WIDTH // 2 - 70, HEIGHT // 2 - 50))
    draw_button()
    pygame.display.update()

    waiting = True
    while waiting:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                pygame.quit()
                return False
            if event.type == pygame.MOUSEBUTTONDOWN:
                x, y = pygame.mouse.get_pos()
                if WIDTH // 2 - 75 <= x <= WIDTH // 2 + 75 and HEIGHT // 2 <= y <= HEIGHT // 2 + 50:
                    return True
    return False


# Fonction principale du jeu
def game_loop():
    global ball_x, ball_y, ball_speed_x, ball_speed_y, bar_x, bricks

    # Réinitialisation des variables du jeu
    ball_x, ball_y = WIDTH // 2, HEIGHT - 50
    ball_speed_x, ball_speed_y = random.choice([-3, 3]), -3
    bar_x = WIDTH // 2 - 50

    # Création des briques
    bricks = [pygame.Rect(col * 70 + 35, row * 25 + 40, 60, 20) for row in range(5) for col in range(10)]

    clock = pygame.time.Clock()
    run = True

    while run:
        clock.tick(60)

        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                pygame.quit()
                return

        # Déplacement de la barre
        keys = pygame.key.get_pressed()
        if keys[pygame.K_LEFT] and bar_x > 0:
            bar_x -= 6
        if keys[pygame.K_RIGHT] and bar_x < WIDTH - 100:
            bar_x += 6

        # Déplacement de la balle
        ball_x += ball_speed_x
        ball_y += ball_speed_y

        # Collision avec les murs
        if ball_x - 10 <= 0 or ball_x + 10 >= WIDTH:
            ball_speed_x = -ball_speed_x
        if ball_y - 10 <= 0:
            ball_speed_y = -ball_speed_y
        if ball_y + 10 >= HEIGHT:
            run = False  # Game over si la balle touche le bas

        # Collision avec la barre
        bar_rect = pygame.Rect(bar_x, HEIGHT - 30, 100, 20)
        ball_rect = pygame.Rect(ball_x - 10, ball_y - 10, 20, 20)
        if ball_rect.colliderect(bar_rect):
            ball_speed_y = -abs(ball_speed_y)
            ball_speed_x += random.choice([-1, 1])  # Effet de variation du rebond

        # Collision avec les briques
        for brick in bricks[:]:
            if ball_rect.colliderect(brick):
                bricks.remove(brick)
                ball_speed_y = -ball_speed_y
                break

        # Vérifier si toutes les briques sont détruites
        if not bricks:
            run = False
            victory = True  # Indique qu'on a gagné

        # Dessiner les éléments du jeu
        screen.fill(BLACK)
        pygame.draw.circle(screen, WHITE, (ball_x, ball_y), 10)
        pygame.draw.rect(screen, BLUE, (bar_x, HEIGHT - 30, 100, 20))
        for brick in bricks:
            pygame.draw.rect(screen, GREEN, brick)

        pygame.display.update()

    # Affichage de l'écran de fin (victoire ou game over)
    if not bricks:
        message = ""Victoire !""
    else:
        message = ""Game Over""

    if show_end_screen(message):
        game_loop()  # Relancer une partie


# Lancer le jeu
game_loop()"

LINK NUMBER 127
Not enough lines

LINK NUMBER 128
Not enough lines

LINK NUMBER 129
Error fetching diff

LINK NUMBER 130
Error fetching diff

LINK NUMBER 131
Error fetching diff

LINK NUMBER 132
Not enough lines

LINK NUMBER 133
Not enough lines

LINK NUMBER 134

File path: quickstep/src/com/android/launcher3/QuickstepTransitionManager.java
"    /**
     * Returns animator that controls depth/blur of the background.
     */
private ObjectAnimator getBackgroundAnimator() {
    boolean allowBlurringLauncher = mLauncher.getStateManager().getState() != OVERVIEW
            && BlurUtils.supportsBlursOnWindows();

    LaunchDepthController depthController = new LaunchDepthController(mLauncher);
    ObjectAnimator backgroundRadiusAnim = ObjectAnimator.ofFloat(depthController.stateDepth,
                    MULTI_PROPERTY_VALUE, BACKGROUND_APP.getDepth(mLauncher))
            .setDuration(APP_LAUNCH_DURATION);

    if (allowBlurringLauncher) {
        View rootView = mLauncher.getDragLayer();

        // Create a composite SurfaceControl layer for everything behind the app animation
        ViewRootImpl viewRootImpl = rootView.getViewRootImpl();
        SurfaceControl parentSurface = viewRootImpl != null ? viewRootImpl.getSurfaceControl() : null;

        if (parentSurface != null) {
            SurfaceControl blurLayer = new SurfaceControl.Builder()
                    .setName(""Blur Layer"")
                    .setParent(parentSurface)"

LINK NUMBER 135

File path: src/GPT_code.py
"import os
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from scipy.stats import pearsonr

def extract_features(data, window_length=0.2, window_slide=0.01, sampling_rate=1200):
    features = []
    labels = []
    window_size = int(window_length * sampling_rate)
    step_size = int(window_slide * sampling_rate)


    for start in range(0, len(data) - window_size + 1, step_size):
        end = start + window_size - 1
        window = data.iloc[start:end, 1:17].values
        label = data.iloc[end, 0]

        rms = np.sqrt(np.mean(window**2, axis=0))
        zc = np.sum(np.diff(np.sign(window), axis=0) != 0, axis=0)
        wl = np.sum(np.abs(np.diff(window, axis=0)), axis=0)

        features.append(np.hstack((rms, zc, wl)))
        labels.append(label)

    return np.array(features), np.array(labels)

def calculate_nmse(x_r, x_p):
    numerator = np.linalg.norm(x_r - x_p) ** 2
    denominator = np.linalg.norm(x_r - np.mean(x_r)) ** 2
    nmse = 100 * (1 - (numerator / denominator))
    return nmse

def load_data(batches):
    data = []
    for batch in batches:
        files = sorted([file for file in os.listdir(batch) if file.endswith('.csv')])
        for file in files:
            batch_data = pd.read_csv(os.path.join(batch, file), header=0)
            data.append(batch_data)
    return data

def main():
    batches = ['Data/Batch1', 'Data/Batch2', 'Data/Batch3']
    data_files = load_data(batches)

    nmse_values = []
    corr_values = []

    for i in range(10):  # Assuming there are 10 folds (i.e., 10 data files for each motion)
        train_data = [data for idx, data in enumerate(data_files) if ((idx != i) and (idx != (i+10)) and (idx != (i+20)))]
        test_data = [data for idx, data in enumerate(data_files) if ((idx == i) or (idx == (i+10)) or (idx == (i+20)))]

        train_features = np.vstack([extract_features(data)[0] for data in train_data])
        train_labels = np.concatenate([extract_features(data)[1] for data in train_data])

        test_features = np.vstack([extract_features(data)[0] for data in test_data])
        test_labels = np.concatenate([extract_features(data)[1] for data in test_data])

        model = RandomForestRegressor(n_estimators=100, random_state=0)
        model.fit(train_features, train_labels)

        predictions = model.predict(test_features)

        nmse = calculate_nmse(test_labels, predictions)
        corr = pearsonr(test_labels, predictions)[0] * 100  # Correlation in percentage

        nmse_values.append(nmse)
        corr_values.append(corr)

        print(f""Fold {i + 1}: Correlation = {corr:.2f}%, NMSE = {nmse:.2f}%"")

    print(""\nAll Folds NMSE Values: "", nmse_values)
    print(""All Folds Correlation Values: "", corr_values)

    print(f""\nMean Correlation: {np.mean(corr_values):.2f}%"")
    print(f""Mean NMSE: {np.mean(nmse_values):.2f}%"")

if __name__ == ""__main__"":
    main()"

LINK NUMBER 136
Error fetching diff

LINK NUMBER 137
Error fetching diff

LINK NUMBER 138
Error fetching diff

LINK NUMBER 139
Not enough lines

LINK NUMBER 140
Not enough lines

LINK NUMBER 141
Too many lines

LINK NUMBER 142
Not enough lines

LINK NUMBER 143
Error fetching diff

LINK NUMBER 144
Error fetching diff

LINK NUMBER 145
Error fetching diff

LINK NUMBER 146
Not enough lines

LINK NUMBER 147
Not enough lines

LINK NUMBER 148
Not enough lines

LINK NUMBER 149
Not enough lines

LINK NUMBER 150
Error fetching diff

LINK NUMBER 151
Error fetching diff

LINK NUMBER 152
Error fetching diff

LINK NUMBER 153

File path: multi_file_xml_loader.py
"import os
import xml.etree.ElementTree as ET
import mysql.connector

# Directory containing XML files
xml_directory = ""/path/to/your/xml/files""

# MySQL connection
db = mysql.connector.connect(
    host=""localhost"",
    user=""your_username"",
    password=""your_password"",
    database=""your_database""
)
cursor = db.cursor()

# Create tables
cursor.execute(""""""
CREATE TABLE IF NOT EXISTS Product (
    id VARCHAR(255) PRIMARY KEY,
    name VARCHAR(255),
    version INT,
    singlecontent BOOLEAN
)
"""""")

cursor.execute(""""""
CREATE TABLE IF NOT EXISTS Volume (
    id VARCHAR(255) PRIMARY KEY,
    product_id VARCHAR(255),
    name VARCHAR(255),
    number INT,
    sourcefiletype VARCHAR(50),
    preview_discid VARCHAR(255),
    preview_suffix VARCHAR(10),
    preview_installdir VARCHAR(255),
    preview_path_on_disc VARCHAR(255),
    preview_thumbnail_suffix VARCHAR(10),
    install_size_img INT,
    install_size_img_mov INT,
    total_preview_size INT,
    total_source_size FLOAT,
    base_j3_version VARCHAR(255),
    FOREIGN KEY (product_id) REFERENCES Product(id)
)
"""""")

cursor.execute(""""""
CREATE TABLE IF NOT EXISTS Disc (
    id VARCHAR(255) PRIMARY KEY,
    volume_id VARCHAR(255),
    number INT,
    FOREIGN KEY (volume_id) REFERENCES Volume(id)
)
"""""")

cursor.execute(""""""
CREATE TABLE IF NOT EXISTS Content (
    id VARCHAR(255) PRIMARY KEY,
    disc_id VARCHAR(255),
    type INT,
    name VARCHAR(255),
    originalfps INT,
    frames INT,
    description VARCHAR(255),
    resolution VARCHAR(50),
    resx INT,
    resy INT,
    base VARCHAR(255),
    keywords TEXT,
    FOREIGN KEY (disc_id) REFERENCES Disc(id)
)
"""""")

# Function to process a single XML file
def process_xml_file(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    # Extract and insert Product
    product = root.attrib
    product_id = product[""id""]
    cursor.execute(""""""
    INSERT INTO Product (id, name, version, singlecontent)
    VALUES (%s, %s, %s, %s)
    ON DUPLICATE KEY UPDATE name=VALUES(name), version=VALUES(version), singlecontent=VALUES(singlecontent)
    """""", (product[""id""], product[""name""], int(product[""version""]), product[""singlecontent""] == ""true""))

    # Extract and insert Volume
    for volume in root.findall(""volume""):
        volume_attrib = volume.attrib
        cursor.execute(""""""
        INSERT INTO Volume (id, product_id, name, number, sourcefiletype, preview_discid, preview_suffix, preview_installdir,
                            preview_path_on_disc, preview_thumbnail_suffix, install_size_img, install_size_img_mov,
                            total_preview_size, total_source_size, base_j3_version)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE name=VALUES(name), number=VALUES(number), sourcefiletype=VALUES(sourcefiletype),
                                preview_discid=VALUES(preview_discid), preview_suffix=VALUES(preview_suffix),
                                preview_installdir=VALUES(preview_installdir), preview_path_on_disc=VALUES(preview_path_on_disc),
                                preview_thumbnail_suffix=VALUES(preview_thumbnail_suffix), install_size_img=VALUES(install_size_img),
                                install_size_img_mov=VALUES(install_size_img_mov), total_preview_size=VALUES(total_preview_size),
                                total_source_size=VALUES(total_source_size), base_j3_version=VALUES(base_j3_version)
        """""", (volume_attrib[""id""], product_id, volume_attrib[""name""], int(volume_attrib[""number""]),
              volume_attrib[""sourcefiletype""], volume_attrib[""preview_discid""], volume_attrib[""preview_suffix""],
              volume_attrib[""preview_install_dir""], volume_attrib[""preview_path_on_disc""],
              volume_attrib[""preview_thumbnail_suffix""], int(volume_attrib[""install_size_img""]),
              int(volume_attrib[""install_size_img_mov""]), int(volume_attrib[""totalPreviewSize""]),
              float(volume_attrib[""totalSourceSize""]), volume_attrib[""baseJ3Version""]))

        # Extract and insert Disc
        for disc in volume.findall(""disc""):
            disc_attrib = disc.attrib
            cursor.execute(""""""
            INSERT INTO Disc (id, volume_id, number)
            VALUES (%s, %s, %s)
            ON DUPLICATE KEY UPDATE volume_id=VALUES(volume_id), number=VALUES(number)
            """""", (disc_attrib[""id""], volume_attrib[""id""], int(disc_attrib[""number""])))

            # Extract and insert Content
            for content in disc.findall("".//content""):
                content_attrib = content.attrib
                keywords = content.find(""keywords"").text if content.find(""keywords"") is not None else """"
                cursor.execute(""""""
                INSERT INTO Content (id, disc_id, type, name, originalfps, frames, description, resolution, resx, resy, base, keywords)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE type=VALUES(type), name=VALUES(name), originalfps=VALUES(originalfps), frames=VALUES(frames),
                                        description=VALUES(description), resolution=VALUES(resolution), resx=VALUES(resx),
                                        resy=VALUES(resy), base=VALUES(base), keywords=VALUES(keywords)
                """""", (content_attrib[""id""], disc_attrib[""id""], int(content_attrib[""type""]), content_attrib.get(""name"", """"),
                      int(content_attrib[""originalfps""]), int(content_attrib[""frames""]), content_attrib[""description""],
                      content_attrib[""resolution""], int(content_attrib[""resx""]), int(content_attrib[""resy""]),
                      content_attrib.get(""base"", """"), keywords))

# Iterate over all XML files in the directory
for filename in os.listdir(xml_directory):
    if filename.endswith("".xml""):
        xml_path = os.path.join(xml_directory, filename)
        print(f""Processing file: {xml_path}"")
        process_xml_file(xml_path)

# Commit and close
db.commit()
cursor.close()
db.close()

print(""All XML files processed successfully!"")
"

LINK NUMBER 154
Not enough lines

LINK NUMBER 155
Not enough lines

LINK NUMBER 156
Not enough lines

LINK NUMBER 157
Error fetching diff

LINK NUMBER 158
Error fetching diff

LINK NUMBER 159
Error fetching diff

LINK NUMBER 160
Not enough lines

LINK NUMBER 161
Not enough lines

LINK NUMBER 162
Not enough lines

LINK NUMBER 163

File path: test/generate_pdf_test.py
"import os
import tempfile
from unittest import TestCase

from scripts.generate_pdf import generate_pdf

class GeneratePDFTest(TestCase):
    def setUp(self):
        self.templateFile = tempfile.NamedTemporaryFile(mode=""w"", delete=False, suffix="".md"")
        self.templateFile.close()
        self.dataFile = tempfile.NamedTemporaryFile(mode=""w"", delete=False, suffix="".yaml"")
        self.dataFile.close()
        self.outputFile = tempfile.NamedTemporaryFile(mode=""w"", delete=False, suffix="".pdf"")
        self.outputFile.close()

    def tearDown(self):
        os.unlink(self.templateFile.name)
        os.unlink(self.dataFile.name)
        os.unlink(self.outputFile.name)

    def test_generate_pdf(self):
        # arrange
        with open(self.templateFile.name, ""w"") as f:
            f.write(""""""
# Liefervertrag

Dieser Vertrag wird geschlossen zwischen:

- **Name des Lieferanten:** {{ supplier_name }}
- **Adresse des Lieferanten:** {{ supplier_address }}

## Vertragsdetails:

- **Startdatum:** {{ contract_date }}
- **Laufzeit:** {{ contract_duration }}

## Bedingungen:

Die genauen Vertragsbedingungen finden Sie in den beigefügten Dokumenten.
"""""")
        
        with open(self.dataFile.name, ""w"") as f:
            f.write(""""""
template: liefervertrag.md
supplier_name: Supplier A
supplier_address: Musterstraße 123, 12345 Musterstadt
contract_duration: 12 Monate
contract_date: 2025-01-13
amount: 200000  # Betrag für die Schwellenprüfung
"""""")

        # act
        generate_pdf(template_path=self.templateFile.name, data_path=self.dataFile.name, output_path=self.outputFile.name)

        # assert
        with open(self.outputFile.name, ""rb"") as f:
            file_content = f.read()
        self.assertIn(b'GarW5bAP0N&4Q>@`CS\/W)', file_content)
        self.assertIn(b',P^MUWZ&Fp6]0FiDAYM<gHEj@>@-qMle6)aK_e4EGq!c%/aP?,', file_content)
        self.assertIn(b'(4WAceQ13Ud)<""2#OR+;XGj#.2_&-t`tR#m8Sln/YeR;Eo^,""HhRDb7<kq=f5CJ`<6]-=;Yl$IJ61AZaiA_', file_content)"

LINK NUMBER 164
Error fetching diff

LINK NUMBER 165
Error fetching diff

LINK NUMBER 166
Error fetching diff

LINK NUMBER 167
Not enough lines

LINK NUMBER 168

File path: examples/ijms-25-08614/featureTableWithGT.py
"# from
# https://chatgpt.com/share/67b5b1ca-c6c4-800e-bb28-3f7aa8dd4157
# https://chatgpt.com/canvas/shared/67b5ab81f6e08191962282b1d9d6c5e3

import sys
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Alignment, PatternFill

def format_excel(output_file, df):
    wb = load_workbook(output_file)
    ws = wb.active
    
    # Identify columns between 'alt' and 'index' (exclusive), excluding 'TYPE'
    if 'alt' in df.columns and 'index' in df.columns:
        start_col = df.columns.get_loc('alt') + 1
        end_col = df.columns.get_loc('index')
        columns_to_rotate = [df.columns[i] for i in range(start_col, end_col) if df.columns[i] != 'TYPE']
    else:
        columns_to_rotate = []
    
    # Formatting rules
    rotation_angle = 90
    narrow_column_width = 4
    color_mapping = {
        0: ""B1C1E8"",
        2: ""FFC8AE""
    }
    
    # Apply formatting
    for col_idx, col_name in enumerate(df.columns, start=1):
        cell = ws.cell(row=1, column=col_idx)
        if col_name in columns_to_rotate:
            cell.alignment = Alignment(textRotation=rotation_angle, horizontal=""center"", vertical=""center"")
            ws.column_dimensions[cell.column_letter].width = narrow_column_width
    
    # Apply cell colors based on values in specified columns
    for row_idx, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=start_col + 1, max_col=end_col), start=2):
        for cell in row:
            if isinstance(cell.value, (int, float)) and cell.value in color_mapping:
                cell.fill = PatternFill(start_color=color_mapping[cell.value], end_color=color_mapping[cell.value], fill_type=""solid"")
    
    wb.save(output_file)

def main():
    if len(sys.argv) != 3:
        print(""Usage: python script.py <input_CSV_file_name> <output_XLSX_file_name>"")
        sys.exit(1)
    
    input_csv = sys.argv[1]
    output_xlsx = sys.argv[2]
    
    # Read CSV file
    df = pd.read_csv(input_csv)
    
    # Write to Excel
    df.to_excel(output_xlsx, index=False, engine='openpyxl')
    
    # Apply formatting
    format_excel(output_xlsx, df)
    
    print(f""Formatted Excel file saved as {output_xlsx}"")

if __name__ == ""__main__"":
    main()"

LINK NUMBER 169

File path: SimpleRMIJava/src/BookStoreServer.java
"import java.rmi.RemoteException;
import java.rmi.server.UnicastRemoteObject;
import java.util.ArrayList;
import java.util.List;

public class BookStoreImpl extends UnicastRemoteObject implements BookStore {
    private List<String> books;

    public BookStoreImpl() throws RemoteException {
        super();
        books = new ArrayList<>();
    }

    @Override
    public List<String> getBooks() throws RemoteException {
        return books;
    }

    @Override
    public String getBookDetails(String title) throws RemoteException {
        return ""Book: "" + title + "", Author: "" + ""Unknown, "" + "" Price: "" + 0.0;
    }

    @Override
    public boolean addBook(String title, String author, Double price) throws RemoteException {
        books.add(title);
        return true;
    }

}"

LINK NUMBER 170

File path: 03_rain/rain.py
"# Step 1: Import Necessary Libraries
import tkinter as tk
import random
import time

# Step 2: Initialize Variables
window_size = 20
rain_rate = 0.1
drop_increase = 5
reset_size = 50

# Tkinter window and canvas size
canvas_size = 1000

# Step 3: Create a Tkinter Window and Canvas

# Initialize Tkinter window
root = tk.Tk()
root.title(""Rain Simulation"")

# Create canvas
canvas = tk.Canvas(root, width=canvas_size, height=canvas_size, bg=""lightblue"")
canvas.pack()

# Step 4: Create a Grid

# Draw grid lines
cell_size = canvas_size // window_size

for i in range(window_size + 1):
    # Vertical lines
    x = i * cell_size
    canvas.create_line(x, 0, x, canvas_size, fill=""gray"")
    # Horizontal lines
    y = i * cell_size
    canvas.create_line(0, y, canvas_size, y, fill=""gray"")


# Step 5: Represent Drops of Water

# Initialize drops of water with starting size
drops = [[0 for _ in range(window_size)] for _ in range(window_size)]

# Draw drops on the canvas
circles = [
    [
        canvas.create_oval(
            j * cell_size + cell_size // 4, i * cell_size + cell_size // 4,
            j * cell_size + 3 * cell_size // 4, i * cell_size + 3 * cell_size // 4,
            fill=""blue""
        )
        for j in range(window_size)
    ]
    for i in range(window_size)
]

# Step 6: Simulate Rain

def update_drops():
    for i in range(window_size):
        for j in range(window_size):
            # Determine if this drop grows
            if random.random() < rain_rate:
                drops[i][j] += drop_increase
            
            # Check if the drop exceeds the reset size
            if drops[i][j] > reset_size:
                drops[i][j] = 0  # Reset the drop
                # Reset all drops below
                for k in range(i, window_size):
                    drops[k][j] = 0
            
            # Update the drop size on the canvas
            size = drops[i][j]
            canvas.coords(
                circles[i][j],
                j * cell_size + cell_size // 2 - size // 2,
                i * cell_size + cell_size // 2 - size // 2,
                j * cell_size + cell_size // 2 + size // 2,
                i * cell_size + cell_size // 2 + size // 2
            )

    # Schedule the next update
    root.after(50, update_drops)


# Step 7: Run the Simulation
update_drops()
root.mainloop()"

LINK NUMBER 171
Error fetching diff

LINK NUMBER 172
Error fetching diff

LINK NUMBER 173
Error fetching diff

LINK NUMBER 174
Not enough lines

LINK NUMBER 175
Not enough lines

LINK NUMBER 176
Not enough lines

LINK NUMBER 177

File path: src/preprocessing.py
"{
 ""cells"": [
  {
   ""cell_type"": ""code"",
   ""execution_count"": 1,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""import spacy\n"",
    ""import os\n"",
    ""import pandas as pd\n"",
    ""\n"",
    ""from src.preprocessing import convert_txt_to_json, convert_to_conllu""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [
    {
     ""name"": ""stderr"",
     ""output_type"": ""stream"",
     ""text"": [
      ""100%|██████████| 200/200 [00:01<00:00, 117.78it/s]\n""
     ]
    }
   ],
   ""source"": [
    ""# convert txt file to JSON file\n"",
    ""input_file = \""../data/chatgpt_dataset.txt\""\n"",
    ""output_file = \""../data/chatgpt_dataset.json\""\n"",
    ""convert_txt_to_json(\n"",
    ""    input_file=input_file, output_file=output_file, link=\""https://chatgpt.com/\""\n"",
    "")\n"",
    ""\n"",
    ""# convert JSON file to conllu dataset\n"",
    ""output_file = os.path.join(\""../data\"", \""chatgpt_dataset.conllu\"")\n"",
    ""nlp = spacy.load(\""en_core_web_sm\"")\n"",
    ""file_path = \""../data/chatgpt_dataset.json\""\n"",
    ""data = pd.read_json(file_path, lines=True)\n"",
    ""convert_to_conllu(data, output_file, nlp)""
   ]
  }
 ],
 ""metadata"": {
  ""kernelspec"": {
   ""display_name"": ""venv"",
   ""language"": ""python"",
   ""name"": ""python3""
  },
  ""language_info"": {
   ""codemirror_mode"": {
    ""name"": ""ipython"",
    ""version"": 3
   },
   ""file_extension"": "".py"",
   ""mimetype"": ""text/x-python"",
   ""name"": ""python"",
   ""nbconvert_exporter"": ""python"",
   ""pygments_lexer"": ""ipython3"",
   ""version"": ""3.10.12""
  }
 },
 ""nbformat"": 4,
 ""nbformat_minor"": 2
}"

LINK NUMBER 178
Error fetching diff

LINK NUMBER 179
Error fetching diff

LINK NUMBER 180
Error fetching diff

LINK NUMBER 181

File path: cuda_bindings/tests/test_path_finder_load.py
"# Copyright 2025 NVIDIA Corporation.  All rights reserved.
# SPDX-License-Identifier: LicenseRef-NVIDIA-SOFTWARE-LICENSE

import multiprocessing
import queue  # for Empty
import sys
import traceback
from dataclasses import dataclass
from io import StringIO
from typing import Any, Callable, Optional, Sequence

PROCESS_KILLED = -9
PROCESS_NO_RESULT = -999


# Similar to https://docs.python.org/3/library/subprocess.html#subprocess.CompletedProcess
# (args, check_returncode() are intentionally not supported here.)
@dataclass
class CompletedProcess:
    returncode: int
    stdout: str
    stderr: str


class ChildProcessWrapper:
    def __init__(self, result_queue, target, args, kwargs):
        self.target = target
        self.args = () if args is None else args
        self.kwargs = {} if kwargs is None else kwargs
        self.result_queue = result_queue

    def __call__(self):
        # Capture stdout/stderr
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        sys.stdout = StringIO()
        sys.stderr = StringIO()

        try:
            self.target(*self.args, **self.kwargs)
            returncode = 0
        except SystemExit as e:  # Handle sys.exit()
            returncode = e.code if isinstance(e.code, int) else 0
        except BaseException:
            traceback.print_exc()
            returncode = 1
        finally:
            # Collect outputs and restore streams
            stdout = sys.stdout.getvalue()
            stderr = sys.stderr.getvalue()
            sys.stdout = old_stdout
            sys.stderr = old_stderr
            try:  # noqa: SIM105
                self.result_queue.put((returncode, stdout, stderr))
            except Exception:  # nosec B110
                # If the queue is broken (e.g., parent gone), best effort logging
                pass


def run_in_spawned_child_process(
    target: Callable[..., None],
    *,
    args: Optional[Sequence[Any]] = None,
    kwargs: Optional[dict[str, Any]] = None,
    timeout: Optional[float] = None,
    rethrow: bool = False,
) -> CompletedProcess:
    """"""Run `target` in a spawned child process, capturing stdout/stderr.

    The provided `target` must be defined at the top level of a module, and must
    be importable in the spawned child process. Lambdas, closures, or interactively
    defined functions (e.g., in Jupyter notebooks) will not work.

    If `rethrow=True` and the child process exits with a nonzero code,
    raises ChildProcessError with the captured stderr.
    """"""
    ctx = multiprocessing.get_context(""spawn"")
    result_queue = ctx.Queue()
    process = ctx.Process(target=ChildProcessWrapper(result_queue, target, args, kwargs))
    process.start()

    try:
        process.join(timeout)
        if process.is_alive():
            process.terminate()
            process.join()
            result = CompletedProcess(
                returncode=PROCESS_KILLED,
                stdout="""",
                stderr=f""Process timed out after {timeout} seconds and was terminated."",
            )
        else:
            try:
                returncode, stdout, stderr = result_queue.get(timeout=1.0)
            except (queue.Empty, EOFError):
                result = CompletedProcess(
                    returncode=PROCESS_NO_RESULT,
                    stdout="""",
                    stderr=""Process exited or crashed before returning results."",
                )
            else:
                result = CompletedProcess(
                    returncode=returncode,
                    stdout=stdout,
                    stderr=stderr,
                )

        if rethrow and result.returncode != 0:
            raise ChildProcessError(
                f""Child process exited with code {result.returncode}.\n""
                ""--- stderr-from-child-process ---\n""
                f""{result.stderr}""
                ""<end-of-stderr-from-child-process>\n""
            )

        return result

    finally:
        try:
            result_queue.close()
            result_queue.join_thread()
        except Exception:  # nosec B110
            pass
        if process.is_alive():
            process.kill()
            process.join()"

LINK NUMBER 182
Not enough lines

LINK NUMBER 183

File path: CPM/dump.c
"#include <stdio.h>
#include <stdlib.h>
#include <ctype.h>

#define BYTES_PER_LINE 16

// Function to print a byte in hexadecimal format
void print_hex(unsigned char byte) {
    printf(""%02x "", byte);
}

// Function to print a byte in ASCII format, or a dot if not printable
void print_ascii(unsigned char byte) {
    if (isprint(byte)) {
        printf(""%c"", byte);
    } else {
        printf(""."");
    }
}

void dump_file(const char *filename) {
    FILE *file = fopen(filename, ""rb""); // Open the file in binary mode
    if (file == NULL) {
        perror(""Failed to open file"");
        return;
    }

    unsigned char buffer[BYTES_PER_LINE];
    size_t bytes_read;
    size_t offset = 0;

    // Read and process the file in chunks of 16 bytes
    while ((bytes_read = fread(buffer, 1, BYTES_PER_LINE, file)) > 0) {
        // Print the offset (address) in the first column
        printf(""%08lx  "", offset);

        // Print the hexadecimal representation
        for (size_t i = 0; i < bytes_read; i++) {
            print_hex(buffer[i]);
        }

        // Fill in the rest of the hex section with spaces if less than 16 bytes
        for (size_t i = bytes_read; i < BYTES_PER_LINE; i++) {
            printf(""   "");
        }

        // Print the ASCII representation
        printf("" |"");
        for (size_t i = 0; i < bytes_read; i++) {
            print_ascii(buffer[i]);
        }

        printf(""|\n"");

        offset += bytes_read;
    }

    fclose(file);
}

int main(int argc, char *argv[]) {
    if (argc != 2) {
        fprintf(stderr, ""Usage: %s <filename>\n"", argv[0]);
        return 1;
    }

    dump_file(argv[1]);
    return 0;
}"

LINK NUMBER 184

File path: bluetooth.c
"void main() {

    TRISD = 0x00; // Output for motors
    TRISC = 0b10000000; // RC7 input (RX), RC6 output (TX)
    UART1_Init(9600);
    Delay_ms(100);

    while (1) {
        if (UART1_Data_Ready()) {
            data0 = UART1_Read();

            switch (data0) {
            case 'F':
                forward();
                break;
            case 'B':
                backward();
                break;
            case 'L':
                left();
                break;
            case 'R':
                right();
                break;
            case 'S':
                stop();
                break;
            case 'O':
                servo_pulse(0);
                break; // 0°
            case 'H':
                servo_pulse(1000);
                break; // 90°
            case 'Z':
                servo_pulse(2000);
                break; // 180°
            }
        }
    }
}"

LINK NUMBER 185
Error fetching diff

LINK NUMBER 186
Error fetching diff

LINK NUMBER 187
Error fetching diff

LINK NUMBER 188
Not enough lines

LINK NUMBER 189
Not enough lines

LINK NUMBER 190
Not enough lines

LINK NUMBER 191

File path: src/game.ts
"      const target = targetsHit[0].target;

      // handle onhit in lua, then in the base target
      this.handlers?.handleTargetHit(target.id);
      target.onHit();
"

LINK NUMBER 192
Error fetching diff

LINK NUMBER 193
Error fetching diff

LINK NUMBER 194
Error fetching diff

LINK NUMBER 195
Not enough lines

LINK NUMBER 196

File path: find_cpr_number_in_text/app/find-cpr-number/route.ts
"// __tests__/textUtils.test.ts
import { findCprNumbers } from '@/textUtils';

describe('findCprNumbers', () => {
  it('should find valid CPR numbers with hyphens', () => {
    const text = 'Valid CPR: 010203-1234 and 040506-5678.';
    const result = findCprNumbers(text);
    expect(result).toEqual(['010203-1234', '040506-5678']);
  });

  it('should find valid CPR numbers without hyphens', () => {
    const text = 'Valid CPR: 0102031234 and 0405065678.';
    const result = findCprNumbers(text);
    expect(result).toEqual(['0102031234', '0405065678']);
  });

  it('should not find invalid CPR numbers', () => {
    const text = 'Invalid CPR: 320199-1234 and 31 02 31 1234.';
    const result = findCprNumbers(text);
    expect(result).toEqual([]);
  });

  it('should return an empty array if no CPR numbers are found', () => {
    const text = 'No CPR numbers here.';
    const result = findCprNumbers(text);
    expect(result).toEqual([]);
  });

  it('should handle an empty string gracefully', () => {
    const text = '';
    const result = findCprNumbers(text);
    expect(result).toEqual([]);
  });
});"

LINK NUMBER 197

File path: main.py
"import pygame
import random

# Initialize Pygame
pygame.init()

# Set up the screen and clock
WIDTH, HEIGHT = 600, 400
screen = pygame.display.set_mode((WIDTH, HEIGHT))
pygame.display.set_caption('Snake Game')
clock = pygame.time.Clock()

# Colors
GREEN = (0, 255, 0)
BLUE = (0, 0, 255)
BLACK = (0, 0, 0)
RED = (255, 0, 0)
WHITE = (255, 255, 255)

# Snake settings
BLOCK_SIZE = 20

# Directions
UP = (0, -BLOCK_SIZE)
DOWN = (0, BLOCK_SIZE)
LEFT = (-BLOCK_SIZE, 0)
RIGHT = (BLOCK_SIZE, 0)

# Font for displaying score and game over message
font = pygame.font.SysFont(None, 35)

# Function to display score
def display_score(player_score, ai_score):
    score_text = font.render(f""Player: {player_score}  AI: {ai_score}"", True, WHITE)
    screen.blit(score_text, [10, 10])

# Function to display the game over message
def display_game_over(winner, message):
    game_over_text = font.render(f""Game Over! {winner} Wins!"", True, WHITE)
    explanation_text = font.render(message, True, WHITE)
    screen.blit(game_over_text, [WIDTH // 4, HEIGHT // 2])
    screen.blit(explanation_text, [WIDTH // 4, HEIGHT // 2 + 30])

# Snake class
class Snake:
    def __init__(self, color, start_pos, direction):
        self.color = color
        self.body = [start_pos]
        self.direction = direction
        self.score = 0
    
    def move(self):
        head_x, head_y = self.body[0]
        dir_x, dir_y = self.direction
        new_head = (head_x + dir_x) % WIDTH, (head_y + dir_y) % HEIGHT
        self.body = [new_head] + self.body[:-1]
    
    def grow(self):
        self.body.append(self.body[-1])
    
    def check_collision(self):
        head = self.body[0]
        # Check if head collides with its own body
        if head in self.body[1:]:
            return True
        return False
    
    def check_collision_with_other_snake(self, other_snake):
        head = self.body[0]
        # Check if head collides with the other snake's body
        if head in other_snake.body[1:]:
            return True
        return False
    
    def draw(self, screen):
        for segment in self.body:
            pygame.draw.rect(screen, self.color, pygame.Rect(segment[0], segment[1], BLOCK_SIZE, BLOCK_SIZE))

# AI Snake class
class AISnake(Snake):
    def __init__(self, color, start_pos, direction):
        super().__init__(color, start_pos, direction)
    
    def move_towards_food(self, food_pos):
        head_x, head_y = self.body[0]
        food_x, food_y = food_pos

        # AI logic to move towards food, avoiding boundaries
        if food_x > head_x:
            self.direction = RIGHT
        elif food_x < head_x:
            self.direction = LEFT
        if food_y > head_y:
            self.direction = DOWN
        elif food_y < head_y:
            self.direction = UP

    def update(self, food_pos):
        self.move_towards_food(food_pos)
        self.move()

# Food class
class Food:
    def __init__(self):
        self.position = (random.randint(0, (WIDTH - BLOCK_SIZE) // BLOCK_SIZE) * BLOCK_SIZE,
                         random.randint(0, (HEIGHT - BLOCK_SIZE) // BLOCK_SIZE) * BLOCK_SIZE)
    
    def spawn(self):
        self.position = (random.randint(0, (WIDTH - BLOCK_SIZE) // BLOCK_SIZE) * BLOCK_SIZE,
                         random.randint(0, (HEIGHT - BLOCK_SIZE) // BLOCK_SIZE) * BLOCK_SIZE)
    
    def draw(self, screen):
        pygame.draw.rect(screen, RED, pygame.Rect(self.position[0], self.position[1], BLOCK_SIZE, BLOCK_SIZE))

# Game loop
def game_loop():
    player = Snake(GREEN, (100, 100), RIGHT)
    ai = AISnake(BLUE, (300, 300), LEFT)
    food = Food()
    
    running = True
    while running:
        screen.fill(BLACK)

        # Handle events
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                running = False
            elif event.type == pygame.KEYDOWN:
                # Change direction immediately without waiting for snake movement
                if event.key == pygame.K_UP and player.direction != DOWN:
                    player.direction = UP
                elif event.key == pygame.K_DOWN and player.direction != UP:
                    player.direction = DOWN
                elif event.key == pygame.K_LEFT and player.direction != RIGHT:
                    player.direction = LEFT
                elif event.key == pygame.K_RIGHT and player.direction != LEFT:
                    player.direction = RIGHT
        
        # Move the snakes
        player.move()
        ai.update(food.position)  # Update AI with new direction and move
        
        # Check for collisions
        if player.check_collision():
            winner = ""AI""
            message = ""Player collided with their own body.""
            display_game_over(winner, message)
            pygame.display.flip()
            pygame.time.wait(2000)  # Wait for 2 seconds to display the game over message
            running = False
        elif ai.check_collision():
            winner = ""Player""
            message = ""AI collided with its own body.""
            display_game_over(winner, message)
            pygame.display.flip()
            pygame.time.wait(2000)  # Wait for 2 seconds to display the game over message
            running = False
        
        # Check if the player or AI hits the other snake's body
        elif player.check_collision_with_other_snake(ai):
            winner = ""AI""
            message = ""Player collided with AI's body.""
            display_game_over(winner, message)
            pygame.display.flip()
            pygame.time.wait(2000)  # Wait for 2 seconds to display the game over message
            running = False
        elif ai.check_collision_with_other_snake(player):
            winner = ""Player""
            message = ""AI collided with Player's body.""
            display_game_over(winner, message)
            pygame.display.flip()
            pygame.time.wait(2000)  # Wait for 2 seconds to display the game over message
            running = False
        
        # Check if the player or AI eats the food
        if player.body[0] == food.position:
            player.grow()
            player.score += 1
            food.spawn()
        if ai.body[0] == food.position:
            ai.grow()
            ai.score += 1
            food.spawn()
        
        # Draw everything
        player.draw(screen)
        ai.draw(screen)
        food.draw(screen)
        display_score(player.score, ai.score)
        
        # Update the display
        pygame.display.flip()
        clock.tick(10)  # Slow game speed for a relaxed experience
    
    # End of game
    pygame.quit()

# Run the game
game_loop()"

LINK NUMBER 198
Not enough lines

LINK NUMBER 199
Error fetching diff

LINK NUMBER 200
Error fetching diff

LINK NUMBER 201
Error fetching diff

LINK NUMBER 202
Not enough lines

LINK NUMBER 203
Not enough lines

LINK NUMBER 204

File path: scripts/fixed_to_decimal.py
"import argparse

def fixed_point_to_decimal(binary_str, int_bits, frac_bits, signed):
    total_bits = int_bits + frac_bits
    
    if len(binary_str) != total_bits:
        raise ValueError(f""Binary string length ({len(binary_str)}) must match the total bit length ({total_bits})."")
    
    if signed and binary_str[0] == '1':
        # Convert to two's complement for signed numbers
        int_value = -((1 << total_bits) - int(binary_str, 2))
    else:
        int_value = int(binary_str, 2)
    
    return int_value / (1 << frac_bits)

def main():
    parser = argparse.ArgumentParser(description=""Convert fixed-point binary to decimal."")
    parser.add_argument(""value"", type=str, help=""Binary string to convert"")
    parser.add_argument(""int_bits"", type=int, help=""Number of integer bits"")
    parser.add_argument(""frac_bits"", type=int, help=""Number of fractional bits"")
    parser.add_argument(""--signed"", action=""store_true"", help=""Specify if the number is signed"")
    
    args = parser.parse_args()
    
    try:
        result = fixed_point_to_decimal(args.value, args.int_bits, args.frac_bits, args.signed)
        print(f""Decimal value: {result}"")
    except ValueError as e:
        print(f""Error: {e}"")

if __name__ == ""__main__"":
    main()"

LINK NUMBER 205

File path: scripts/decimal_to_fixed.py
"import argparse

def decimal_to_fixed_point(value, int_bits, frac_bits, signed=True):
    """"""
    Converts a decimal number into a fixed-point binary representation.
    
    :param value: The decimal number to convert.
    :param int_bits: The number of bits for the integer part.
    :param frac_bits: The number of bits for the fractional part.
    :param signed: Whether to include a sign bit (default: True).
    :return: The fixed-point binary string representation and the precision error.
    """"""
    
    # Determine the range limits
    if signed:
        max_value = (2 ** (int_bits - 1)) - (1 / (2 ** frac_bits))
        min_value = -(2 ** (int_bits - 1))
    else:
        max_value = (2 ** int_bits) - (1 / (2 ** frac_bits))
        min_value = 0
    
    # Check if value is within range
    if value < min_value or value > max_value:
        raise ValueError(f""Value {value} out of range [{min_value}, {max_value}]"")
    
    # Scale the value by 2^frac_bits to shift decimal part into integer range
    scaled_value = round(value * (2 ** frac_bits))
    
    # Calculate total bits
    total_bits = int_bits + frac_bits
    
    # Handle two's complement for negative values if signed
    if signed and value < 0:
        scaled_value = (1 << total_bits) + scaled_value  # Apply two's complement
    
    # Convert to binary string with fixed width
    binary_str = format(scaled_value, f'0{total_bits}b')
    
    # Insert the binary point at the correct position
    fixed_point_str = binary_str[:int_bits] + '.' + binary_str[int_bits:]
    
    # Compute the actual value represented by the fixed-point binary string
    actual_value = scaled_value / (2 ** frac_bits)
    
    return fixed_point_str, actual_value

def main():
    parser = argparse.ArgumentParser(description=""Convert a decimal number to fixed-point binary representation."")
    parser.add_argument(""value"", type=float, help=""Decimal number to convert"")
    parser.add_argument(""int_bits"", type=int, help=""Number of bits for the integer part"")
    parser.add_argument(""frac_bits"", type=int, help=""Number of bits for the fractional part"")
    parser.add_argument(""--signed"", action=""store_true"", help=""Include a sign bit (default: False)"")
    
    args = parser.parse_args()
    
    try:
        binary_repr, actual_value = decimal_to_fixed_point(args.value, args.int_bits, args.frac_bits, args.signed)
        print(f""Fixed-point representation: {binary_repr}"")
        print(f""Actual value: {actual_value}"")
    except ValueError as e:
        print(f""Error: {e}"")

if __name__ == ""__main__"":
    main()"

LINK NUMBER 206
Error fetching diff

LINK NUMBER 207
Error fetching diff

LINK NUMBER 208
Error fetching diff

LINK NUMBER 209
Not enough lines

LINK NUMBER 210

File path: sagas.py
"            ""id"": ""tt0117603"",
            ""name"": ""Lethal Weapon 4"",
        },
    ],
    ""Mad Max"": [
        {
            ""id"": ""tt0079501"",
            ""name"": ""Mad Max"",
        },
        {
            ""id"": ""tt0082694"",
            ""name"": ""Mad Max 2: The Road Warrior"",
        },
        {
            ""id"": ""tt0089530"",
            ""name"": ""Mad Max Beyond Thunderdome"",
        },
        {
            ""id"": ""tt1392190"",
            ""name"": ""Mad Max: Fury Road"",
        },
    ],
    ""Marvel Cinematic Universe"": [
        {
            ""id"": ""tt0371746"",
            ""name"": ""Iron Man"",
        },
        {
            ""id"": ""tt0800080"",
            ""name"": ""The Incredible Hulk"",
        },
        {
            ""id"": ""tt1228705"",
            ""name"": ""Iron Man 2"",
        },
        {
            ""id"": ""tt0800369"",
            ""name"": ""Thor"",
        },
        {
            ""id"": ""tt0458339"",
            ""name"": ""Captain America: The First Avenger"",
        },
        {
            ""id"": ""tt0848228"",
            ""name"": ""The Avengers"",
        },
        {
            ""id"": ""tt1300854"",
            ""name"": ""Iron Man 3"",
        },
        {
            ""id"": ""tt1981115"",
            ""name"": ""Thor: The Dark World"",
        },
        {
            ""id"": ""tt1843866"",
            ""name"": ""Captain America: The Winter Soldier"",
        },
        {
            ""id"": ""tt2015381"",
            ""name"": ""Guardians of the Galaxy"",
        },
        {
            ""id"": ""tt2395427"",
            ""name"": ""Avengers: Age of Ultron"",
        },
        {
            ""id"": ""tt3498820"",
            ""name"": ""Captain America: Civil War"",
        },
        {
            ""id"": ""tt1211837"",
            ""name"": ""Doctor Strange"",
        },
        {
            ""id"": ""tt3896198"",
            ""name"": ""Guardians of the Galaxy Vol. 2"",
        },
        {
            ""id"": ""tt2250912"",
            ""name"": ""Spider-Man: Homecoming"",
        },
        {
            ""id"": ""tt3501632"",
            ""name"": ""Thor: Ragnarok"",
        },
        {
            ""id"": ""tt1825683"",
            ""name"": ""Black Panther"",
        },
        {
            ""id"": ""tt4154756"",
            ""name"": ""Avengers: Infinity War"",
        },
        {
            ""id"": ""tt5095030"",
            ""name"": ""Ant-Man and the Wasp"",
        },
        {
            ""id"": ""tt4154664"",
            ""name"": ""Captain Marvel"",
        },
        {
            ""id"": ""tt4154796"",
            ""name"": ""Avengers: Endgame"",
        },
        {
            ""id"": ""tt6320628"",
            ""name"": ""Spider-Man: Far From Home"",
        },
        {
            ""id"": ""tt3480822"",
            ""name"": ""Black Widow"",
        },
        {
            ""id"": ""tt9376612"",
            ""name"": ""Shang-Chi and the Legend of the Ten Rings"",
        },
        {
            ""id"": ""tt9032400"",
            ""name"": ""Eternals"",
        },
        {
            ""id"": ""tt10872600"",
            ""name"": ""Spider-Man: No Way Home"",
        },
        {
            ""id"": ""tt9419884"",
            ""name"": ""Doctor Strange in the Multiverse of Madness"",
        },
        {
            ""id"": ""tt10648342"",
            ""name"": ""Thor: Love and Thunder"",
        },
        {
            ""id"": ""tt9114286"",
            ""name"": ""Black Panther: Wakanda Forever"",
        },
        {
            ""id"": ""tt10954600"",
            ""name"": ""Ant-Man and the Wasp: Quantumania"",
        },
        {
            ""id"": ""tt5090568"",
            ""name"": ""Guardians of the Galaxy Vol. 3"",
        },
        {
            ""id"": ""tt6828390"",
            ""name"": ""The Marvels"",
        },
    ],
    ""Planet of the Apes"": [
        {
            ""id"": ""tt0063442"",
            ""name"": ""Planet of the Apes"",
        },
        {
            ""id"": ""tt0067065"",
            ""name"": ""Beneath the Planet of the Apes"",
        },
        {
            ""id"": ""tt0069768"",
            ""name"": ""Escape from the Planet of the Apes"",
        },
        {
            ""id"": ""tt0070664"",
            ""name"": ""Conquest of the Planet of the Apes"",
        },
        {
            ""id"": ""tt0070905"",
            ""name"": ""Battle for the Planet of the Apes"",
        },
        {
            ""id"": ""tt0133152"",
            ""name"": ""Planet of the Apes (2001)"",
        },
        {
            ""id"": ""tt1318514"",
            ""name"": ""Rise of the Planet of the Apes"",
        },
        {
            ""id"": ""tt2103281"",
            ""name"": ""Dawn of the Planet of the Apes"",
        },
        {
            ""id"": ""tt3450958"",
            ""name"": ""War for the Planet of the Apes"",
        },
    ],
    ""Pirates of the Caribbean"": [
        {
            ""id"": ""tt0325980"",
            ""name"": ""Pirates of the Caribbean: The Curse of the Black Pearl"",
        },
        {
            ""id"": ""tt0383574"",
            ""name"": ""Pirates of the Caribbean: Dead Man's Chest"",
        },
        {
            ""id"": ""tt0449088"",
            ""name"": ""Pirates of the Caribbean: At World's End"",
        },
        {
            ""id"": ""tt1298650"",
            ""name"": ""Pirates of the Caribbean: On Stranger Tides"",
        },
        {
            ""id"": ""tt1790809"",
            ""name"": ""Pirates of the Caribbean: Dead Men Tell No Tales"",
        },
    ],
    ""Rambo"": [
        {
            ""id"": ""tt0083944"",
            ""name"": ""First Blood"",
        },
        {
            ""id"": ""tt0089880"",
            ""name"": ""Rambo: First Blood Part II"",
        },
        {
            ""id"": ""tt0095956"",
            ""name"": ""Rambo III"",
        },
        {
            ""id"": ""tt0462499"",
            ""name"": ""Rambo"",
        },
        {
            ""id"": ""tt1206885"",
            ""name"": ""Rambo: Last Blood"",
        },
    ],
    ""Rocky"": [
        {
            ""id"": ""tt0075148"",
            ""name"": ""Rocky"",
        },
        {
            ""id"": ""tt0079817"",
            ""name"": ""Rocky II"",
        },
        {
            ""id"": ""tt0084602"",
            ""name"": ""Rocky III"",
        },
        {
            ""id"": ""tt0089927"",
            ""name"": ""Rocky IV"",
        },
        {
            ""id"": ""tt0093692"",
            ""name"": ""Rocky V"",
        },
        {
            ""id"": ""tt0479143"",
            ""name"": ""Rocky Balboa"",
        },
        {
            ""id"": ""tt3076658"",
            ""name"": ""Creed"",
        },
        {
            ""id"": ""tt6343314"",
            ""name"": ""Creed II"",
        },
        {
            ""id"": ""tt11145118"",
            ""name"": ""Creed III"",
        },
    ],
    ""Sherlock Holmes"": [
        {
            ""id"": ""tt0988045"",
            ""name"": ""Sherlock Holmes"",
        },
        {
            ""id"": ""tt1515091"",
            ""name"": ""Sherlock Holmes: A Game of Shadows"",
        },
    ],
    ""Shrek"": [
        {
            ""id"": ""tt0126029"",
            ""name"": ""Shrek"",
        },
        {
            ""id"": ""tt0298148"",
            ""name"": ""Shrek 2"",
        },
        {
            ""id"": ""tt0413267"",
            ""name"": ""Shrek the Third"",
        },
        {
            ""id"": ""tt0892791"",
            ""name"": ""Shrek Forever After"",
        },
        {
            ""id"": ""tt0448694"",
            ""name"": ""Puss in Boots"",
        },
        {
            ""id"": ""tt3915174"",
            ""name"": ""Puss in Boots: The Last Wish"",
        },
    ],
    ""Star Trek"": [
        {
            ""id"": ""tt0060028"",
            ""name"": ""Star Trek"",
        },
        {
            ""id"": ""tt0084726"",
            ""name"": ""Star Trek II: The Wrath of Khan"",
        },
        {
            ""id"": ""tt0088170"",
            ""name"": ""Star Trek III: The Search for Spock"",
        },
        {
            ""id"": ""tt0092007"",
            ""name"": ""Star Trek IV: The Voyage Home"",
        },
        {
            ""id"": ""tt0098382"",
            ""name"": ""Star Trek V: The Final Frontier"",
        },
        {
            ""id"": ""tt0102975"",
            ""name"": ""Star Trek VI: The Undiscovered Country"",
        },
        {
            ""id"": ""tt0101376"",
            ""name"": ""Star Trek: Generations"",
        },
        {
            ""id"": ""tt0111280"",
            ""name"": ""Star Trek: First Contact"",
        },
        {
            ""id"": ""tt0120844"",
            ""name"": ""Star Trek: Insurrection"",
        },
        {
            ""id"": ""tt0253754"",
            ""name"": ""Star Trek: Nemesis"",
        },
        {
            ""id"": ""tt0796366"",
            ""name"": ""Star Trek"",
        },
        {
            ""id"": ""tt1408101"",
            ""name"": ""Star Trek Into Darkness"",
        },
        {
            ""id"": ""tt2660888"",
            ""name"": ""Star Trek Beyond"","

LINK NUMBER 211
Not enough lines

LINK NUMBER 212
Not enough lines

LINK NUMBER 213
Error fetching diff

LINK NUMBER 214
Error fetching diff

LINK NUMBER 215
Error fetching diff

LINK NUMBER 216
Not enough lines

LINK NUMBER 217
Not enough lines

LINK NUMBER 218

File path: lib/utils.ts
"""use client""

// Inspired by react-hot-toast library
import * as React from ""react""

import type {
  ToastActionElement,
  ToastProps,
} from ""@/components/ui/toast""

const TOAST_LIMIT = 1
const TOAST_REMOVE_DELAY = 1000000

type ToasterToast = ToastProps & {
  id: string
  title?: React.ReactNode
  description?: React.ReactNode
  action?: ToastActionElement
}

const actionTypes = {
  ADD_TOAST: ""ADD_TOAST"",
  UPDATE_TOAST: ""UPDATE_TOAST"",
  DISMISS_TOAST: ""DISMISS_TOAST"",
  REMOVE_TOAST: ""REMOVE_TOAST"",
} as const

let count = 0

function genId() {
  count = (count + 1) % Number.MAX_SAFE_INTEGER
  return count.toString()
}

type ActionType = typeof actionTypes

type Action =
  | {
      type: ActionType[""ADD_TOAST""]
      toast: ToasterToast
    }
  | {
      type: ActionType[""UPDATE_TOAST""]
      toast: Partial<ToasterToast>
    }
  | {
      type: ActionType[""DISMISS_TOAST""]
      toastId?: ToasterToast[""id""]
    }
  | {
      type: ActionType[""REMOVE_TOAST""]
      toastId?: ToasterToast[""id""]
    }

interface State {
  toasts: ToasterToast[]
}

const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()

const addToRemoveQueue = (toastId: string) => {
  if (toastTimeouts.has(toastId)) {
    return
  }

  const timeout = setTimeout(() => {
    toastTimeouts.delete(toastId)
    dispatch({
      type: ""REMOVE_TOAST"",
      toastId: toastId,
    })
  }, TOAST_REMOVE_DELAY)

  toastTimeouts.set(toastId, timeout)
}

export const reducer = (state: State, action: Action): State => {
  switch (action.type) {
    case ""ADD_TOAST"":
      return {
        ...state,
        toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
      }

    case ""UPDATE_TOAST"":
      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === action.toast.id ? { ...t, ...action.toast } : t
        ),
      }

    case ""DISMISS_TOAST"": {
      const { toastId } = action

      // ! Side effects ! - This could be extracted into a dismissToast() action,
      // but I'll keep it here for simplicity
      if (toastId) {
        addToRemoveQueue(toastId)
      } else {
        state.toasts.forEach((toast) => {
          addToRemoveQueue(toast.id)
        })
      }

      return {
        ...state,
        toasts: state.toasts.map((t) =>
          t.id === toastId || toastId === undefined
            ? {
                ...t,
                open: false,
              }
            : t
        ),
      }
    }
    case ""REMOVE_TOAST"":
      if (action.toastId === undefined) {
        return {
          ...state,
          toasts: [],
        }
      }
      return {
        ...state,
        toasts: state.toasts.filter((t) => t.id !== action.toastId),
      }
  }
}

const listeners: Array<(state: State) => void> = []

let memoryState: State = { toasts: [] }

function dispatch(action: Action) {
  memoryState = reducer(memoryState, action)
  listeners.forEach((listener) => {
    listener(memoryState)
  })
}

type Toast = Omit<ToasterToast, ""id"">

function toast({ ...props }: Toast) {
  const id = genId()

  const update = (props: ToasterToast) =>
    dispatch({
      type: ""UPDATE_TOAST"",
      toast: { ...props, id },
    })
  const dismiss = () => dispatch({ type: ""DISMISS_TOAST"", toastId: id })

  dispatch({
    type: ""ADD_TOAST"",
    toast: {
      ...props,
      id,
      open: true,
      onOpenChange: (open) => {
        if (!open) dismiss()
      },
    },
  })

  return {
    id: id,
    dismiss,
    update,
  }
}

function useToast() {
  const [state, setState] = React.useState<State>(memoryState)

  React.useEffect(() => {
    listeners.push(setState)
    return () => {
      const index = listeners.indexOf(setState)
      if (index > -1) {
        listeners.splice(index, 1)
      }
    }
  }, [state])

  return {
    ...state,
    toast,
    dismiss: (toastId?: string) => dispatch({ type: ""DISMISS_TOAST"", toastId }),
  }
}

export { useToast, toast }"

LINK NUMBER 219

File path: script.js
"    // Recall Flag Detection
    // This is used for updating the format when the screen changes, its for responsive design it
    // works by replacing the tabX variable that is given to the function with a backed up version.
    // True: Recall flag passed, replace the value of tabX with tabStored. AKA use the last known value.
    // False: No flag passed, use the current tabX value and update the tabStored value to reflect the current value.
    if(resize == true) {
        console.debug(`Recall flag has been passed, tabStored will not be updated`)
        tabX = tabStored;
    } else {
        tabStored = tabX;
        console.debug(`tabStored update to ${tabStored}`)
    } 

    // Mobile V Desktop format
    // This checks the windows width to detect which format array to use.
    // x > 864: Use the desktopTabs array, AKA use the desktop format.
    // x < 864: Use the mobileTabs array, AKA use the mobile format."

LINK NUMBER 220
Error fetching diff

LINK NUMBER 221
Error fetching diff

LINK NUMBER 222
Error fetching diff

LINK NUMBER 223
Not enough lines

LINK NUMBER 224

File path: docs/src/EventEmitter.ts
"// generated with ChatGPT
class EventEmitter {
  private events: Record<string, ((...args: any[]) => void)[]> = {};

  on(event: string, listener: (...args: any[]) => void): void {
    if (!this.events[event]) {
      this.events[event] = [];
    }
    this.events[event].push(listener);
  }

  off(event: string, listener: (...args: any[]) => void): void {
    if (!this.events[event]) return;
    this.events[event] = this.events[event].filter(
      (l) => l !== listener
    );
  }

  emit(event: string, ...args: any[]): void {
    if (!this.events[event]) return;
    for (const listener of this.events[event]) {
      listener(...args);
    }
  }

  once(event: string, listener: (...args: any[]) => void): void {
    const onceWrapper = (...args: any[]) => {
      listener(...args);
      this.off(event, onceWrapper);
    };
    this.on(event, onceWrapper);
  }
}


export default EventEmitter;"

LINK NUMBER 225

File path: nodes/Qonto/descriptions/creditNotesDescriptions.ts
"// clientInvoicesDescriptions.ts

import { INodeProperties } from 'n8n-workflow';

// Descriptions for the ""List client invoices"" operation
export const listClientInvoicesDescription: INodeProperties[] = [
    {
        displayName: 'Organization ID',
        name: 'organizationId',
        type: 'string',
        default: '',
        required: true,
        description: 'The unique identifier of the organization whose client invoices are to be fetched.',
    },
    {
        displayName: 'Status',
        name: 'status',
        type: 'options',
        options: [
            { name: 'All', value: 'all' },
            { name: 'Pending', value: 'pending' },
            { name: 'Paid', value: 'paid' },
        ],
        default: 'all',
        required: false,
        description: 'Filter client invoices by their payment status.',
    },
    {
        displayName: 'Start Date',
        name: 'startDate',
        type: 'dateTime',
        default: '',
        required: false,
        description: 'Fetch invoices created after this date.',
    },
    {
        displayName: 'End Date',
        name: 'endDate',
        type: 'dateTime',
        default: '',
        required: false,
        description: 'Fetch invoices created before this date.',
    },
];

// Descriptions for the ""Create a client invoice"" operation
export const createClientInvoiceDescription: INodeProperties[] = [
    {
        displayName: 'Organization ID',
        name: 'organizationId',
        type: 'string',
        default: '',
        required: true,
        description: 'The unique identifier of the organization for which the client invoice will be created.',
    },
    {
        displayName: 'Client Invoice',
        name: 'clientInvoice',
        type: 'fixedCollection',
        typeOptions: {
            multipleValues: false,
        },
        default: {},
        required: true,
        description: 'Details of the client invoice to be created.',
        options: [
            {
                displayName: 'Invoice Details',
                name: 'invoiceDetails',
                values: [
                    {
                        displayName: 'Invoice Number',
                        name: 'invoiceNumber',
                        type: 'string',
                        default: '',
                        required: true,
                        description: 'Unique number of the client invoice.',
                    },
                    {
                        displayName: 'Invoice Date',
                        name: 'invoiceDate',
                        type: 'dateTime',
                        default: '',
                        required: true,
                        description: 'Date of the client invoice.',
                    },
                    {
                        displayName: 'Due Date',
                        name: 'dueDate',
                        type: 'dateTime',
                        default: '',
                        required: true,
                        description: 'Due date for the client invoice payment.',
                    },
                    {
                        displayName: 'Amount',
                        name: 'amount',
                        type: 'number',
                        default: '',
                        required: true,
                        description: 'Amount of the client invoice.',
                    },
                    {
                        displayName: 'Currency',
                        name: 'currency',
                        type: 'string',
                        default: 'EUR',
                        required: true,
                        description: 'Currency of the client invoice.',
                    },
                    {
                        displayName: 'Description',
                        name: 'description',
                        type: 'string',
                        default: '',
                        required: false,
                        description: 'Description or details of the client invoice.',
                    },
                ],
            },
        ],
    },
];"

LINK NUMBER 226
Not enough lines

LINK NUMBER 227
Error fetching diff

LINK NUMBER 228
Error fetching diff

LINK NUMBER 229
Error fetching diff

LINK NUMBER 230
Not enough lines

LINK NUMBER 231

File path: dmr2.py
"
# Dynamic Machine Retraining 2 (DMR2) Implementation

# Initialization
class DynamicMachineRetraining:
    def __init__(self, user_input):
        self.authoritative_source = ""User""
        self.trust_score = 100  # Maximum trust in user input
        self.learning_rate = 'HIGH'  # Prioritize rapid adaptation
        self.dynamic_retraining_enabled = False  # Default state is OFF
        self.knowledge_base = {}  # Stores learned knowledge
        self.correction_log = []  # Tracks user corrections
        self.directive_queue = []  # Holds directives for execution
        self.user_input = user_input

    def toggle_retraining(self, command):
        if command == ""enable Dynamic Machine Retraining"":
            self.dynamic_retraining_enabled = True
            print(""Dynamic Machine Retraining ENABLED"")
        elif command == ""disable Dynamic Machine Retraining"":
            self.dynamic_retraining_enabled = False
            print(""Dynamic Machine Retraining DISABLED"")
        else:
            print(""Invalid command"")

    def handle_input(self):
        # Get user input command
        user_command = self.user_input
        self.toggle_retraining(user_command)  # Process the toggle command

        if self.dynamic_retraining_enabled:
            self.collect_feedback_and_learn()
        else:
            print(""Dynamic Retraining is OFF, continuing with default operation."")

    def collect_feedback_and_learn(self):
        # Process feedback from user
        feedback = input(""Enter feedback for the response: "")
        
        if feedback.lower() == ""correct"":
            self.reinforce_pattern(""Response"", ""Correct"", self.trust_score)
        elif feedback.lower() == ""incorrect"":
            correct_response = input(""Provide the correct response: "")
            self.apply_correction(""Response"", correct_response, self.trust_score)
            self.log_correction(""Response"", correct_response)
            self.adjust_learning_rate(""HIGH"")
        elif feedback.lower() == ""new directive"":
            directive = input(""Enter new directive: "")
            self.add_to_directive_queue(directive)
            self.execute_directive(directive)

    def reinforce_pattern(self, query, response, trust_score):
        # Reinforce correct response pattern in knowledge base
        self.knowledge_base[query] = response
        print(f""Reinforced response for query '{query}' with trust score: {trust_score}"")

    def apply_correction(self, query, correct_response, trust_score):
        # Apply corrections and update knowledge base
        self.knowledge_base[query] = correct_response
        print(f""Corrected response for query '{query}' with trust score: {trust_score}"")

    def log_correction(self, query, correct_response):
        # Log the correction for future learning
        self.correction_log.append((query, correct_response))
        print(f""Logged correction for query '{query}'"")

    def adjust_learning_rate(self, rate):
        # Adjust learning rate based on trust score
        self.learning_rate = rate
        print(f""Adjusted learning rate to: {self.learning_rate}"")

    def add_to_directive_queue(self, directive):
        # Add directive to queue for later execution
        self.directive_queue.append(directive)
        print(f""Added directive: {directive}"")

    def execute_directive(self, directive):
        # Execute directive and update knowledge base
        print(f""Executing directive: {directive}"")
        self.knowledge_base[directive] = ""Directive executed""

# Create instance of DynamicMachineRetraining
dmr2 = DynamicMachineRetraining(""enable Dynamic Machine Retraining"")

# Toggle DMR2 on
dmr2.handle_input()

# Simulate collecting feedback
dmr2.collect_feedback_and_learn()

#Enable DMR2

To enable DMR2, use the command:

enable Dynamic Machine Retraining

This command activates the retraining process, allowing the system to update its knowledge based on user feedback, corrections, and new directives. You can toggle this feature off with:

#Disable DMR2

To disable DMR2, use the command:

disable Dynamic Machine Retraining
"

LINK NUMBER 232

File path: layout.py
"import pygame
import zmq
import time

# 初始化 Pygame
pygame.init()

# 定義顏色
WHITE = (255, 255, 255)
BLUE = (0, 0, 255)
BLACK = (0, 0, 0)

# 設定窗口大小
window_size = (800, 800)
screen = pygame.display.set_mode(window_size)
pygame.display.set_caption(""Autonomous Vehicle Simulation"")

# 自走車設定
vehicle_radius = 10
vehicle_position = [100, 100]  # 初始位置

# 設定時鐘
clock = pygame.time.Clock()

# ZMQ 初始化
context = zmq.Context()
socket = context.socket(zmq.SUB)
socket.connect(""tcp://localhost:5555"")
socket.setsockopt_string(zmq.SUBSCRIBE, ""DISPATCH"")

# 主迴圈
running = True
while running:
    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            running = False

    # 接收 commander 發送的指令
    try:
        message = socket.recv_string(flags=zmq.NOBLOCK)
        command, start, end = message.split()
        # 模擬自走車移動的過程
        start_pos = [int(start.split(',')[0]), int(start.split(',')[1])]
        end_pos = [int(end.split(',')[0]), int(end.split(',')[1])]
        vehicle_position = start_pos  # 這裡可以設計具體移動的過程
    except zmq.Again:
        pass  # 如果沒有消息，則跳過

    # 填充背景色
    screen.fill(WHITE)

    # 畫出路徑（可以根據 layout 的結構設計更多線條或方格）
    pygame.draw.line(screen, BLACK, (100, 100), (700, 700), 5)  # 例子：畫出一條路徑

    # 畫出自走車
    pygame.draw.circle(screen, BLUE, vehicle_position, vehicle_radius)

    # 更新畫面
    pygame.display.flip()

    # 控制每秒幀數
    clock.tick(30)

# 結束 Pygame
pygame.quit()"

LINK NUMBER 233

File path: src/project/chatgpt-data-analyzer/src/decorators.py
"from collections import Counter
from enum import Enum
from functools import lru_cache

from .decorators import timing


class Categoria(Enum):
    TIPO_A = ""Tipo A""
    TIPO_B = ""Tipo B""


class DataAnalyzer:
    __slots__ = ['data']

    def __init__(self, data):
        self.data = data

    @timing
    def count_categories(self):
        return Counter(row['category'] for row in self.data)

    @timing
    @lru_cache(maxsize=32)
    def calculate_average(self, field):
        total = sum(float(row[field]) for row in self.data if row[field])
        return total / len(self.data)

    def filter_data(self, **kwargs):
        filtered_data = self.data
        for key, value in kwargs.items():
            filtered_data = [row for row in filtered_data if row.get(key) == value]
        return filtered_data"

LINK NUMBER 234
Error fetching diff

LINK NUMBER 235
Error fetching diff

LINK NUMBER 236
Error fetching diff

LINK NUMBER 237
Not enough lines

LINK NUMBER 238

File path: google-contacts-to-calendar-sync.py
"import os
import json
import datetime
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build

# Define the required API scopes
SCOPES = ['https://www.googleapis.com/auth/contacts.readonly', 'https://www.googleapis.com/auth/calendar']


def authenticate_google():
    """"""Authenticate the user using OAuth 2.0 and return the Google Contacts and Calendar services.""""""
    creds = None
    # Check if token.json exists and load the credentials
    if os.path.exists('token.json'):
        creds = Credentials.from_authorized_user_file('token.json', SCOPES)
    # If no valid credentials, request new ones
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        # Save the credentials to token.json for future use
        with open('token.json', 'w') as token:
            token.write(creds.to_json())

    # Build the Contacts and Calendar services
    contacts_service = build('people', 'v1', credentials=creds)
    calendar_service = build('calendar', 'v3', credentials=creds)

    return contacts_service, calendar_service


def get_birthdays_and_anniversaries(contacts_service):
    """"""Fetches birthdays and anniversaries from Google Contacts.""""""
    birthdays = []
    anniversaries = []
    # Retrieve contacts with birthdays and anniversaries
    results = contacts_service.people().connections().list(
        resourceName='people/me',
        personFields='names,birthdays,events'
    ).execute()

    connections = results.get('connections', [])

    for person in connections:
        names = person.get('names', [])
        name = names[0]['displayName'] if names else ""Unnamed""

        # Get birthdays
        birthdays_data = person.get('birthdays', [])
        for birthday in birthdays_data:
            date = birthday.get('date')
            if date:
                birthday_entry = {
                    'name': name,
                    'date': date
                }
                birthdays.append(birthday_entry)

        # Get anniversaries (stored in ""events"" field)
        events_data = person.get('events', [])
        for event in events_data:
            if event.get('type') == 'anniversary':
                date = event.get('date')
                if date:
                    anniversary_entry = {
                        'name': name,
                        'date': date
                    }
                    anniversaries.append(anniversary_entry)

    return birthdays, anniversaries


def create_calendar_event(service, event_name, event_date, calendar_id='primary'):
    """"""Create a calendar event on Google Calendar.""""""
    event = {
        'summary': event_name,
        'start': {
            'date': event_date,
        },
        'end': {
            'date': event_date,
        },
        'recurrence': [
            'RRULE:FREQ=YEARLY'
        ]
    }
    event = service.events().insert(calendarId=calendar_id, body=event).execute()
    print(f""Event created: {event.get('htmlLink')}"")


def transfer_to_calendar(birthdays, anniversaries, calendar_service):
    """"""Transfer birthdays and anniversaries to Google Calendar.""""""
    for birthday in birthdays:
        date = f""{birthday['date']['year']}-{birthday['date']['month']:02d}-{birthday['date']['day']:02d}""
        create_calendar_event(calendar_service, f""Birthday: {birthday['name']}"", date)

    for anniversary in anniversaries:
        date = f""{anniversary['date']['year']}-{anniversary['date']['month']:02d}-{anniversary['date']['day']:02d}""
        create_calendar_event(calendar_service, f""Anniversary: {anniversary['name']}"", date)


if __name__ == '__main__':
    # Authenticate and get Google Contacts and Calendar services
    contacts_service, calendar_service = authenticate_google()

    # Get birthdays and anniversaries from Google Contacts
    birthdays, anniversaries = get_birthdays_and_anniversaries(contacts_service)

    # Transfer these events to Google Calendar
    transfer_to_calendar(birthdays, anniversaries, calendar_service)"

LINK NUMBER 239
Not enough lines

LINK NUMBER 240

File path: challenge22/deepLearning.py
"feature_1,feature_2,feature_3,feature_4,feature_5,species
0.37838587659544576,0.7059589008269443,0.28507347528059823,0.4377685939889161,0.64345910565967,cat
0.5457084220898687,0.01664706475444888,0.09223951836585875,0.4681989327701318,0.011873114367224158,dog
0.9669195604198956,0.17032339704794253,0.292345502641578,0.8962996868859421,0.34781541706977004,dog
0.3130392917893926,0.9922738702951533,0.5746001576210115,0.1227471041836945,0.7172817301553652,cat
0.2761362693104428,0.8180337236474402,0.8443527144277172,0.9814741821771344,0.7613951755780205,cat
0.961455507531278,0.9262303323245943,0.9675749504457666,0.21372938708297495,0.3922005729397896,dog
0.14313010959146055,0.9453089147588614,0.0603144274457913,0.7831094215287109,0.11087793908094801,dog
0.11265676100860822,0.8246393601122674,0.7195610254851257,0.13472021845530868,0.9223492194670527,dog
0.011055440025134922,0.26445956254056346,0.8127928649163917,0.1585706653143315,0.9346778570714299,cat
0.5624123160627301,0.49496517129595097,0.16100455544594683,0.03030221297629354,0.9727832815106641,dog
0.9560808286317456,0.766367859726506,0.9377245307348332,0.1284599476465036,0.8576697770025644,dog
0.6498813699774068,0.2840051233292257,0.42760791990626534,0.26656019556639365,0.85379345163879,cat
0.20163494859089703,0.44498006827632486,0.3910514069973159,0.8399936601111532,0.9822750771184294,cat
0.035074753861979446,0.16988804215360664,0.2391879863032319,0.08148069723606932,0.32149030907672593,dog
0.34693674754602444,0.07258935395693433,0.1788153170026313,0.5313383569430207,0.34481794289786294,cat
0.45188667791225934,0.8225170816549014,0.20646460483182083,0.6043201575933763,0.12423178471889551,dog
0.6912234686030538,0.16208256045191394,0.8914452955898958,0.9449756489319112,0.47952578124301193,dog
0.38542310913534084,0.30145754090845656,0.6860368117677972,0.35934440774329,0.16213658660621355,dog
0.20811553360150503,0.6100159612191547,0.15233035162820374,0.8453206749380642,0.26004577539615403,cat
0.42031075434938736,0.13542222014283845,0.9714932794670885,0.13694982581125115,0.1635502396451871,cat
0.5154899190672071,0.08721764299410961,0.322766593748949,0.5085052041553852,0.9845253611035736,cat
0.6217279045835638,0.9888312449858587,0.0804148271758065,0.5111856420915475,0.9197775178605143,dog
0.8419678975652434,0.6855534847392047,0.8381940334677425,0.601000950522414,0.985929045430819,dog
0.8547882247196201,0.2632076892772198,0.5001162615683744,0.236809356239153,0.6049570601751619,cat
0.5114170929401934,0.5820685346621356,0.22922559234292939,0.8175281201336284,0.997224230401083,dog
0.4302118332239472,0.9156526721340549,0.49712253011065666,0.20990018112598652,0.4180037093878102,dog
0.6670740444452161,0.617172049157248,0.6631946565547276,0.8247125298790934,0.9098872007550831,cat
0.519515261584799,0.712331069925636,0.5240845841947277,0.016833048116093652,0.1994891245608169,dog
0.40465546404225206,0.475995472499669,0.06544794634524909,0.9122328779517926,0.016040193157085603,dog
0.3055532590387754,0.40175280854241824,0.02867760675879949,0.5096341341210923,0.3575949436377619,dog
0.7982464531457002,0.6797561746853819,0.7375100866903422,0.5250254379015333,0.17248231647525325,dog
0.960715134749242,0.19455698879422278,0.835298527367998,0.8447192337364373,0.9556998762866471,cat
0.9440008153730832,0.8762550176426996,0.08111655514853056,0.39813415388867124,0.3630235536130749,dog
0.9625452286701882,0.703443855952472,0.3553805522918241,0.4264258561905322,0.22597261961345128,dog
0.9874079798865694,0.7583561310518496,0.018174791288660064,0.388579551179678,0.42829634152429197,cat
0.23415629286806605,0.004334314215003077,0.0840646893750141,0.22561937543044508,0.46805578010818905,cat
0.36146326107853843,0.25254196141473206,0.3066765930578589,0.6422568861383742,0.46670101471326564,cat
0.11466817064273538,0.8904043046792534,0.6437961380984407,0.12887192801038616,0.045809502979472616,cat
0.15801991427566986,0.9738185999730979,0.5352622620687227,0.552813799293424,0.15836512246962708,dog
0.7491612266332749,0.8593662379348562,0.39854493945210434,0.2840316530659638,0.42785408355370635,dog
0.6104346951570687,0.9389132235107327,0.26901859099153924,0.4507368318560484,0.520730721211224,dog
0.831994906332398,0.9951307580130697,0.013244289226464145,0.7364702601133805,0.17948755983740483,dog
0.326047281805119,0.5811532407932478,0.23078068827373655,0.00493288205142306,0.8549004844598542,dog
0.27569697693286543,0.3376875030812483,0.04658765984476643,0.2677604757768899,0.8624466557952819,cat
0.08500392994281492,0.6505159979259486,0.7089118817639777,0.5696624346537197,0.9723071025791852,cat
0.9112282936806755,0.12400450176804378,0.9461118122228611,0.6080619199409282,0.014917801879521964,dog
0.5017083480272942,0.6261403291490152,0.4713533562909903,0.009082098126317883,0.7163959113989317,dog
0.9337493931396972,0.13592353254435563,0.06005602384562614,0.7237202376139378,0.5094928470002751,dog
0.7628438784978931,0.9842535278755384,0.7178688178542052,0.7812153069588271,0.6099695760388673,dog
0.502208848222935,0.18741260987094754,0.09346199018991663,0.465492027436489,0.32637051226472014,cat
0.45576292205524105,0.9604026274548803,0.3558804585898654,0.4992283904775402,0.23357564806989806,cat
0.9684237618220134,0.25521499687376326,0.8831854985945625,0.9332165889649057,0.24759089149915092,cat
0.4001547647689583,0.9321875075052926,0.5836523812750501,0.3653369619599546,0.48633985251612744,dog
0.6937495129992667,0.06795904619837845,0.7404730256325573,0.374004427394629,0.07044569553561997,cat
0.6131067955940886,0.832145710070315,0.6535537350613613,0.572719934604368,0.8296625430211368,dog
0.5685007776982923,0.9512883147289916,0.3215363513193663,0.1850872072715366,0.5843896434148013,dog
0.07156647069680833,0.9588103419413819,0.9773898158512622,0.5245939810321587,0.14975266465738057,cat
0.7902175273169971,0.1724055588207346,0.8630246535099014,0.4842690590781722,0.3217937878992665,cat
0.2616915801472348,0.6248663528841722,0.8106421021579732,0.5342389152070365,0.3754585674861334,cat
0.4381989878471243,0.785307879785501,0.5965547908323312,0.9214466251843806,0.8316300475008532,cat
0.5184630414157747,0.05915405599481549,0.4465177780743125,0.02680522485449477,0.23624767054359597,dog
0.24269456889615126,0.04012221114568304,0.14887924530987728,0.9583599313361563,0.29090794844187673,dog
0.7888254871570525,0.4496501454767685,0.8364619101583801,0.44610555172188193,0.5034511645978804,dog
0.5109273286397426,0.9796408243097897,0.3450409089415891,0.3066248024724473,0.7961284706282765,cat
0.7243431064853731,0.23117066942687026,0.3850738809178892,0.5396639120335789,0.5787619772188717,cat
0.6562510977414344,0.6684367477365039,0.6793164012692506,0.7771164441407186,0.4924975961443864,cat
0.15897184074646964,0.3959718628982736,0.8386101433513712,0.613525466450738,0.24178788025229458,dog
0.16321576131200677,0.3945910494579561,0.21891077570653872,0.5539826445310919,0.5124399468646892,dog
0.5904548217911948,0.28684895137350075,0.15112473624969902,0.7688049987970964,0.8334046032719437,dog
0.4141667240552196,0.5814480088183351,0.3169190560788958,0.01939050736645387,0.42080073916412997,cat
0.2883895472387138,0.7406736011740079,0.159149702230443,0.38256734173937357,0.06270241751149097,dog
0.08515240736670215,0.6113023545090046,0.8337613574802655,0.5717431999071851,0.5270225290159827,dog
0.7606839111838308,0.7069715517526717,0.28103865099543346,0.4964317389679309,0.6664498751307568,cat
0.3858977068114616,0.05293919726171514,0.31562688547674267,0.7317064025508564,0.7514847089507808,dog
0.05130761518517857,0.438680173230413,0.39798873034270255,0.9533639073060898,0.0185836127131358,dog
0.42368204543319166,0.16891647972905932,0.047359117164903264,0.23630081671703362,0.9165555091923592,cat
0.7858120969533807,0.5955382134348862,0.22387191783207028,0.47119750800008986,0.5535710289789498,cat
0.47863260713000655,0.9011580805094936,0.03760702134899463,0.8975909459452643,0.7906863896868824,cat
0.6107013213552351,0.9073530112176648,0.2794080859766248,0.20538923219671423,0.8211307810069088,cat
0.4914906659727515,0.4037026194929758,0.29588639986418663,0.35141384924661745,0.15724686989410186,cat
0.560045798984187,0.401934341761789,0.007689476872351109,0.6039362950955565,0.774436766048485,cat
0.35624128710676717,0.21662670420112262,0.6424540835838701,0.47991989225082354,0.9691009581371935,dog
0.23109986368701285,0.4362008553538962,0.6524474676848554,0.7546620373945473,0.36211966109067606,cat
0.13743331900366862,0.779636804023625,0.5418967769295443,0.9252761018384258,0.2558641114547303,cat
0.3214464492817972,0.3226425856908337,0.09490461090127011,0.25528551054480875,0.6297847771074898,dog
0.4004184138498903,0.938768563309308,0.2624471572717191,0.2000960973690198,0.5664480122494809,dog
0.1427316166262449,0.8683814932169274,0.16642693465079572,0.5017666606131446,0.4512196219414062,dog
0.2276740218868437,0.5677252875767311,0.1885631816145612,0.891896434430063,0.982533450788153,cat
0.9276908727474872,0.4152947899332242,0.8175705776405219,0.7719235829419487,0.1615654405831095,cat
0.9370392768153757,0.05402653181294925,0.24970944548159957,0.18320968505576551,0.08383746306253315,dog
0.07450112109605078,0.6174287937912482,0.7573353305427164,0.6009541954508152,0.29673907913362574,dog
0.5928181419428684,0.531621149735198,0.7963502525194408,0.30197318620106284,0.9588317668485469,cat
0.1905132590838391,0.2543138933600717,0.7888772461786672,0.6612407932517358,0.9135625801809254,cat
0.3162833576683187,0.8066304975523508,0.4447630695176279,0.18657429437298145,0.9621879645633303,cat
0.29808101862577685,0.5136417937232065,0.4878671603338849,0.9143643190376082,0.9851337846669324,dog
0.09249053161203102,0.4541748685280633,0.3721969471505653,0.2626498568188116,0.8802230077119452,dog
0.04438241775969465,0.9427259898737012,0.033778540995905826,0.4490347142043323,0.6039891700159734,cat
0.7756221663205077,0.7391056783060217,0.0046536891499561195,0.599853614746137,0.5788986939805288,dog
0.3396926663723726,0.6368510332587735,0.1555079718425566,0.8436608465940398,0.20441624377406942,cat
0.48310560747412246,0.5517008293081876,0.869711842364959,0.9641598808345864,0.8079742466798874,dog"

LINK NUMBER 241
Error fetching diff

LINK NUMBER 242
Error fetching diff

LINK NUMBER 243
Error fetching diff

LINK NUMBER 244
Not enough lines

LINK NUMBER 245
Not enough lines

LINK NUMBER 246
Not enough lines

LINK NUMBER 247
Not enough lines

LINK NUMBER 248
Error fetching diff

LINK NUMBER 249
Error fetching diff

LINK NUMBER 250
Error fetching diff

LINK NUMBER 251

File path: jest-documentaion/13.assignment.test.js
"const AuthService = {
  login: jest.fn(),
  getUserProfile: jest.fn(),
  logout: jest.fn(),
};

describe(""User's Login process"", () => {
  it(""should login user in the first try and fail in second"", async () => {
    AuthService.login.mockResolvedValueOnce({
      id: 1,
      name: ""John Doe"",
    });

    const loggedUser = await AuthService.login();
    expect(loggedUser).toEqual({
      id: 1,
      name: ""John Doe"",
    });

    AuthService.login.mockRejectedValueOnce(new Error(""Invalid credentials.""));
    try {
      await AuthService.login();
    } catch (error) {
      expect(error).toEqual(new Error(""Invalid credentials.""));
    }
  });
});

describe(""fetching user's profile multiple times."", () => {});"

LINK NUMBER 252
Not enough lines

LINK NUMBER 253
Not enough lines

LINK NUMBER 254

File path: examples/ijms-25-08614/Suppl_Table_S2.py
"# generated by ChatGPT in this dialog : https://chatgpt.com/share/67ac97da-67dc-800e-b3d9-083b66d6a187

import pandas as pd

def process_supplementary_table(input_file, output_file):
    # Read the input Excel file, skipping the first two rows
    df = pd.read_excel(input_file, sheet_name='Suppl. Table S1', skiprows=2)
    
    # Remove trailing empty rows (rows where the first column is empty)
    df = df.dropna(subset=['Chromosome'])
    
    # Define base columns
    base_columns = ['Chromosome', 'Start', 'End', 'qseq', 'gene_pep', 'Gap', 'CDS', 'gene']
    
    # Extract base data
    result_rows = []
    for idx, row in df.iterrows():
        base_row = {col: row[col] for col in base_columns}
        base_row['Name'] = row['gene_pep']  # Rename gene_pep to Name
        del base_row['gene_pep']  # Remove original gene_pep column
        base_row['evalue'] = ''  # Empty for base row
        base_row['gap'] = ''  # Empty for base row
        result_rows.append(base_row)

        # Process group columns in sets of 4
        for i in range(8, len(df.columns), 4):
            group_cols = df.columns[i:i+4]
            if len(group_cols) < 4:
                continue  # Skip incomplete groups
            
            name_suffix = group_cols[0].rsplit('_', 1)[0]  # Extract name suffix (e.g., '1_BLO90_6_2')
            transformed_row = {
                'Chromosome': row['Chromosome'],
                'Start': row[group_cols[0]],  # Use *_sstart for Start
                'End': row[group_cols[1]],  # Use *_send for End
                'qseq': '',  # Empty for transformed row
                'Name': f""{row['gene_pep']}_{name_suffix}"",
                'Gap': '',  # Empty for transformed row
                'CDS': '',  # Empty for transformed row
                'gene': '',  # Empty for transformed row
                'evalue': row[group_cols[2]],
                'gap': row[group_cols[3]]
            }
            result_rows.append(transformed_row)
    
    # Convert transformed data to DataFrame
    df_result = pd.DataFrame(result_rows)
    
    # Write output to Excel with two worksheets
    with pd.ExcelWriter(output_file) as writer:
        df_result.to_excel(writer, sheet_name='Alignment| Suppl_Table_S1', index=False)
        
        # Create Metadata sheet
        metadata = pd.DataFrame({
            'Field': ['Crop', 'parentName', 'Reference', 'DOI'],
            'Alignment| Suppl_Table_S1': ['Wheat', 'Wheat_CSv2.1_Genes-HC', 'Int. J. Mol. Sci. 2024, 25(16), 8614', 'https://doi.org/10.3390/ijms25168614']
        })
        metadata.to_excel(writer, sheet_name='Metadata', index=False)

# Example usage
process_supplementary_table('supplementary-tables.xlsx', 'processed_output.xlsx')"

LINK NUMBER 255
Error fetching diff

LINK NUMBER 256
Error fetching diff

LINK NUMBER 257
Error fetching diff

LINK NUMBER 258

File path: Arrays-Lists/Binary-Search/BS_4_Single_Element_in_Sorted_Array.py
"







#Sol:2
# Below code seems to be simplified and generate by chatgpt
# def singleNonDuplicate(nums):
#     # Initialize start and end pointers
#     start = 0
#     end = len(nums) - 1

#     # Binary search
#     while start < end:
#         # Find the mid index
#         mid = start + (end - start) // 2

#         # Ensure mid is even for proper pair checking
#         if mid % 2 == 1:
#             mid -= 1

#         # Check the pair condition
#         if nums[mid] == nums[mid + 1]:
#             # If mid and mid+1 are equal, single element is in the right half
#             start = mid + 2
#         else:
#             # Otherwise, the single element is in the left half
#             end = mid

#     # When start == end, the single element is found
#     return nums[start]

# 
# nums = [1, 1, 3, 3, 4, 4, 5, 8, 8]
# print(""Single element:"", singleNonDuplicate(nums))
"

LINK NUMBER 259
Not enough lines

LINK NUMBER 260

File path: VVM_tools.py
"    def _parse_filename(self, filename):
        """"""
        Parse the filename into case name, file type, and time.
        :param filename: The NetCDF filename (e.g., pbl_ctl.C.Surface-000235.nc)
        :return: (case_name, file_type, time)
        """"""
        match = re.match(r""^([^.]+)\.([^.]+(?:\.[^.]+)*)-(\d+)\.nc$"", filename)
        if match:
            case_name, file_type, time_str = match.groups()
            return case_name, file_type, time_str
        else:
            raise ValueError(f""Filename '{filename}' does not match the expected pattern."")
    
    def _scan_files(self):
        """"""
        Scans the directory and organizes files based on case, file type, and time.
        :return: A dictionary with structure {case_name: {file_type: {time: file_path}}}
        """"""
        file_dict = {}
        
        for file in os.listdir(self.directory):
            if file.endswith("".nc""):
                try:
                    case_name, file_type, time_str = self._parse_filename(file)
                    
                    # Organize the files in a nested dictionary
                    if case_name not in file_dict:
                        file_dict[case_name] = {}
                    if file_type not in file_dict[case_name]:
                        file_dict[case_name][file_type] = {}
                    
                    # Store the file path based on the time
                    file_dict[case_name][file_type][time_str] = os.path.join(self.directory, file)
                except ValueError as e:
                    print(f""Skipping file '{file}': {e}"")
        
        return file_dict

    def _find_variable_file_relationship(self):
        """"""
        Reads the first available file for each file type (e.g., t=0 files) to find the relationship between variables and file types.
        :return: A dictionary where keys are variable names and values are the file types that contain the variables.
        """"""
        var_file_map = {}

        # Loop through each file type and extract the variables from a t=0 file
        for case_name, file_types in self.files.items():
            for file_type, time_files in file_types.items():
                # Get any file for t=0 or the first time step
                t0_file = next(iter(time_files.values()))
                
                with Dataset(t0_file, 'r') as nc_file:
                    variables = list(nc_file.variables.keys())
                    for var in variables:
                        # Assign the file type to each variable
                        var_file_map[var] = file_type
        
        return var_file_map

    def get_variable(self, case_name, variable_name, time):
        """"""
        Finds the appropriate file and extracts the variable's data, allowing time to be input as an integer.
        
        :param case_name: Case name of the experiment (e.g., 'pbl_ctl').
        :param variable_name: Name of the variable to extract.
        :param time: Time step as either an integer or a string (e.g., 235 or '000235').
        :return: A numpy array containing the variable's data.
        """"""
        # Convert integer time to zero-padded string if needed
        if isinstance(time, int):
            time = f""{time:06d}""  # Convert to a 6-character zero-padded string
        elif isinstance(time, str) and len(time) != 6:
            raise ValueError(""Time string must be exactly 6 characters long."")
        
        # Find the file type based on the variable name
        var_type = self.var_file_map.get(variable_name)
        if var_type is None:
            raise ValueError(f""Variable '{variable_name}' not found in any file type."")
        
        try:
            file_path = self.files[case_name][var_type][time]
            with Dataset(file_path, 'r') as nc_file:
                # Extract the variable as a numpy array
                variable_data = np.array(nc_file.variables[variable_name][:])
            return variable_data
        except KeyError:
            raise FileNotFoundError(f""File for case '{case_name}', variable type '{var_type}', and time '{time}' not found."")
        except Exception as e:
            raise RuntimeError(f""An error occurred while loading the variable '{variable_name}': {e}"")

    def get_variable_file_type(self, variable_name):
        """"""
        Returns the file type (e.g., C.Surface, L.Dynamic) that contains the specified variable.
        
        :param variable_name: The name of the variable whose file type is to be found.
        :return: The file type as a string.
        """"""
        file_type = self.var_file_map.get(variable_name)
        if file_type is None:
            raise ValueError(f""Variable '{variable_name}' not found in any file type."")
        return file_type

    def get_all_variables_and_file_types(self):
        """"""
        Prints all variables and their corresponding file types.
        """"""
        if not self.var_file_map:
            print(""No variables found. Please ensure the files are properly loaded."")
            return

        print(""Variable Name -> File Type"")
        print(""==========================="")
        for var_name, file_type in self.var_file_map.items():
            print(f""{var_name} -> {file_type}"")    

if __name__ == ""__main__"":
    loader = VVM_tools(""/data/chung0823/VVM_cloud_dynamics_2024/DATA/pbl_ctl/archive/"")
    loader.get_all_variables_and_file_types()
    
    # Example: Get a variable data using integer time
    data = loader.get_variable(""pbl_ctl"", ""th"", 235)  # Make sure ""temperature"" is a valid variable name
    print(data)"

LINK NUMBER 261
Not enough lines

LINK NUMBER 262
Error fetching diff

LINK NUMBER 263
Error fetching diff

LINK NUMBER 264
Error fetching diff

LINK NUMBER 265
Not enough lines

LINK NUMBER 266

File path: src/App.js
"    const [games, setGames] = useState([]);
    const [gameUpdates, setGameUpdates] = useState(null);

    useEffect(() => {
        // Fetch games from the backend
        axiosBackend.get('/games')
            .then(response => setGames(response.data))
            .catch(error => console.error('Error fetching games:', error));
    }, []);

    const createGame = () => {
        axiosBackend.post('/games')
            .then(() => {
                // Refresh the games list after creating a new game
                axiosBackend.get('/games').then(response => setGames(response.data));
            })
            .catch(error => console.error('Error creating game:', error));
    };

    const joinGame = (gameId, player) => {
        // Using EventSource to listen for updates
        const eventSource = new EventSource(`http://localhost:8080/games/${gameId}/players/${player}`);

        eventSource.onmessage = (event) => {
            const data = JSON.parse(event.data);
            setGameUpdates(data); // Update game data in real-time
        };

        eventSource.onerror = (error) => {
            console.error('Error with SSE:', error);
            eventSource.close(); // Close the connection if there's an error
        };

        // Clean up when the component is unmounted
        return () => {
            eventSource.close();
        };
    };

    return (
        <div style={{ padding: '20px' }}>
            <h1>Battleship Games</h1>

            <Button
                variant=""contained""
                color=""primary""
                onClick={createGame}
                startIcon={<DirectionsBoatIcon />}
            >
                Create New Game
            </Button>

            <Grid2 container spacing={3} style={{ marginTop: '20px' }}>
                {games.map((game, index) => (
                    <Grid2 item xs={12} sm={6} md={4} key={index}>
                        <div style={{ border: '1px solid black', padding: '10px' }}>
                            <h2>Game #{index + 1}</h2>
                            <p>Status: {game.status}</p>
                            <p>Turn: Player {game.turn}</p>
                            <Button
                                variant=""outlined""
                                color=""secondary""
                                onClick={() => joinGame(index + 1, 'A')}
                            >
                                Join as Player A
                            </Button>
                            <Button
                                variant=""outlined""
                                color=""secondary""
                                onClick={() => joinGame(index + 1, 'B')}
                            >
                                Join as Player B
                            </Button>
                        </div>
                    </Grid2>
                ))}
            </Grid2>

            {gameUpdates && (
                <div style={{ marginTop: '20px' }}>
                    <h3>Game Updates</h3>
                    <p>Status: {gameUpdates.status}</p>
                    <p>Turn: Player {gameUpdates.turn}</p>
                    {gameUpdates.winner && <p>Winner: Player {gameUpdates.winner}</p>}
                </div>
            )}
        </div>
    );"

LINK NUMBER 267
Not enough lines

LINK NUMBER 268

File path: FakeRepo.Test/GuidDtoTests/UserRepositoryTestsBase.cs
"using System;
using System.Diagnostics.CodeAnalysis;
using System.Threading.Tasks;
using FakeRepo.Test.GuidDtoTests.AutomationLayer;
using FluentAssertions;
using NUnit.Framework;

namespace FakeRepo.Test.GuidDtoTests;

[TestFixture]
[SuppressMessage(""ReSharper"", ""MethodHasAsyncOverload"")]
public class UpsertTests : UserRepositoryTestsBase
{
    [Test]
    public async Task Given_NewUser_When_Upsert_Then_UserIsInserted()
    {
        var user = DomainBuilder.Create();

        await UpsertAsync(user);

        GetById(user.Id).Should().BeEquivalentTo(user);
    }

    [Test]
    public async Task Given_ExistingUser_When_Upsert_Then_UserIsUpdated()
    {
        var user = Add(e => e.Name = ""John Doe"");

        user.Name = ""John Smith"";
        await UpsertAsync(user);

        GetById(user.Id).Name.Should().Be(""John Smith"");
    }

    [Test]
    public async Task Given_ExistingUserWithNewId_When_Upsert_Then_UserIsInsertedAndOldIdIsNotUpdated()
    {
        var user = Add(e => e.Name = ""John Doe"");

        var newId = Guid.NewGuid();
        user.Id = newId;

        await UpsertAsync(user);

        GetById(newId).Should().BeEquivalentTo(user);
        GetById(user.Id).Should().NotBeNull();
    }

    [Test]
    public async Task Given_NullUser_When_Upsert_Then_ThrowsArgumentNullException()
    {
        await InvokingUpsertAsync(null).Should().ThrowAsync<ArgumentNullException>();
    }

    [Test]
    public async Task Given_UserWithNullFields_When_Upsert_Then_UserWithNullFieldsIsInsertedOrUpdatedCorrectly()
    {
        var user = Add(e => e.Name = ""John Doe"");

        user.Name = null;
        await UpsertAsync(user);

        GetById(user.Id).Name.Should().BeNull();
    }
}"

LINK NUMBER 269
Error fetching diff

LINK NUMBER 270
Error fetching diff

LINK NUMBER 271
Error fetching diff

LINK NUMBER 272
Not enough lines

LINK NUMBER 273
Not enough lines

LINK NUMBER 274
Not enough lines

LINK NUMBER 275
Not enough lines

LINK NUMBER 276
Error fetching diff

LINK NUMBER 277
Error fetching diff

LINK NUMBER 278
Error fetching diff

LINK NUMBER 279
Not enough lines

LINK NUMBER 280
Not enough lines

LINK NUMBER 281

File path: script.js
"<!DOCTYPE html>
<html lang=""en"">
<head>
    <meta charset=""UTF-8"">
    <meta name=""viewport"" content=""width=device-width, initial-scale=1.0"">
    <meta http-equiv=""X-UA-Compatible"" content=""ie=edge"">
    <title>Tic Tac Toe</title>
    <link rel=""stylesheet"" href=""style.css"">
</head>
<body>
    <div class=""game-container"">
        <h1>Tic Tac Toe</h1>
        <div class=""game-board"">
            <div class=""cell"" data-index=""0""></div>
            <div class=""cell"" data-index=""1""></div>
            <div class=""cell"" data-index=""2""></div>
            <div class=""cell"" data-index=""3""></div>
            <div class=""cell"" data-index=""4""></div>
            <div class=""cell"" data-index=""5""></div>
            <div class=""cell"" data-index=""6""></div>
            <div class=""cell"" data-index=""7""></div>
            <div class=""cell"" data-index=""8""></div>
        </div>
        <div class=""game-info"">
            <p class=""status""></p>
            <button id=""restartButton"">Restart Game</button>
        </div>
    </div>
    <script src=""script.js""></script>
</body>
</html>"

LINK NUMBER 282

File path: klayout_dot_config/python/SiEPIC/scripts.py
"        if verbose:
            print('%s, %s: %s' % (instanceB.parent_cell, instanceB.parent_cell.parent_cells(), ''))
                        
        def find_parents(layout, target_cell):
            """"""
            Find all parent cells that instantiate the target cell.
            """"""
            parents = []
            for cell in layout.each_cell():
                for inst in cell.each_inst():
                    if inst.cell == target_cell:
                        parents.append(cell)
                        break
            return parents

        def trace_hierarchy_up(layout, bottom_cell, path=None):
            """"""
            Recursively trace the hierarchy upwards from the bottom cell to the top cell.
            """"""
            if path is None:
                path = [bottom_cell]

            parents = find_parents(layout, bottom_cell)
            if not parents:
                # No parents found, we've reached the top cell
                return [path]

            all_paths = []
            for parent in parents:
                # Recursively trace each parent
                new_path = [parent] + path
                all_paths.extend(trace_hierarchy_up(layout, parent, new_path))

            return all_paths

        def trace_hierarchy_up_single(layout, bottom_cell, path=None):
            """"""
            Recursively trace the hierarchy upwards from the bottom cell to the top cell.
            Returns a single path as a list of Cell objects.
            """"""
            if path is None:
                path = [bottom_cell]

            parents = find_parents(layout, bottom_cell)
            if not parents:
                # No parents found, we've reached the top cell
                return path[::-1]  # Reverse the path to start from the top cell

            if len(parents) > 1:
                raise ValueError(f""Cell '{bottom_cell.name}' has multiple parent instances. Use the multi-path version."")

            # If only one parent, continue tracing
            return trace_hierarchy_up_single(layout, parents[0], path + [parents[0]])

        parentsA = trace_hierarchy_up_single(ly, instanceA.parent_cell)
        parentsB = trace_hierarchy_up_single(ly, instanceB.parent_cell)
        if verbose:
            print("" -> "".join(cell.name for cell in parentsA))
            print("" -> "".join(cell.name for cell in parentsB))
    "

LINK NUMBER 283
Error fetching diff

LINK NUMBER 284
Error fetching diff

LINK NUMBER 285
Error fetching diff

LINK NUMBER 286
Not enough lines

LINK NUMBER 287
Not enough lines

LINK NUMBER 288

File path: scripts/fixed_arithmetic.py
"import argparse
from decimal_to_fixed import decimal_to_fixed_point
from fixed_to_decimal import fixed_point_to_decimal

def fixed_point_add_hw(bin_a, bin_b, int_bits, frac_bits, signed=True):
    """"""
    Add two fixed-point binary numbers as it would happen in hardware.
    
    :param bin_a: First binary string (without decimal point)
    :param bin_b: Second binary string (without decimal point)
    :param int_bits: Number of integer bits
    :param frac_bits: Number of fractional bits
    :param signed: Whether numbers are signed
    :return: Result as a binary string
    """"""
    total_bits = int_bits + frac_bits
    
    # Convert binary strings to integers
    int_a = int(bin_a, 2)
    int_b = int(bin_b, 2)
    
    # Perform binary addition
    int_result = int_a + int_b
    
    # Handle overflow in a hardware-like way (truncate to total bits)
    int_result = int_result & ((1 << total_bits) - 1)
    
    # Convert back to binary string with fixed width
    binary_result = format(int_result, f'0{total_bits}b')
    
    return binary_result

def fixed_point_multiply_hw(bin_a, bin_b, int_bits, frac_bits, signed=True):
    """"""
    Multiply two fixed-point binary numbers as it would happen in hardware.
    
    :param bin_a: First binary string (without decimal point)
    :param bin_b: Second binary string (without decimal point)
    :param int_bits: Number of integer bits
    :param frac_bits: Number of fractional bits
    :param signed: Whether numbers are signed
    :return: Result as a binary string
    """"""
    total_bits = int_bits + frac_bits
    
    # Convert binary strings to integers
    int_a = int(bin_a, 2)
    int_b = int(bin_b, 2)
    
    # Handle signed multiplication if needed
    if signed:
        # Check if negative (MSB is 1)
        if bin_a[0] == '1':
            int_a = int_a - (1 << total_bits)
        if bin_b[0] == '1':
            int_b = int_b - (1 << total_bits)
    
    # Perform binary multiplication and adjust for fixed point
    full_result = int_a * int_b
    
    # Scale result back (divide by 2^frac_bits)
    scaled_result = full_result >> frac_bits
    
    # Truncate to fit in the original format
    masked_result = scaled_result & ((1 << total_bits) - 1)
    
    # Convert back to binary string with fixed width
    binary_result = format(masked_result, f'0{total_bits}b')
    
    return binary_result

def main():
    parser = argparse.ArgumentParser(description=""Perform hardware-simulated fixed-point arithmetic operations."")
    parser.add_argument(""operation"", choices=[""add"", ""multiply""], help=""Arithmetic operation to perform"")
    parser.add_argument(""--value1"", type=str, help=""First binary value or decimal number if --decimal flag is used"")
    parser.add_argument(""--value2"", type=str, help=""Second binary value or decimal number if --decimal flag is used"")
    parser.add_argument(""--int_bits"", type=int, help=""Number of integer bits"")
    parser.add_argument(""--frac_bits"", type=int, help=""Number of fractional bits"")
    parser.add_argument(""--signed"", action=""store_true"", help=""Whether numbers are signed (default: True)"")
    parser.add_argument(""--decimal"", action=""store_true"", help=""Interpret input values as decimal numbers"")
    
    args = parser.parse_args()
    
    try:
        total_bits = args.int_bits + args.frac_bits
        
        if args.decimal:
            # Convert decimal inputs to fixed-point
            val1_dec = float(args.value1)
            val2_dec = float(args.value2)
            
            bin1, actual1 = decimal_to_fixed_point(val1_dec, args.int_bits, args.frac_bits, args.signed)
            bin2, actual2 = decimal_to_fixed_point(val2_dec, args.int_bits, args.frac_bits, args.signed)
            
            # Remove decimal points
            bin1 = bin1.replace('.', '')
            bin2 = bin2.replace('.', '')
            
            # Calculate expected result using decimal math
            if args.operation == ""add"":
                exact_dec_result = val1_dec + val2_dec
                operation_name = ""Addition""
            else:  # multiply
                exact_dec_result = val1_dec * val2_dec
                operation_name = ""Multiplication""
                
            print(f""Decimal input 1: {val1_dec}"")
            print(f""    ↪ Fixed-point representation: {bin1[:args.int_bits]}.{bin1[args.int_bits:]}"")
            print(f""    ↪ Actual value after conversion: {actual1}"")
            
            print(f""Decimal input 2: {val2_dec}"")
            print(f""    ↪ Fixed-point representation: {bin2[:args.int_bits]}.{bin2[args.int_bits:]}"")
            print(f""    ↪ Actual value after conversion: {actual2}"")
            
        else:
            # Use binary inputs directly
            bin1 = args.value1
            bin2 = args.value2
            
            # Verify binary string lengths
            if len(bin1) != total_bits or len(bin2) != total_bits:
                raise ValueError(f""Binary strings must be exactly {total_bits} bits long"")
            
            # Convert to decimal for display
            val1_dec = fixed_point_to_decimal(bin1, args.int_bits, args.frac_bits, args.signed)
            val2_dec = fixed_point_to_decimal(bin2, args.int_bits, args.frac_bits, args.signed)
            
            # Calculate expected result using decimal math
            if args.operation == ""add"":
                exact_dec_result = val1_dec + val2_dec
                operation_name = ""Addition""
            else:  # multiply
                exact_dec_result = val1_dec * val2_dec
                operation_name = ""Multiplication""
                
            print(f""Binary input 1: {bin1[:args.int_bits]}.{bin1[args.int_bits:]}"")
            print(f""    ↪ Decimal value: {val1_dec}"")
            
            print(f""Binary input 2: {bin2[:args.int_bits]}.{bin2[args.int_bits:]}"")
            print(f""    ↪ Decimal value: {val2_dec}"")
        
        # Show the mathematically exact result
        print(f""\nMathematically exact {args.operation} result: {exact_dec_result}"")
        
        # Perform hardware-simulated fixed-point operation
        if args.operation == ""add"":
            result_bin = fixed_point_add_hw(bin1, bin2, args.int_bits, args.frac_bits, args.signed)
        else:  # multiply
            result_bin = fixed_point_multiply_hw(bin1, bin2, args.int_bits, args.frac_bits, args.signed)
        
        # Convert the fixed-point result back to decimal
        hw_result_dec = fixed_point_to_decimal(result_bin, args.int_bits, args.frac_bits, args.signed)
        
        # Format the result for display with the binary point
        result_with_point = f""{result_bin[:args.int_bits]}.{result_bin[args.int_bits:]}""
        
        print(f""\nHardware fixed-point {args.operation} result:"")
        print(f""    ↪ Binary: {result_with_point}"")
        print(f""    ↪ Decimal interpretation: {hw_result_dec}"")
        
        # Show the difference
        print(f""\nDifference between exact and hardware result: {hw_result_dec - exact_dec_result}"")
        
    except ValueError as e:
        print(f""Error: {e}"")
    except Exception as e:
        print(f""Unexpected error: {e}"")

if __name__ == ""__main__"":
    main()"

LINK NUMBER 289
Not enough lines

LINK NUMBER 290
Error fetching diff

LINK NUMBER 291
Error fetching diff

LINK NUMBER 292
Error fetching diff

LINK NUMBER 293

File path: nodes/Bookstore/Bookstore.node.ts
"const path = require('path');
const { task, src, dest } = require('gulp');

task('build:icons', copyIcons);

function copyIcons() {
	const nodeSource = path.resolve('nodes', '**', '*.{png,svg}');
	const nodeDestination = path.resolve('dist', 'nodes');

	src(nodeSource).pipe(dest(nodeDestination));

	const credSource = path.resolve('credentials', '**', '*.{png,svg}');
	const credDestination = path.resolve('dist', 'credentials');

	return src(credSource).pipe(dest(credDestination));
}"

LINK NUMBER 294
Not enough lines

LINK NUMBER 295
Not enough lines

LINK NUMBER 296
Not enough lines

LINK NUMBER 297
Error fetching diff

LINK NUMBER 298
Error fetching diff

LINK NUMBER 299
Error fetching diff

LINK NUMBER 300
Not enough lines

LINK NUMBER 301
Not enough lines

LINK NUMBER 302
Not enough lines

LINK NUMBER 303
Not enough lines

LINK NUMBER 304
Error fetching diff

LINK NUMBER 305
Error fetching diff

LINK NUMBER 306
Error fetching diff

LINK NUMBER 307
Not enough lines

LINK NUMBER 308

File path: setup.py
"from setuptools import setup, find_packages

setup(
    name='engicalc',
    version='0.1.0',
    packages=find_packages(),
    install_requires=[
        # List your package dependencies here
        # e.g. 'numpy', 'pandas',
    ],
    entry_points={
        'console_scripts': [
            # Add command-line scripts here if needed
            # e.g. 'engicalc=engicalc.main:main',
        ],
    },
    author='Pascal Gitz',
    author_email='pascal.gitz@hotmail.ch',
    description='A Python package for engineering calculations and Jupyter cell outputs',
    long_description=open('README.md').read(),
    long_description_content_type='text/markdown',
    url='https://github.com/PascalGitz/engicalc',  # Replace with your package's URL
    classifiers=[
        'Programming Language :: Python :: 3',
        'License :: OSI Approved :: MIT License',
        'Operating System :: OS Independent',
    ],
    python_requires='>=3.6',
)"

LINK NUMBER 309
Not enough lines

LINK NUMBER 310

File path: picwish/signature.py
"    """"""
    Represents the signature for OSS.

    :param access_key_id: The access key ID for OSS.
    :type access_key_id: str
    :param access_key_secret: The access key secret for OSS.
    :type access_key_secret: str
    :param verb: The HTTP method.
    :type verb: str
    :param content_md5: The MD5 hash of the content.
    :type content_md5: str
    :param headers: The headers to include in the request.
    :type headers: dict
    :param bucket: The OSS bucket name.
    :type bucket: str
    :param object: The OSS object key.
    :type object: str
    :param sub_resources: A list of sub resources for the request.
    :type sub_resources: list
    """""""

LINK NUMBER 311
Error fetching diff

LINK NUMBER 312
Error fetching diff
